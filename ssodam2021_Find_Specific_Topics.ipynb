{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57cecfd",
   "metadata": {},
   "source": [
    "## Load_Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e335c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe93dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7cec958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data_l/ssodam2021_tokenized.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69abbb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num                                                                    1082901\n",
       "board                                                                      익게2\n",
       "title                                                                    해피뉴이어\n",
       "text                                                      2021년은 모두 행복한 한해가 되길\n",
       "writer                                                                      익명\n",
       "upload_date                                                         2021/01/01\n",
       "upload_time                                                              00:00\n",
       "view                                                                    1343.0\n",
       "likes                                                                    195.0\n",
       "dislikes                                                                   0.0\n",
       "comments                     앗, 성지다, 첫글 ㅊㅊ, 추천 준다, 내 24살은 인생에서 가장 빛나는 날로 만들...\n",
       "comments_writer                                                            NaN\n",
       "comments_cnt                                                              20.0\n",
       "text_tokenized               [('2021년', 'Number'), ('은', 'Foreign'), ('모두',...\n",
       "title_tokenized                                            [('해피뉴이어', 'Noun')]\n",
       "comments_tokenized           [('앗', 'Noun'), (',', 'Punctuation'), ('성지', '...\n",
       "comments_writer_tokenized                                                  NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af5a477",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87e537a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_list_from_str(msg):\n",
    "    try :\n",
    "        return [tuple([re.sub(\"'\",'',y) for y in re.findall('\\'.*?\\'',x)]) for x in re.findall('\\(.*?\\)',msg)]\n",
    "    except :\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9a4bb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')\n",
    "df.text_tokenized = df.text_tokenized.apply(lambda x: get_noun_list_from_str(x))\n",
    "df.title_tokenized = df.title_tokenized.apply(lambda x: get_noun_list_from_str(x))\n",
    "df.comments_tokenized = df.comments_tokenized.apply(lambda x: get_noun_list_from_str(x))\n",
    "df.comments_writer_tokenized = df.comments_writer_tokenized.apply(lambda x: get_noun_list_from_str(x))\n",
    "df.upload_date = pd.to_datetime(df.upload_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e47fcdb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>board</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>writer</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>view</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_writer</th>\n",
       "      <th>comments_cnt</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>comments_writer_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1082901</td>\n",
       "      <td>익게2</td>\n",
       "      <td>해피뉴이어</td>\n",
       "      <td>2021년은 모두 행복한 한해가 되길</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>앗, 성지다, 첫글 ㅊㅊ, 추천 준다, 내 24살은 인생에서 가장 빛나는 날로 만들...</td>\n",
       "      <td></td>\n",
       "      <td>20.0</td>\n",
       "      <td>[(2021년, Number), (은, Foreign), (모두, Noun), (행...</td>\n",
       "      <td>[(해피뉴이어, Noun)]</td>\n",
       "      <td>[(앗, Noun), (,, Punctuation), (성지, Noun), (다, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1082902</td>\n",
       "      <td>익게2</td>\n",
       "      <td>2021년 새해복 많이받으세요</td>\n",
       "      <td>모든 일이 잘 되기를 12시 땡</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>107.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>늦었네</td>\n",
       "      <td>2빠다 ㅎㅎ, 내년에 도전한다</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(모든, Noun), (일이, Modifier), (잘, Verb), (되, Ve...</td>\n",
       "      <td>[(2021년, Number), (새해, Noun), (복, Noun), (많이, ...</td>\n",
       "      <td>[(늦었네, Verb)]</td>\n",
       "      <td>[(2, Number), (빠다, Noun), (ㅎㅎ, KoreanParticle)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082903</td>\n",
       "      <td>익게2</td>\n",
       "      <td>첫글은 내꼬</td>\n",
       "      <td>예비회계사 나다미</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ㄹㅇ 1등이네 ㅋㅋ, 실패</td>\n",
       "      <td>ㅜㅜ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(예비, Noun), (회계사, Noun), (나, Noun), (다미, Noun)]</td>\n",
       "      <td>[(첫, Modifier), (글, Noun), (은, Josa), (내꼬, Noun)]</td>\n",
       "      <td>[(ㄹㅇ, KoreanParticle), (1등, Number), (이네, Fore...</td>\n",
       "      <td>[(ㅜㅜ, KoreanParticle)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082905</td>\n",
       "      <td>익게2</td>\n",
       "      <td>땡ㅎㅎㅎㅎㅎㅎㅎ</td>\n",
       "      <td>1등</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(1등, Number)]</td>\n",
       "      <td>[(땡, Noun), (ㅎㅎㅎㅎㅎㅎㅎ, KoreanParticle)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1082906</td>\n",
       "      <td>익게2</td>\n",
       "      <td>어디 카운트 다운 하는 곳 없냐</td>\n",
       "      <td>언제바껴</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232번 불교방송</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(언, Modifier), (제바, Noun), (껴, Verb)]</td>\n",
       "      <td>[(어디, Noun), (카운트, Noun), (다운, Noun), (하는, Ver...</td>\n",
       "      <td>[(232, Number), (번, Noun), (불교, Noun), (방송, No...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num board              title                  text writer upload_date  \\\n",
       "0  1082901   익게2              해피뉴이어  2021년은 모두 행복한 한해가 되길     익명  2021-01-01   \n",
       "1  1082902   익게2   2021년 새해복 많이받으세요     모든 일이 잘 되기를 12시 땡     익명  2021-01-01   \n",
       "2  1082903   익게2             첫글은 내꼬             예비회계사 나다미     익명  2021-01-01   \n",
       "3  1082905   익게2           땡ㅎㅎㅎㅎㅎㅎㅎ                    1등     익명  2021-01-01   \n",
       "4  1082906   익게2  어디 카운트 다운 하는 곳 없냐                  언제바껴     익명  2021-01-01   \n",
       "\n",
       "  upload_time    view  likes  dislikes  \\\n",
       "0       00:00  1343.0  195.0       0.0   \n",
       "1       00:00   107.0    3.0       0.0   \n",
       "2       00:00   139.0    1.0       0.0   \n",
       "3       00:00    39.0    0.0       0.0   \n",
       "4       00:00    84.0    0.0       0.0   \n",
       "\n",
       "                                            comments   comments_writer  \\\n",
       "0  앗, 성지다, 첫글 ㅊㅊ, 추천 준다, 내 24살은 인생에서 가장 빛나는 날로 만들...                     \n",
       "1                                                늦었네  2빠다 ㅎㅎ, 내년에 도전한다   \n",
       "2                                     ㄹㅇ 1등이네 ㅋㅋ, 실패                ㅜㅜ   \n",
       "3                                                                        \n",
       "4                                          232번 불교방송                     \n",
       "\n",
       "   comments_cnt                                     text_tokenized  \\\n",
       "0          20.0  [(2021년, Number), (은, Foreign), (모두, Noun), (행...   \n",
       "1           3.0  [(모든, Noun), (일이, Modifier), (잘, Verb), (되, Ve...   \n",
       "2           3.0   [(예비, Noun), (회계사, Noun), (나, Noun), (다미, Noun)]   \n",
       "3           0.0                                     [(1등, Number)]   \n",
       "4           1.0             [(언, Modifier), (제바, Noun), (껴, Verb)]   \n",
       "\n",
       "                                     title_tokenized  \\\n",
       "0                                    [(해피뉴이어, Noun)]   \n",
       "1  [(2021년, Number), (새해, Noun), (복, Noun), (많이, ...   \n",
       "2  [(첫, Modifier), (글, Noun), (은, Josa), (내꼬, Noun)]   \n",
       "3             [(땡, Noun), (ㅎㅎㅎㅎㅎㅎㅎ, KoreanParticle)]   \n",
       "4  [(어디, Noun), (카운트, Noun), (다운, Noun), (하는, Ver...   \n",
       "\n",
       "                                  comments_tokenized  \\\n",
       "0  [(앗, Noun), (,, Punctuation), (성지, Noun), (다, ...   \n",
       "1                                      [(늦었네, Verb)]   \n",
       "2  [(ㄹㅇ, KoreanParticle), (1등, Number), (이네, Fore...   \n",
       "3                                                 []   \n",
       "4  [(232, Number), (번, Noun), (불교, Noun), (방송, No...   \n",
       "\n",
       "                           comments_writer_tokenized  \n",
       "0                                                 []  \n",
       "1  [(2, Number), (빠다, Noun), (ㅎㅎ, KoreanParticle)...  \n",
       "2                             [(ㅜㅜ, KoreanParticle)]  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "182b8e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_l/ssodam2021_tokenized_df.pkl','rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9c89b4",
   "metadata": {},
   "source": [
    "## BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050c3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 load\n",
    "with open('./data/stopwords.txt',encoding='utf-8') as f:\n",
    "    stopwords = f.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "8d74cd0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('잘', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n",
      "('못', 'VerbPrefix')\n",
      "('잘', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n",
      "('잘', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n",
      "('잘', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n"
     ]
    }
   ],
   "source": [
    "#형태소 체크\n",
    "limit = 0\n",
    "for row in df.total_tokens:\n",
    "    if limit > 10:\n",
    "        break\n",
    "    for tup in row:\n",
    "        if tup[1]=='VerbPrefix':\n",
    "            print(tup)\n",
    "            limit += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c7693a",
   "metadata": {},
   "source": [
    "### 익게2 데이터로부터 BoW 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "f7521b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Token's Bag of Words\n",
    "corpus = []\n",
    "for column in ['total_tokens']:\n",
    "    for text in df.loc[df['board']=='익게2',column]:\n",
    "        for word in text:\n",
    "            if word[1]=='Noun':\n",
    "                if word[0] not in stopwords:\n",
    "                    corpus.append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "851e406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_total = {}\n",
    "bow_total = []\n",
    "\n",
    "for token in corpus:\n",
    "    if token not in idx_total.keys():\n",
    "        idx_total[token] = len(idx_total)\n",
    "        bow_total.insert(len(idx_total)-1,1)\n",
    "    else:\n",
    "        bow_total[idx_total[token]] += 1\n",
    "        \n",
    "idx_key = list(idx_total.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9314b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/idx_total.pkl','rb') as f:\n",
    "    idx_total = pickle.load(f)\n",
    "with open('./data/bow_total.pkl','rb') as f:\n",
    "    bow_total = pickle.load(f)\n",
    "idx_key = list(idx_total.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29484a6a",
   "metadata": {},
   "source": [
    "### 익게2의 각 날짜별 BoW 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "4c42e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "#corpus for each day\n",
    "cfd = pd.DataFrame(columns=['upload_date','BoW'])\n",
    "\n",
    "for date in date_range(datetime(2021,1,1), datetime(2021,7,1)):\n",
    "    bow = np.zeros(len(idx_total.keys()))\n",
    "    \n",
    "    for token in df.loc[(df.board=='익게2') & (df.upload_date==date),'total_tokens']:\n",
    "        for word in token:\n",
    "            if (word[1]=='Noun') and (word[0] not in stopwords):\n",
    "                try:\n",
    "                    bow[idx_total[word[0]]] += 1\n",
    "                except:\n",
    "                    print('Error occured')\n",
    "                    \n",
    "    cfd.loc[len(cfd)] = [date, bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c46ed8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_l/cfd.pkl','rb') as f:\n",
    "    cfd = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04ca3b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.,  1., 29., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 41., ...,  0.,  0.,  0.],\n",
       "       [ 2.,  3., 42., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 3.,  1., 69., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  3., 53., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  3., 54., ...,  1.,  2.,  1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BoW 매트릭스\n",
    "BoW_mat = np.array([list(value) for value in cfd.BoW.values])\n",
    "BoW_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50053e",
   "metadata": {},
   "source": [
    "### 날짜별 인기 키워드 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdf59ba",
   "metadata": {},
   "source": [
    "#### 지수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc671c9",
   "metadata": {},
   "source": [
    "급상승 지수\n",
    "1. 전일 언급 횟수 a\n",
    "2. 당일 언급된 횟수 b\n",
    "3. 전체 기간 중 언급 횟수 c\n",
    "4. 가중치 w0, w1, w2\n",
    "5. 적당한 상수 K, 아주 작은 상수 E\n",
    "\n",
    "w0 x log(1+(b - a)/(a + K1)) + w1 x tanh( 0.1 x (b - K2) ) - w2 x c^E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a52f0971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    if x<0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# [w0, w1, w2, K1, K2, E]    \n",
    "W = [1,1,-0.0001,10,10,1.1]\n",
    "\n",
    "def _hot_point(a,b,c):\n",
    "    x0 = np.log(relu(((b-a)/(a+W[3])))+1)\n",
    "    x1 = np.tanh(0.1*(b-W[4]))\n",
    "    x2 = pow(c,W[5])\n",
    "    \n",
    "    return W[0]*x0, W[1]*x1, W[2]*x2\n",
    "    \n",
    "def hot_point(a,b,c):\n",
    "    x,y,z = _hot_point(a,b,c)\n",
    "    return x + y + z\n",
    "\n",
    "def pp2(a,b,idx):\n",
    "    c = BoW_mat[:,idx].sum()\n",
    "    x, y, z = _hot_point(a,b,c)\n",
    "    print(f'상승률지수 : {x}')\n",
    "    print(f'언급지수   : {y}')\n",
    "    print(f'패널티     : {z}')\n",
    "    print(f'최종값     : {x+y+z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c17be",
   "metadata": {},
   "source": [
    "#### 날짜/단어별 지수 columns 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f267c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 날짜/단어별 급상승 지수 계산\n",
    "cfd['points'] = [np.zeros(len(bow_total)) for i in range(len(cfd))]\n",
    "\n",
    "for i in range(1,len(BoW_mat)):\n",
    "    for j in range(len(bow_total)):\n",
    "        cfd.points[i][j] = hot_point(BoW_mat[i-1,j],BoW_mat[i,j],BoW_mat[:,j].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "de4c4425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.78060801, -0.77416411, -0.49338631, ..., -0.76169416,\n",
       "        -0.76180851, -0.76169416],\n",
       "       [-0.50072907, -0.35457346, -0.74149917, ..., -0.76169416,\n",
       "        -0.76180851, -0.76169416],\n",
       "       ...,\n",
       "       [-0.36101737, -0.63355764, -0.33941053, ..., -0.76169416,\n",
       "        -0.76180851, -0.76169416],\n",
       "       [-0.73531173, -0.44988364, -0.7579678 , ..., -0.76169416,\n",
       "        -0.76180851, -0.76169416],\n",
       "       [-0.73531173, -0.61693773, -0.74215272, ..., -0.62108769,\n",
       "        -0.48192957, -0.62108769]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Points 매트릭스\n",
    "Points = np.array([list(value) for value in cfd.points.values])\n",
    "Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63609ba",
   "metadata": {},
   "source": [
    "- __불용어 추가__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ea6964c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = ['데','뭐','게','익','층','실','곤','급','관','쪽','번','중','감','명','점','곳']\n",
    "for idx in [idx_total[key] for key in X_list]:\n",
    "    Points[:,idx] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daaa3f5",
   "metadata": {},
   "source": [
    "#### 일별 상위 10, 20개 키워드 추려내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "a3a93f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index 찾아 True로 저장할 ndarray 정의\n",
    "top10s = np.zeros(Points.shape, dtype=bool)\n",
    "top20s = np.zeros(Points.shape, dtype=bool)\n",
    "\n",
    "for i in range(1,len(Points)):\n",
    "    #날짜별 점수 상위 10개만 추림\n",
    "    limit_10 = np.sort(Points[i,:])[-10]\n",
    "    limit_20 = np.sort(Points[i,:])[-20]\n",
    "    for j in range(Points.shape[1]):\n",
    "        if Points[i,j]>=limit_20:\n",
    "            #상위 20개에 대해 True값으로 저장\n",
    "            top20s[i,j] = True\n",
    "            \n",
    "            if Points[i,j]>=limit_10:\n",
    "                #상위 10개에 대해 True값으로 저장\n",
    "                top10s[i,j] = True\n",
    "\n",
    "top10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "4789d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#일별 상위 10개 키워드 저장\n",
    "top10_keywords = [[idx_key[int(j)] for j in np.arange(top10s.shape[1])[top10s[i]]] for i in range(len(top10s))]\n",
    "#일별 상위 20개 키워드 저장\n",
    "top20_keywords = [[idx_key[int(j)] for j in np.arange(top20s.shape[1])[top20s[i]]] for i in range(len(top20s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d7d64eea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['선택',\n",
       " '얘',\n",
       " '배려',\n",
       " '경험',\n",
       " '룸메',\n",
       " '족보',\n",
       " '생리',\n",
       " '대학원',\n",
       " '서로',\n",
       " '헬스장',\n",
       " '밑',\n",
       " '약',\n",
       " '조언',\n",
       " '중대',\n",
       " '연구',\n",
       " '김치',\n",
       " '냉동',\n",
       " '감염',\n",
       " '모닝콜',\n",
       " '쓰레기']"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20_keywords[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da31ce83",
   "metadata": {},
   "source": [
    "#### 상위 10개 키워드 중 빈출 키워드 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd10be",
   "metadata": {},
   "source": [
    "__top10s__의 __BoW__ 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ffca7b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10s_idx = {}\n",
    "top10s_bow = []\n",
    "\n",
    "for day_keywords in top10_keywords:\n",
    "    for keyword in day_keywords:\n",
    "        if keyword not in top10s_idx.keys():\n",
    "            top10s_idx[keyword]=len(top10s_idx)\n",
    "            top10s_bow.insert(len(top10s_idx)-1,1)\n",
    "        else :\n",
    "            top10s_bow[top10s_idx[keyword]]+=1\n",
    "            \n",
    "top10s_bow = np.array(top10s_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce68771",
   "metadata": {},
   "source": [
    "__BoW__를 __DataFrame__화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "fd0c479f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>배려</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>룸메</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>생리</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>헬스장</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>조언</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword  count\n",
       "0      배려      1\n",
       "1      룸메      1\n",
       "2      생리      3\n",
       "3     헬스장      1\n",
       "4      조언      1"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10s_keys = [key for key, value in top10s_idx.items()]\n",
    "\n",
    "df_10bow = pd.DataFrame(np.array([top10s_keys,top10s_bow]).T,\n",
    "                      columns = ['keyword','count'])\n",
    "df_10bow['count'] = df_10bow['count'].astype(int)\n",
    "\n",
    "df_10bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "5299cba7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>연애</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>외모</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>변호사</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>문과</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>아빠</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>일본</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>의사</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>의대</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>대출</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>중국</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>휴학</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>동아리</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>동생</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>세대</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>헌혈</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>냉동</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>고양이</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>논문</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>정치</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>생일</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>조교</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>과외</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>이과</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>교회</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>대면</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>애플</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>투표</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>경제학</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>언니</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>삼성</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>수술</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>할머니</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>오빠</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>검사</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>수능</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>리트</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>학부</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>소득</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>피자</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>백신</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>정원</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>예수회</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>서울대</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>진이뽀</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>장학금</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>공대</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>선수</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>로욜라</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>마스크</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>학벌</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    keyword  count\n",
       "114      연애      8\n",
       "420      외모      8\n",
       "17      변호사      8\n",
       "69       문과      8\n",
       "577      아빠      7\n",
       "33       일본      7\n",
       "223      의사      7\n",
       "65       의대      6\n",
       "294      대출      6\n",
       "64       중국      6\n",
       "78       휴학      6\n",
       "256     동아리      6\n",
       "11       동생      6\n",
       "50       세대      6\n",
       "113      헌혈      6\n",
       "6        냉동      6\n",
       "257     고양이      6\n",
       "218      논문      6\n",
       "32       정치      5\n",
       "149      생일      5\n",
       "795      조교      5\n",
       "45       과외      5\n",
       "184      이과      5\n",
       "265      교회      5\n",
       "42       대면      5\n",
       "62       애플      5\n",
       "609      투표      5\n",
       "326     경제학      5\n",
       "168      언니      5\n",
       "290      삼성      5\n",
       "222      수술      5\n",
       "357     할머니      5\n",
       "772      오빠      5\n",
       "14       검사      5\n",
       "205      수능      5\n",
       "504      리트      5\n",
       "769      학부      5\n",
       "336      소득      4\n",
       "300      피자      4\n",
       "534      백신      4\n",
       "124      정원      4\n",
       "337     예수회      4\n",
       "310     서울대      4\n",
       "279     진이뽀      4\n",
       "125     장학금      4\n",
       "68       공대      4\n",
       "318      선수      4\n",
       "90      로욜라      4\n",
       "72      마스크      4\n",
       "698      학벌      4"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_10bow.sort_values('count',ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a972c",
   "metadata": {},
   "source": [
    "#### 상위 20개 키워드 중 빈출 키워드 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee8e16",
   "metadata": {},
   "source": [
    "__top20s__의 __BoW__ 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "04457c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20s_idx = {}\n",
    "top20s_bow = []\n",
    "\n",
    "for day_keywords in top20_keywords:\n",
    "    for keyword in day_keywords:\n",
    "        if keyword not in top20s_idx.keys():\n",
    "            top20s_idx[keyword]=len(top20s_idx)\n",
    "            top20s_bow.insert(len(top20s_idx)-1,1)\n",
    "        else :\n",
    "            top20s_bow[top20s_idx[keyword]]+=1\n",
    "            \n",
    "top20s_bow = np.array(top20s_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9c837",
   "metadata": {},
   "source": [
    "__BoW__를 __DataFrame__화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "2131527b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>선택</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>얘</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>배려</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경험</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>룸메</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword  count\n",
       "0      선택      3\n",
       "1       얘      1\n",
       "2      배려      2\n",
       "3      경험      1\n",
       "4      룸메      1"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20s_keys = [key for key, value in top20s_idx.items()]\n",
    "\n",
    "df_20bow = pd.DataFrame(np.array([top20s_keys,top20s_bow]).T,\n",
    "                      columns = ['keyword','count'])\n",
    "df_20bow['count'] = df_20bow['count'].astype(int)\n",
    "\n",
    "df_20bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "96b680e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>변호사</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>결혼</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>문과</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>휴학</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>아빠</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>외모</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>동생</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>연애</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>미국</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>팬</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>중국</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>학부</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>일본</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>총장</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>곡</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>병원</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>수능</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>조교</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>대면</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>철학</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>경찰</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>고양이</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>복전</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>합격</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>세대</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>애플</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>동아리</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>사건</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>공대</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>이과</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>담배</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>공감</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>경제학</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>논문</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>수술</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>주식</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>카페</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>축하</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>언니</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>의사</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>족보</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>방송</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>키</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>부모님</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>오빠</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>형</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>폰</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>선배</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>부동산</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>코인</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword  count\n",
       "35       변호사     14\n",
       "178       결혼     13\n",
       "137       문과     12\n",
       "40        휴학     12\n",
       "271       아빠     12\n",
       "70        외모     12\n",
       "24        동생     12\n",
       "220       연애     11\n",
       "63        미국     11\n",
       "518        팬     10\n",
       "125       중국     10\n",
       "448       학부     10\n",
       "69        일본     10\n",
       "703       총장     10\n",
       "976        곡      9\n",
       "408       병원      9\n",
       "80        수능      9\n",
       "509       조교      9\n",
       "47        대면      9\n",
       "107       철학      9\n",
       "38        경찰      9\n",
       "468      고양이      9\n",
       "135       복전      9\n",
       "206       합격      9\n",
       "97        세대      8\n",
       "122       애플      8\n",
       "462      동아리      8\n",
       "73        사건      8\n",
       "133       공대      8\n",
       "142       이과      8\n",
       "147       담배      8\n",
       "774       공감      8\n",
       "402      경제학      8\n",
       "333       논문      8\n",
       "405       수술      8\n",
       "118       주식      8\n",
       "88        카페      8\n",
       "296       축하      8\n",
       "317       언니      8\n",
       "36        의사      8\n",
       "5         족보      8\n",
       "1080      방송      7\n",
       "880        키      7\n",
       "26       부모님      7\n",
       "464       오빠      7\n",
       "207        형      7\n",
       "30         폰      7\n",
       "353       선배      7\n",
       "75       부동산      7\n",
       "1020      코인      7"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_20bow.sort_values('count',ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffcb520",
   "metadata": {},
   "source": [
    "__가중치 조정 기록 및 결과 저장__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "351d5346",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pickle\n",
    "f_idx = '2nd'\n",
    "with open(f'{f_idx}_weights.pkl','wb') as f:\n",
    "    pickle.dump(W,f)\n",
    "with open(f'{f_idx}_cfd.pkl','wb') as f:\n",
    "    pickle.dump(cfd,f)\n",
    "with open(f'{f_idx}_10bow.pkl','wb') as f:\n",
    "    pickle.dump(df_10bow,f)\n",
    "with open(f'{f_idx}_20bow.pkl','wb') as f:\n",
    "    pickle.dump(df_20bow,f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107201f3",
   "metadata": {},
   "source": [
    "__불러오기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e02369e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/10bow.pkl','rb') as f:\n",
    "    df_10bow = pickle.load(f)\n",
    "with open('./data/20bow.pkl','rb') as f:\n",
    "    df_20bow = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebaad90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f63073",
   "metadata": {},
   "source": [
    "## 월별 인기 키워드 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d76da6e",
   "metadata": {},
   "source": [
    "### 작년 12월 데이터를 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f521e03d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>board</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>writer</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>view</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_writer</th>\n",
       "      <th>comments_cnt</th>\n",
       "      <th>popularity</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>comment_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>813032</td>\n",
       "      <td>익게2</td>\n",
       "      <td>2020년 파이팅!!</td>\n",
       "      <td>모두들 파이팅</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>1375</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>['올 첫글 ㅋㅋ', '아 너 뭔데 나보다 일찍 썼냐ㅡㅡ추천이나 먹어라', '첫글 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>[('파이팅', 'Noun')]</td>\n",
       "      <td>[('2020년', 'Number'), ('파이팅', 'Noun'), ('!!', ...</td>\n",
       "      <td>[(\"['\", 'Punctuation'), ('올', 'Verb'), ('첫', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>813033</td>\n",
       "      <td>익게2</td>\n",
       "      <td>새해</td>\n",
       "      <td>ㅊㅊ</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[('ㅊㅊ', 'KoreanParticle')]</td>\n",
       "      <td>[('새해', 'Noun')]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>813034</td>\n",
       "      <td>익게2</td>\n",
       "      <td>2020 첫 글 ㄱㅈㅇ</td>\n",
       "      <td>ㅇㅇ</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[('ㅇㅇ', 'KoreanParticle')]</td>\n",
       "      <td>[('2020', 'Number'), ('첫', 'Noun'), ('글', 'Nou...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>813037</td>\n",
       "      <td>익게2</td>\n",
       "      <td>ㅅㅅ</td>\n",
       "      <td>ㅅㅅ</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[('ㅅㅅ', 'KoreanParticle')]</td>\n",
       "      <td>[('ㅅㅅ', 'KoreanParticle')]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>813038</td>\n",
       "      <td>익게2</td>\n",
       "      <td>스물넷이다</td>\n",
       "      <td>뭐했다고 벌써</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>['어? 너두?', '난방금전까지 스물넷..']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[('뭐', 'Noun'), ('했다고', 'Verb'), ('벌써', 'Noun')]</td>\n",
       "      <td>[('스물넷', 'Noun'), ('이다', 'Josa')]</td>\n",
       "      <td>[(\"['\", 'Punctuation'), ('?', 'Punctuation'), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num board         title     text writer upload_date upload_time  view  \\\n",
       "0  813032   익게2   2020년 파이팅!!  모두들 파이팅     익명  2020-01-01       00:00  1375   \n",
       "1  813033   익게2            새해       ㅊㅊ     익명  2020-01-01       00:00    97   \n",
       "2  813034   익게2  2020 첫 글 ㄱㅈㅇ       ㅇㅇ     익명  2020-01-01       00:00   128   \n",
       "3  813037   익게2            ㅅㅅ       ㅅㅅ     익명  2020-01-01       00:00    70   \n",
       "4  813038   익게2         스물넷이다  뭐했다고 벌써     익명  2020-01-01       00:00   124   \n",
       "\n",
       "   likes  dislikes                                           comments  \\\n",
       "0    168         0  ['올 첫글 ㅋㅋ', '아 너 뭔데 나보다 일찍 썼냐ㅡㅡ추천이나 먹어라', '첫글 ...   \n",
       "1      2         0                                                NaN   \n",
       "2      1         0                                                NaN   \n",
       "3      0         0                                                NaN   \n",
       "4      3         0                         ['어? 너두?', '난방금전까지 스물넷..']   \n",
       "\n",
       "  comments_writer  comments_cnt  popularity  \\\n",
       "0             NaN            14           1   \n",
       "1             NaN             0           0   \n",
       "2             NaN             0           0   \n",
       "3             NaN             0           0   \n",
       "4             NaN             2           0   \n",
       "\n",
       "                                     text_tokenized  \\\n",
       "0                                 [('파이팅', 'Noun')]   \n",
       "1                        [('ㅊㅊ', 'KoreanParticle')]   \n",
       "2                        [('ㅇㅇ', 'KoreanParticle')]   \n",
       "3                        [('ㅅㅅ', 'KoreanParticle')]   \n",
       "4  [('뭐', 'Noun'), ('했다고', 'Verb'), ('벌써', 'Noun')]   \n",
       "\n",
       "                                     title_tokenized  \\\n",
       "0  [('2020년', 'Number'), ('파이팅', 'Noun'), ('!!', ...   \n",
       "1                                   [('새해', 'Noun')]   \n",
       "2  [('2020', 'Number'), ('첫', 'Noun'), ('글', 'Nou...   \n",
       "3                         [('ㅅㅅ', 'KoreanParticle')]   \n",
       "4                  [('스물넷', 'Noun'), ('이다', 'Josa')]   \n",
       "\n",
       "                                   comment_tokenized  \n",
       "0  [(\"['\", 'Punctuation'), ('올', 'Verb'), ('첫', '...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  [(\"['\", 'Punctuation'), ('?', 'Punctuation'), ...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_20 = pd.read_csv('./data_l/ssodam2020_all_tokened_final.csv', encoding='utf-8')\n",
    "#날짜 데이터를 datetime으로.\n",
    "tokens_20.upload_date = pd.to_datetime(tokens_20.upload_date)\n",
    "tokens_20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ad24deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_list_from_str(msg):\n",
    "    try :\n",
    "        return [tuple([re.sub(\"'\",'',y) for y in re.findall('\\'.*?\\'',x)]) for x in re.findall('\\(.*?\\)',msg)]\n",
    "    except :\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6b04347c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>board</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>writer</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>view</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_writer</th>\n",
       "      <th>comments_cnt</th>\n",
       "      <th>popularity</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>comments_writer_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161968</th>\n",
       "      <td>1058725</td>\n",
       "      <td>익게2</td>\n",
       "      <td>엽기붕어빵ㅋㅋ</td>\n",
       "      <td>붕어빵10개 1만 6천원ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>00:06</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['ㅈ같은 프리미엄화 좀 하지마라ㅠ']</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[(붕어빵, Noun), (10, Number), (개, Noun), (1만, Nu...</td>\n",
       "      <td>[(엽기, Noun), (붕어빵, Noun), (ㅋㅋ, KoreanParticle)]</td>\n",
       "      <td>[(\", ,), (ㅈ, KoreanParticle), (같은, Adjective),...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161969</th>\n",
       "      <td>1058727</td>\n",
       "      <td>익게2</td>\n",
       "      <td>다미들 푸우욱 잘 자라옹</td>\n",
       "      <td>졸리다냥</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>00:07</td>\n",
       "      <td>143</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(졸리다냥, Verb)]</td>\n",
       "      <td>[(푸우, Noun), (욱, Noun), (자라, Noun), (옹, Noun)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161970</th>\n",
       "      <td>1058728</td>\n",
       "      <td>익게2</td>\n",
       "      <td>나 시 써봤는데 어때</td>\n",
       "      <td>거울 속에 한 사내가 서있다사내는 거울 속 자신의 모습이 볼품없다사내는 그런 자신의...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>00:08</td>\n",
       "      <td>245</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>['거사사 너때 때멈 살그... 라고요???? 말이 너무 심하시네요!! 비추드립니다...</td>\n",
       "      <td>['뭐라는거야ㅋㅋㅋㅋ', '저도 쓰고보니 이상 거울이랑 윤동주 자화상이랑 살짝 섞인...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[(거울, Noun), (속, Noun), (사내, Noun), (서있다, Verb...</td>\n",
       "      <td>[(시, Noun), (써, Verb), (봤는데, Verb)]</td>\n",
       "      <td>[(\", ,), (사사, Noun), (때멈, Noun), (살그, Noun), (...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161971</th>\n",
       "      <td>1058729</td>\n",
       "      <td>익게2</td>\n",
       "      <td>민법 한번 공부해 보고싶은데.. 인강 뭐 들어야할지 모르겠어ㅜ</td>\n",
       "      <td>세무사 민법이랑                                법무사 민법...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>00:09</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>['로스쿨 민법 어때? - 로스쿨다미', '자기계발용으로는 적합한지 모르겠지만ㅋㅋㅋ...</td>\n",
       "      <td>['헤헤 그거 들어볼까?? 혹시 추천 강사님 물어봐도돼?ㅎ', 'ㅋㅋㅋㅋ']</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[(세무사, Noun), (민법, Noun), (법무사, Noun), (민법, No...</td>\n",
       "      <td>[(민법, Noun), (한번, Noun), (공부, Noun), (해, Verb)...</td>\n",
       "      <td>[(\", ,), (로스쿨, Noun), (민법, Noun), (?, Punctuat...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161972</th>\n",
       "      <td>1058730</td>\n",
       "      <td>익게2</td>\n",
       "      <td>가정내에서도 결국 사회생활하듯이 살아야할까</td>\n",
       "      <td>나는 엄마랑 감정적으로 친해지고 싶지 않아말하는 관점이 너어어어무 다르고 남 험담을...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>00:10</td>\n",
       "      <td>376</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['솔직히 내가 그 상황이 아니니까 답은 알 수 없지만, 나라면 안 드려 이번에 드...</td>\n",
       "      <td>['진짜 고민이야 ㅠㅠ 정말 오늘 아침도 또 아빠욕하길래 못들어주겟다고 하고 나왔는...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[(엄마, Noun), (랑, Josa), (감정, Noun), (적, Suffix...</td>\n",
       "      <td>[(가정, Noun), (내, Noun), (에서도, Josa), (사회생활, No...</td>\n",
       "      <td>[(\", ,), (솔직히, Adjective), (내, Noun), (상황, Nou...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            num board                               title  \\\n",
       "161968  1058725   익게2                             엽기붕어빵ㅋㅋ   \n",
       "161969  1058727   익게2                       다미들 푸우욱 잘 자라옹   \n",
       "161970  1058728   익게2                         나 시 써봤는데 어때   \n",
       "161971  1058729   익게2  민법 한번 공부해 보고싶은데.. 인강 뭐 들어야할지 모르겠어ㅜ   \n",
       "161972  1058730   익게2             가정내에서도 결국 사회생활하듯이 살아야할까   \n",
       "\n",
       "                                                     text writer upload_date  \\\n",
       "161968  붕어빵10개 1만 6천원ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ...     익명  2020-12-01   \n",
       "161969                                               졸리다냥     익명  2020-12-01   \n",
       "161970  거울 속에 한 사내가 서있다사내는 거울 속 자신의 모습이 볼품없다사내는 그런 자신의...     익명  2020-12-01   \n",
       "161971  세무사 민법이랑                                법무사 민법...     익명  2020-12-01   \n",
       "161972  나는 엄마랑 감정적으로 친해지고 싶지 않아말하는 관점이 너어어어무 다르고 남 험담을...     익명  2020-12-01   \n",
       "\n",
       "       upload_time  view  likes  dislikes  \\\n",
       "161968       00:06   124      0         0   \n",
       "161969       00:07   143      7         0   \n",
       "161970       00:08   245      7         0   \n",
       "161971       00:09   221      0         2   \n",
       "161972       00:10   376     11         0   \n",
       "\n",
       "                                                 comments  \\\n",
       "161968                              ['ㅈ같은 프리미엄화 좀 하지마라ㅠ']   \n",
       "161969                                                      \n",
       "161970  ['거사사 너때 때멈 살그... 라고요???? 말이 너무 심하시네요!! 비추드립니다...   \n",
       "161971  ['로스쿨 민법 어때? - 로스쿨다미', '자기계발용으로는 적합한지 모르겠지만ㅋㅋㅋ...   \n",
       "161972  ['솔직히 내가 그 상황이 아니니까 답은 알 수 없지만, 나라면 안 드려 이번에 드...   \n",
       "\n",
       "                                          comments_writer  comments_cnt  \\\n",
       "161968                                                                1   \n",
       "161969                                                                0   \n",
       "161970  ['뭐라는거야ㅋㅋㅋㅋ', '저도 쓰고보니 이상 거울이랑 윤동주 자화상이랑 살짝 섞인...             8   \n",
       "161971         ['헤헤 그거 들어볼까?? 혹시 추천 강사님 물어봐도돼?ㅎ', 'ㅋㅋㅋㅋ']             8   \n",
       "161972  ['진짜 고민이야 ㅠㅠ 정말 오늘 아침도 또 아빠욕하길래 못들어주겟다고 하고 나왔는...            11   \n",
       "\n",
       "        popularity                                     text_tokenized  \\\n",
       "161968           0  [(붕어빵, Noun), (10, Number), (개, Noun), (1만, Nu...   \n",
       "161969           0                                     [(졸리다냥, Verb)]   \n",
       "161970           0  [(거울, Noun), (속, Noun), (사내, Noun), (서있다, Verb...   \n",
       "161971           0  [(세무사, Noun), (민법, Noun), (법무사, Noun), (민법, No...   \n",
       "161972           0  [(엄마, Noun), (랑, Josa), (감정, Noun), (적, Suffix...   \n",
       "\n",
       "                                          title_tokenized  \\\n",
       "161968    [(엽기, Noun), (붕어빵, Noun), (ㅋㅋ, KoreanParticle)]   \n",
       "161969     [(푸우, Noun), (욱, Noun), (자라, Noun), (옹, Noun)]   \n",
       "161970                [(시, Noun), (써, Verb), (봤는데, Verb)]   \n",
       "161971  [(민법, Noun), (한번, Noun), (공부, Noun), (해, Verb)...   \n",
       "161972  [(가정, Noun), (내, Noun), (에서도, Josa), (사회생활, No...   \n",
       "\n",
       "                                       comments_tokenized  \\\n",
       "161968  [(\", ,), (ㅈ, KoreanParticle), (같은, Adjective),...   \n",
       "161969                                                 []   \n",
       "161970  [(\", ,), (사사, Noun), (때멈, Noun), (살그, Noun), (...   \n",
       "161971  [(\", ,), (로스쿨, Noun), (민법, Noun), (?, Punctuat...   \n",
       "161972  [(\", ,), (솔직히, Adjective), (내, Noun), (상황, Nou...   \n",
       "\n",
       "       comments_writer_tokenized  \n",
       "161968                        []  \n",
       "161969                        []  \n",
       "161970                        []  \n",
       "161971                        []  \n",
       "161972                        []  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12월 데이터만 추려내어 처리\n",
    "tokens_20_12 = tokens_20[tokens_20.upload_date.apply(lambda x: True if x.month==12 else False)]\n",
    "tokens_20_12 = tokens_20_12.fillna('')\n",
    "tokens_20_12.text_tokenized = tokens_20_12.text_tokenized.apply(lambda x: get_noun_list_from_str(x))\n",
    "tokens_20_12.title_tokenized = tokens_20_12.title_tokenized.apply(lambda x: get_noun_list_from_str(x))\n",
    "tokens_20_12.comment_tokenized = tokens_20_12.comment_tokenized.apply(lambda x: get_noun_list_from_str(x))\n",
    "tokens_20_12['comments_writer_tokenized'] = [[] for _ in range(len(tokens_20_12))]\n",
    "tokens_20_12.rename(columns={'comment_tokenized':'comments_tokenized'},inplace=True)\n",
    "tokens_20_12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2ce77b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num', 'board', 'title', 'text', 'writer', 'upload_date', 'upload_time',\n",
       "       'view', 'likes', 'dislikes', 'comments', 'comments_writer',\n",
       "       'comments_cnt', 'popularity', 'text_tokenized', 'title_tokenized',\n",
       "       'comments_tokenized', 'comments_writer_tokenized'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_20_12.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a84bb8e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num', 'board', 'title', 'text', 'writer', 'upload_date', 'upload_time',\n",
       "       'view', 'likes', 'dislikes', 'comments', 'comments_writer',\n",
       "       'comments_cnt', 'text_tokenized', 'title_tokenized',\n",
       "       'comments_tokenized', 'comments_writer_tokenized'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac5a2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([tokens_20_12,df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc0b984",
   "metadata": {},
   "source": [
    "### 익게2 12월~6월간 BoW 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f65218",
   "metadata": {},
   "source": [
    "전체 데이터프레임을 월별로 groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f838f903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upload_month': [12, 1, 2, 3, 4, 5, 6],\n",
       " 'title_tokenized': [[], [], [], [], [], [], []],\n",
       " 'text_tokenized': [[], [], [], [], [], [], []],\n",
       " 'comments_tokenized': [[], [], [], [], [], [], []],\n",
       " 'comments_writer_tokenized': [[], [], [], [], [], [], []]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm_dict = dict.fromkeys(['upload_month','title_tokenized','text_tokenized','comments_tokenized','comments_writer_tokenized'])\n",
    "\n",
    "for key in cfm_dict.keys():\n",
    "    if key == 'upload_month':\n",
    "        cfm_dict[key] = [12]+[i+1 for i in range(6)]\n",
    "    else:\n",
    "        cfm_dict[key] = [[] for i in range(7)]\n",
    "\n",
    "cfm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "a7beb5fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index : 9999 processing...\n",
      "index : 19999 processing...\n",
      "index : 29999 processing...\n",
      "index : 39999 processing...\n",
      "index : 49999 processing...\n",
      "index : 59999 processing...\n",
      "index : 69999 processing...\n"
     ]
    }
   ],
   "source": [
    "_df = df2.loc[df2.board=='익게2']\n",
    "\n",
    "for idx in range(len(_df)):\n",
    "    if (idx+1)%10000==0:\n",
    "        print('index :',idx,'processing...')\n",
    "    row = _df.iloc[idx]\n",
    "    #데이터프레임으로부터 월 인덱스 탐색\n",
    "    month = 0 if row.upload_date.month==12 else row.upload_date.month\n",
    "    #칼럼별 해당 인덱스에 해당되는 토큰 저장\n",
    "    #50단어가 넘는 장문의 글은 제거하고 댓글과 제목만 남김.\n",
    "    if len(row.text_tokenized) > 50:\n",
    "        pass\n",
    "    else :\n",
    "        cfm_dict['text_tokenized'][month] += row.text_tokenized\n",
    "    cfm_dict['title_tokenized'][month] += row.title_tokenized\n",
    "    cfm_dict['comments_tokenized'][month] += row.comments_tokenized\n",
    "    cfm_dict['comments_writer_tokenized'][month] += row.comments_writer_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "4cb9a6a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upload_month</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>comments_writer_tokenized</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>[(엽기, Noun), (붕어빵, Noun), (ㅋㅋ, KoreanParticle)...</td>\n",
       "      <td>[(붕어빵, Noun), (10, Number), (개, Noun), (1만, Nu...</td>\n",
       "      <td>[(\", ,), (ㅈ, KoreanParticle), (같은, Adjective),...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(엽기, Noun), (붕어빵, Noun), (ㅋㅋ, KoreanParticle)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[(해피뉴이어, Noun), (2021년, Number), (새해, Noun), (...</td>\n",
       "      <td>[(2021년, Number), (은, Foreign), (모두, Noun), (행...</td>\n",
       "      <td>[(앗, Noun), (,, Punctuation), (성지, Noun), (다, ...</td>\n",
       "      <td>[(2, Number), (빠다, Noun), (ㅎㅎ, KoreanParticle)...</td>\n",
       "      <td>[(해피뉴이어, Noun), (2021년, Number), (새해, Noun), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[(않이, Verb), (모해, Noun), (따고, Verb), (벌써, Noun...</td>\n",
       "      <td>[(2월, Number), (이냐, Foreign), (지인, Noun), (이, ...</td>\n",
       "      <td>[(난, Noun), (마카롱, Noun), (세트, Noun), (했아, Verb...</td>\n",
       "      <td>[(오, Noun), (좋다, Adjective), (고마워, Adjective),...</td>\n",
       "      <td>[(않이, Verb), (모해, Noun), (따고, Verb), (벌써, Noun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[(약, Noun), (19, Number), (저가, Noun), (코스프레, N...</td>\n",
       "      <td>[(취미, Noun), (로, Josa), (배워, Verb), (보고싶어, Ver...</td>\n",
       "      <td>[(진짜, Noun), (이형, Noun), (꾸준하네, Adjective), (,...</td>\n",
       "      <td>[(고마워, Adjective), (덕분, Noun), (에, Josa), (등업,...</td>\n",
       "      <td>[(약, Noun), (19, Number), (저가, Noun), (코스프레, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[(만우절, Noun), (이, Josa), (벌써, Noun), (끝나, Verb...</td>\n",
       "      <td>[(아쉽다, Adjective), (아쉬워, Adjective), (연애, Noun...</td>\n",
       "      <td>[(스타트, Noun), (가, Josa), (좋구만, Adjective), (ㄱㄱ...</td>\n",
       "      <td>[(나, Noun), (에게, Josa), (있다고, Adjective), (,, ...</td>\n",
       "      <td>[(만우절, Noun), (이, Josa), (벌써, Noun), (끝나, Verb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[(2021년, Number), (5월, Number), (첫, Noun), (글,...</td>\n",
       "      <td>[(새로운, Adjective), (달도, Noun), (희망, Noun), (차게...</td>\n",
       "      <td>[(뭔, Modifier), (데, Noun), (벌써, Noun), (5월, Nu...</td>\n",
       "      <td>[(아, Exclamation), (진짜, Noun), (로, Josa), (그럼,...</td>\n",
       "      <td>[(2021년, Number), (5월, Number), (첫, Noun), (글,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[(지금, Noun), (퇴근, Noun), (하는, Verb), (길, Noun)...</td>\n",
       "      <td>[(입사, Noun), (1년, Number), (아직, Adverb), (안된, ...</td>\n",
       "      <td>[(화이팅, Noun), (시간, Noun), (이, Josa), (지나면, Ver...</td>\n",
       "      <td>[(전망, Noun), (좋고, Adjective), (과제, Noun), (하기,...</td>\n",
       "      <td>[(지금, Noun), (퇴근, Noun), (하는, Verb), (길, Noun)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   upload_month                                    title_tokenized  \\\n",
       "0            12  [(엽기, Noun), (붕어빵, Noun), (ㅋㅋ, KoreanParticle)...   \n",
       "1             1  [(해피뉴이어, Noun), (2021년, Number), (새해, Noun), (...   \n",
       "2             2  [(않이, Verb), (모해, Noun), (따고, Verb), (벌써, Noun...   \n",
       "3             3  [(약, Noun), (19, Number), (저가, Noun), (코스프레, N...   \n",
       "4             4  [(만우절, Noun), (이, Josa), (벌써, Noun), (끝나, Verb...   \n",
       "5             5  [(2021년, Number), (5월, Number), (첫, Noun), (글,...   \n",
       "6             6  [(지금, Noun), (퇴근, Noun), (하는, Verb), (길, Noun)...   \n",
       "\n",
       "                                      text_tokenized  \\\n",
       "0  [(붕어빵, Noun), (10, Number), (개, Noun), (1만, Nu...   \n",
       "1  [(2021년, Number), (은, Foreign), (모두, Noun), (행...   \n",
       "2  [(2월, Number), (이냐, Foreign), (지인, Noun), (이, ...   \n",
       "3  [(취미, Noun), (로, Josa), (배워, Verb), (보고싶어, Ver...   \n",
       "4  [(아쉽다, Adjective), (아쉬워, Adjective), (연애, Noun...   \n",
       "5  [(새로운, Adjective), (달도, Noun), (희망, Noun), (차게...   \n",
       "6  [(입사, Noun), (1년, Number), (아직, Adverb), (안된, ...   \n",
       "\n",
       "                                  comments_tokenized  \\\n",
       "0  [(\", ,), (ㅈ, KoreanParticle), (같은, Adjective),...   \n",
       "1  [(앗, Noun), (,, Punctuation), (성지, Noun), (다, ...   \n",
       "2  [(난, Noun), (마카롱, Noun), (세트, Noun), (했아, Verb...   \n",
       "3  [(진짜, Noun), (이형, Noun), (꾸준하네, Adjective), (,...   \n",
       "4  [(스타트, Noun), (가, Josa), (좋구만, Adjective), (ㄱㄱ...   \n",
       "5  [(뭔, Modifier), (데, Noun), (벌써, Noun), (5월, Nu...   \n",
       "6  [(화이팅, Noun), (시간, Noun), (이, Josa), (지나면, Ver...   \n",
       "\n",
       "                           comments_writer_tokenized  \\\n",
       "0                                                 []   \n",
       "1  [(2, Number), (빠다, Noun), (ㅎㅎ, KoreanParticle)...   \n",
       "2  [(오, Noun), (좋다, Adjective), (고마워, Adjective),...   \n",
       "3  [(고마워, Adjective), (덕분, Noun), (에, Josa), (등업,...   \n",
       "4  [(나, Noun), (에게, Josa), (있다고, Adjective), (,, ...   \n",
       "5  [(아, Exclamation), (진짜, Noun), (로, Josa), (그럼,...   \n",
       "6  [(전망, Noun), (좋고, Adjective), (과제, Noun), (하기,...   \n",
       "\n",
       "                                        total_tokens  \n",
       "0  [(엽기, Noun), (붕어빵, Noun), (ㅋㅋ, KoreanParticle)...  \n",
       "1  [(해피뉴이어, Noun), (2021년, Number), (새해, Noun), (...  \n",
       "2  [(않이, Verb), (모해, Noun), (따고, Verb), (벌써, Noun...  \n",
       "3  [(약, Noun), (19, Number), (저가, Noun), (코스프레, N...  \n",
       "4  [(만우절, Noun), (이, Josa), (벌써, Noun), (끝나, Verb...  \n",
       "5  [(2021년, Number), (5월, Number), (첫, Noun), (글,...  \n",
       "6  [(지금, Noun), (퇴근, Noun), (하는, Verb), (길, Noun)...  "
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm = pd.DataFrame(cfm_dict)\n",
    "cfm['total_tokens'] = cfm.title_tokenized + cfm.text_tokenized + cfm.comments_tokenized + cfm.comments_writer_tokenized\n",
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "0cdb9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Token's Bag of Words\n",
    "corpus_extended = []\n",
    "for column in ['total_tokens']:\n",
    "    for text in cfm[column]:\n",
    "        for word in text:\n",
    "            try:\n",
    "                if word[1]=='Noun':\n",
    "                    if word[0] not in stopwords:\n",
    "                        corpus_extended.append(word[0])\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "c0b3f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_extended = {}\n",
    "bow_extended = []\n",
    "\n",
    "for token in corpus_extended:\n",
    "    if token not in idx_extended.keys():\n",
    "        idx_extended[token] = len(idx_extended)\n",
    "        bow_extended.insert(len(idx_extended)-1,1)\n",
    "    else:\n",
    "        bow_extended[idx_extended[token]] += 1\n",
    "        \n",
    "idx_extended_key = list(idx_extended.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b98b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open('./data/idx_extended.pkl','wb') as f:\n",
    "    pickle.dump(idx_extended,f)\n",
    "with open('./data/bow_extended.pkl','wb') as f:\n",
    "    pickle.dump(bow_extended,f)\n",
    "'''\n",
    "with open('./data/idx_extended.pkl','rb') as f:\n",
    "    idx_extended = pickle.load(f)\n",
    "with open('./data/bow_extended.pkl','rb') as f:\n",
    "    bow_extended = pickle.load(f)\n",
    "idx_extended_key = list(idx_extended.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4651aba",
   "metadata": {},
   "source": [
    "###  Word별 게시글 수 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "id": "f1960ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_words(x):\n",
    "    output = []\n",
    "    for token in x:\n",
    "        if len(token)>1:\n",
    "            output.append(token[0])\n",
    "        else:\n",
    "            pass\n",
    "    return output\n",
    "\n",
    "df2['total_tokens'] = df2.title_tokenized + df2.text_tokenized + df2.comments_tokenized + df2.comments_writer_tokenized\n",
    "df2['_total_tokens'] = df2['total_tokens'].apply(lambda x : return_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1554,
   "id": "41822988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "month_filter = []\n",
    "for i in range(7):\n",
    "    if i==0:\n",
    "        month_filter.append((datetime(2020,12,1)<=df2.upload_date) & (df2.upload_date<datetime(2021,1,1)) & (df2.board=='익게2'))\n",
    "    else:\n",
    "        month_filter.append((datetime(2021,i,1)<=df2.upload_date) & (df2.upload_date<datetime(2021,i+1,1)) & (df2.board=='익게2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca81f4",
   "metadata": {},
   "source": [
    "import time\n",
    "\n",
    "posts_extended = np.zeros((7,len(idx_extended)))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, word in enumerate(idx_extended):\n",
    "    if i%1000 == 0:\n",
    "        print(i,'번째 단어 처리중...',i-1000,'번째로부터',time.time()-start_time,'초 경과.')\n",
    "        start_time = time.time()\n",
    "    _all_posts = df2._total_tokens.apply(lambda x: True if word in x else False)\n",
    "    for j in range(0,7):\n",
    "        posts_extended[j,i] = _all_posts[month_filter[j]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccda7497",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/posts_extended.pkl','rb') as f:\n",
    "    posts_extended = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b6e137",
   "metadata": {},
   "source": [
    "### 익게2 데이터로부터 월별 BoW 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc8a31",
   "metadata": {},
   "source": [
    "__BoW 생성__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "e341fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bows = []\n",
    "\n",
    "for month in range(7):\n",
    "    bow = np.zeros(len(idx_extended.keys()))\n",
    "    \n",
    "    for word in cfm.iloc[month].total_tokens:\n",
    "        #()등 빈 단어들은 패스\n",
    "        if len(word)!=2:\n",
    "            continue\n",
    "        if (word[1]=='Noun') and (word[0] not in stopwords):\n",
    "            try:\n",
    "                bow[idx_extended[word[0]]] += 1\n",
    "            except:\n",
    "                print('Error occured')\n",
    "                \n",
    "    bows.append(bow)\n",
    "\n",
    "cfm['BoW'] = bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e8d16ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "with open('./data_l/cfm.pkl','wb') as f:\n",
    "    pickle.dump(cfm,f)\n",
    "'''\n",
    "with open('./data_l/cfm.pkl','rb') as f:\n",
    "    cfm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c110e5c",
   "metadata": {},
   "source": [
    "### 급상승 지수 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd31e173",
   "metadata": {},
   "source": [
    "idx_total & bow_total로부터 각 월마다 키워드별 급상승지수 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48e183",
   "metadata": {},
   "source": [
    "월별 급상승 지수\n",
    "1. 전월 언급 횟수 a\n",
    "2. 당월 언급된 횟수 b\n",
    "3. 당월 게시글 작성 횟수 c\n",
    "4. 전체 기간(2020.12~2021.6) 중 언급 횟수 d\n",
    "5. 가중치 w0, w1, w2\n",
    "6. 적당한 상수 K, 아주 작은 상수 E\n",
    "\n",
    "w0 x log(1+(b - a)/(a + K1)) + w1 x tanh( 0.1 x (b - K2) ) - w2 x c^E\n",
    "\n",
    "- 월별 등장 횟수는 일별 등장 횟수에 비해 양에 대한 기준치를 높여야 하므로, K1과 K2를 상향 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "id": "890d2026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6., 16.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 4.,  6.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 2.,  2.,  0., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 1.,  5.,  3., ...,  0.,  0.,  0.],\n",
       "       [ 9.,  6.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 3.,  6.,  1., ...,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 1021,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "id": "35611a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 36., 194.,   6., ...,   0.,   0.,   0.],\n",
       "       [ 18.,  29.,   4., ...,   0.,   0.,   0.],\n",
       "       [  4.,  20.,   0., ...,   0.,   0.,   0.],\n",
       "       ...,\n",
       "       [  3.,  38.,   8., ...,   0.,   0.,   0.],\n",
       "       [ 22.,  18.,   3., ...,   0.,   0.,   0.],\n",
       "       [ 12.,  39.,   3., ...,   3.,   3.,   3.]])"
      ]
     },
     "execution_count": 1027,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BoW_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "fa1290d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    if x<0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def sigmoid2(x):\n",
    "    return 1/( 1+np.exp( -(x-5) ) )\n",
    "\n",
    "#   [w0,   w1,  w2,  w3,    w4,  K1,  K2, K3, E]    \n",
    "W = [1.5, 0.3, 1.3, 0.5, -0.05, 10, 100, 10, 1.002]\n",
    "\n",
    "def _hot_point3(a,b,c,d,e):\n",
    "    x0 = sigmoid2((b-a)/(a+W[5]))\n",
    "    x1 = np.tanh(0.05*(b-W[6]))-0.5\n",
    "    x2 = sigmoid2((d-c)/(c+W[7]))\n",
    "    x3 = np.tanh(0.1*(d-20))-0.7\n",
    "    x4 = pow(W[8],e) - 1\n",
    "    \n",
    "    return W[0]*x0, W[1]*x1, W[2]*x2, W[3]*x3, W[4]*x4\n",
    "    \n",
    "def hot_point3(a,b,c,d,e):\n",
    "    x,y,z,w,v = _hot_point3(a,b,c,d,e)\n",
    "    return x + y + z + w + v\n",
    "\n",
    "def pp3(a,b,c,d,idx):\n",
    "    e = BoW_mat[:,idx].sum()\n",
    "    x, y, z, w, v = _hot_point3(a,b,c,d,e)\n",
    "    print(f'상승률지수 : {x}')\n",
    "    print(f'언급지수   : {y}')\n",
    "    print(f'게시글상승 : {z}')\n",
    "    print(f'게시글수   : {w}')\n",
    "    print(f'패널티     : {v}')\n",
    "    print(f'최종값     : {x+y+z+w+v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "01057100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 36., 194.,   6., ...,   0.,   0.,   0.],\n",
       "       [ 18.,  29.,   4., ...,   0.,   0.,   0.],\n",
       "       [  4.,  20.,   0., ...,   0.,   0.,   0.],\n",
       "       ...,\n",
       "       [  3.,  38.,   8., ...,   0.,   0.,   0.],\n",
       "       [ 22.,  18.,   3., ...,   0.,   0.,   0.],\n",
       "       [ 12.,  39.,   3., ...,   3.,   3.,   3.]])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BoW 매트릭스\n",
    "BoW_mat = np.array([list(value) for value in cfm.BoW.values])\n",
    "BoW_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "a47c42f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 날짜/단어별 급상승 지수 계산\n",
    "cfm['points'] = [np.zeros(len(bow_extended)) for i in range(len(cfm))]\n",
    "\n",
    "for i in range(1,len(BoW_mat)):\n",
    "    for j in range(len(bow_extended)):\n",
    "        cfm.points[i][j] = hot_point3(BoW_mat[i-1,j],BoW_mat[i,j],\n",
    "                                      posts_extended[i-1,j],posts_extended[i,j],\n",
    "                                      BoW_mat[:,j].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "00d7cdeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.26481776, -1.2968079 , -1.26402542, ..., -1.26354717,\n",
       "        -1.26354717, -1.26354717],\n",
       "       [-1.27580816, -1.31301699, -1.26999508, ..., -1.26354717,\n",
       "        -1.26354717, -1.26354717],\n",
       "       ...,\n",
       "       [-1.27342948, -1.28727906, -1.25261751, ..., -1.26354717,\n",
       "        -1.26354717, -1.26354717],\n",
       "       [-1.16918425, -1.29200404, -1.26651268, ..., -1.26354717,\n",
       "        -1.26354717, -1.26354717],\n",
       "       [-1.27101071, -1.26587024, -1.26285661, ..., -1.25525361,\n",
       "        -1.25525361, -1.25525361]])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Points 매트릭스\n",
    "Points = np.array([list(value) for value in cfm.points.values])\n",
    "Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeb6f39",
   "metadata": {},
   "source": [
    "__추가 불용어 정의__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "83d9179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#도배된 단어 등 제외\n",
    "for x_word in ['는','걍','을해','얀','인데','꿀꿀','끝내','쿠','원','쿠나','게로','사지','능','조만간','알폰소','아론']:\n",
    "    Points[:,idx_extended[x_word]] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2232608a",
   "metadata": {},
   "source": [
    "### 상위 키워드 추리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "42f97d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index 찾아 True로 저장할 ndarray 정의\n",
    "top10s = np.zeros(Points.shape, dtype=bool)\n",
    "top20s = np.zeros(Points.shape, dtype=bool)\n",
    "\n",
    "for i in range(1,len(Points)):\n",
    "    #날짜별 점수 상위 10개만 추림\n",
    "    limit_10 = np.sort(Points[i,:])[-10]\n",
    "    limit_20 = np.sort(Points[i,:])[-20]\n",
    "    for j in range(Points.shape[1]):\n",
    "        if Points[i,j]>=limit_20:\n",
    "            #상위 20개에 대해 True값으로 저장\n",
    "            top20s[i,j] = True\n",
    "            \n",
    "            if Points[i,j]>=limit_10:\n",
    "                #상위 10개에 대해 True값으로 저장\n",
    "                top10s[i,j] = True\n",
    "\n",
    "top10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "a980756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#일별 상위 10개 키워드 저장\n",
    "top10_keywords = [[idx_extended_key[int(j)] for j in np.arange(top10s.shape[1])[top10s[i]]] for i in range(len(top10s))]\n",
    "#일별 상위 20개 키워드 저장\n",
    "top20_keywords = [[idx_extended_key[int(j)] for j in np.arange(top20s.shape[1])[top20s[i]]] for i in range(len(top20s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "8ac2360d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['눈사람', '능검', '공론', '재래시장', '페스', '페이크', '정인', '로토', '팬픽', '강민철'],\n",
       " ['증원', '쿼터', '뻔뻔', '연강', '괴롭힘', '뻔선', '뻔후', '폭로', '학폭', '학교폭력'],\n",
       " ['피셋', '결석', '벚꽃', '로나', '검찰', '토지', '신도시', '투기', '단태', '브레이브걸스'],\n",
       " ['파상', '벼락치기', '클로즈', '분포', '슈퍼리그', '비제', '권혁', '만우절', '서예지', '김정현'],\n",
       " ['참가자', '퇴소', '자진', '파이', '정민', '퍼즐', '이루리', '공혁준', '또즐', '니갸르'],\n",
       " ['부정행위', '텀페', '중회', '독일', '관회', '메리트', '광학', '팬덤', '유로', '소희']]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "ee240aba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['눈사람',\n",
       "  '능검',\n",
       "  '공론',\n",
       "  '재래시장',\n",
       "  '페스',\n",
       "  '페이크',\n",
       "  '손예진',\n",
       "  '삽자루',\n",
       "  '정인',\n",
       "  '로토',\n",
       "  '팬픽',\n",
       "  '보따리',\n",
       "  '강민철',\n",
       "  '불평',\n",
       "  '와이번스',\n",
       "  '동포',\n",
       "  '담배값',\n",
       "  '냉면',\n",
       "  '아나콘다',\n",
       "  '오줌싸개'],\n",
       " ['증원',\n",
       "  '물성',\n",
       "  '성폭행',\n",
       "  '쿼터',\n",
       "  '설날',\n",
       "  '뻔뻔',\n",
       "  '사인',\n",
       "  '연강',\n",
       "  '괴롭힘',\n",
       "  '뻔선',\n",
       "  '연휴',\n",
       "  '방관',\n",
       "  '뻔후',\n",
       "  '폭로',\n",
       "  '학폭',\n",
       "  '학교폭력',\n",
       "  '탈세',\n",
       "  '동물원',\n",
       "  '김연경',\n",
       "  '역군'],\n",
       " ['장관',\n",
       "  '피셋',\n",
       "  '에이프릴',\n",
       "  '결석',\n",
       "  '벚꽃',\n",
       "  '로나',\n",
       "  '검찰',\n",
       "  '역주행',\n",
       "  '토지',\n",
       "  '신도시',\n",
       "  '서진',\n",
       "  '투기',\n",
       "  '유신',\n",
       "  '롤린',\n",
       "  '단태',\n",
       "  '브레이브걸스',\n",
       "  '마사',\n",
       "  '몰수',\n",
       "  '하윤',\n",
       "  '꼬북좌'],\n",
       " ['부정행위',\n",
       "  '파상',\n",
       "  '벼락치기',\n",
       "  '테뱅',\n",
       "  '클로즈',\n",
       "  '토트넘',\n",
       "  '분포',\n",
       "  '슈퍼리그',\n",
       "  '비제',\n",
       "  '너비',\n",
       "  '간담',\n",
       "  '애정',\n",
       "  '작',\n",
       "  '윽박',\n",
       "  '결식',\n",
       "  '권혁',\n",
       "  '만우절',\n",
       "  '서예지',\n",
       "  '진순',\n",
       "  '김정현'],\n",
       " ['코난',\n",
       "  '범인',\n",
       "  '전기',\n",
       "  '참가자',\n",
       "  '학생회',\n",
       "  '성당',\n",
       "  '퇴소',\n",
       "  '사물함',\n",
       "  '실종',\n",
       "  '자진',\n",
       "  '파이',\n",
       "  '어린이',\n",
       "  '에어컨',\n",
       "  '정민',\n",
       "  '퍼즐',\n",
       "  '이루리',\n",
       "  '캣맘',\n",
       "  '공혁준',\n",
       "  '또즐',\n",
       "  '니갸르'],\n",
       " ['부정행위',\n",
       "  '경통',\n",
       "  '텀페',\n",
       "  '중회',\n",
       "  '떡밥',\n",
       "  '국무',\n",
       "  '독일',\n",
       "  '할미',\n",
       "  '사프컴',\n",
       "  '관회',\n",
       "  '반타작',\n",
       "  '메리트',\n",
       "  '광학',\n",
       "  '팬덤',\n",
       "  '잉글랜드',\n",
       "  '현주',\n",
       "  '유로',\n",
       "  '에고',\n",
       "  '소희',\n",
       "  '쁘걸']]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f4815c",
   "metadata": {},
   "source": [
    "__월별 키워드 보기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "0ef9d038",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('능검', 2.260767814533165),\n",
       " ('눈사람', 1.6846429495194757),\n",
       " ('페스', 1.610230077040688),\n",
       " ('로토', 1.0773097870681805),\n",
       " ('팬픽', 1.0042855362774332),\n",
       " ('페이크', 1.0042390116242759),\n",
       " ('강민철', 0.8337913365931837),\n",
       " ('재래시장', 0.8249923193467364),\n",
       " ('정인', 0.7824369188747704),\n",
       " ('공론', 0.7237889856652208),\n",
       " ('냉면', 0.7000926140740011),\n",
       " ('오줌싸개', 0.6285326091369418),\n",
       " ('아나콘다', 0.5467134683125027),\n",
       " ('와이번스', 0.5331136670134958),\n",
       " ('보따리', 0.5063553456897618),\n",
       " ('삽자루', 0.4552971322576629)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('뻔뻔', 2.9060766694286704),\n",
       " ('학폭', 2.17729433603298),\n",
       " ('뻔선', 1.8340011697949712),\n",
       " ('학교폭력', 1.7158133778593483),\n",
       " ('쿼터', 1.5240046743778157),\n",
       " ('증원', 1.4487172599266391),\n",
       " ('뻔후', 1.238929017862722),\n",
       " ('폭로', 1.2205242316051437),\n",
       " ('괴롭힘', 1.1032633441401642),\n",
       " ('연강', 0.9081321681763606),\n",
       " ('동물원', 0.877751313243363),\n",
       " ('탈세', 0.8742128362653893),\n",
       " ('김연경', 0.8676058012943388),\n",
       " ('물성', 0.8389613842387756),\n",
       " ('역군', 0.8090530675135683),\n",
       " ('사인', 0.7851861517363047),\n",
       " ('연휴', 0.6764222193690317),\n",
       " ('방관', 0.6759785392670195),\n",
       " ('성폭행', 0.6582000882432335),\n",
       " ('설날', 0.6501837356569178),\n",
       " ('돌고래', 0.6475324203931211),\n",
       " ('매매혼', 0.645106973790332),\n",
       " ('강인원', 0.6242970899004467),\n",
       " ('박물관', 0.5779721602587583),\n",
       " ('뜻뜻', 0.5572805601042105),\n",
       " ('이진욱', 0.5127268180871906),\n",
       " ('읏', 0.4925825322501887),\n",
       " ('박혜수', 0.48565225162724185),\n",
       " ('명절', 0.48543285974844463),\n",
       " ('연가', 0.4368597579045375),\n",
       " ('라미', 0.42408578661221585),\n",
       " ('학보', 0.423844042948899),\n",
       " ('세뱃돈', 0.41938121923030325),\n",
       " ('분반', 0.41502840050637846)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('브레이브걸스', 2.22933911185193),\n",
       " ('단태', 2.0792541562070443),\n",
       " ('피셋', 1.703284982834478),\n",
       " ('신도시', 1.642462685846044),\n",
       " ('투기', 1.6165370239971752),\n",
       " ('검찰', 1.5690809043020542),\n",
       " ('결석', 1.5168880880759443),\n",
       " ('토지', 1.478933863061037),\n",
       " ('벚꽃', 1.4000063024463174),\n",
       " ('로나', 1.3672450068133981),\n",
       " ('마사', 1.3500116675752236),\n",
       " ('몰수', 1.2590418314014218),\n",
       " ('롤린', 1.2443783911042554),\n",
       " ('하윤', 1.2395557600221048),\n",
       " ('에이프릴', 1.2199456431016544),\n",
       " ('장관', 1.099773246730592),\n",
       " ('역주행', 1.0995421181074967),\n",
       " ('유신', 1.049941839395576),\n",
       " ('서진', 0.99970779535535),\n",
       " ('꼬북좌', 0.9836643072225276),\n",
       " ('수사', 0.9438734921055012),\n",
       " ('압수수색', 0.9182709420771997),\n",
       " ('자진', 0.8843710011701326),\n",
       " ('소급', 0.8766788875087869),\n",
       " ('버닝썬', 0.828980397868778),\n",
       " ('민주화', 0.8229285479641979),\n",
       " ('성매매', 0.811031207467534),\n",
       " ('룸살롱', 0.7873029929898611),\n",
       " ('향영', 0.7253117704861348),\n",
       " ('그래미', 0.7150509382790209),\n",
       " ('박수홍', 0.6941311631646634),\n",
       " ('임효준', 0.6317820125674505),\n",
       " ('수련', 0.614662265168781),\n",
       " ('쁘걸', 0.6074678333528786),\n",
       " ('동선', 0.5984709908292568),\n",
       " ('노처녀', 0.5760022032913371),\n",
       " ('환수', 0.5596460315295846),\n",
       " ('등업', 0.5586322988712654),\n",
       " ('카츠', 0.5561821747976696),\n",
       " ('가계약', 0.5414083548771053),\n",
       " ('공직자', 0.5134218746353706),\n",
       " ('스프링', 0.48478769961565893),\n",
       " ('비리', 0.4809067758456969),\n",
       " ('하은', 0.47642452303991895),\n",
       " ('혈소판', 0.4752109170110645),\n",
       " ('고위', 0.4505345102898079),\n",
       " ('집회', 0.44949842408299473),\n",
       " ('감사원', 0.4428786557154101),\n",
       " ('폐쇄', 0.4297318599605482),\n",
       " ('서머', 0.4164194620590456)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('서예지', 1.9022807834692488),\n",
       " ('슈퍼리그', 1.6895519677147233),\n",
       " ('클로즈', 1.6880632934864688),\n",
       " ('김정현', 1.2730761500460281),\n",
       " ('비제', 1.1448339147424684),\n",
       " ('만우절', 1.1299672608995588),\n",
       " ('벼락치기', 0.8972771472427674),\n",
       " ('권혁', 0.4997246313270325),\n",
       " ('파상', 0.4670631125631868),\n",
       " ('분포', 0.4465461535817043),\n",
       " ('너비', 0.43658398039753943)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('참가자', 2.0620549547283336),\n",
       " ('퍼즐', 2.061422982385385),\n",
       " ('공혁준', 2.0193505845033326),\n",
       " ('이루리', 1.7752761958177912),\n",
       " ('정민', 1.758700161419743),\n",
       " ('퇴소', 1.7352013308542047),\n",
       " ('또즐', 1.7010357834601493),\n",
       " ('니갸르', 1.5548242004092578),\n",
       " ('파이', 1.5152887325168194),\n",
       " ('자진', 1.5046535945302328),\n",
       " ('사물함', 1.4891681972729147),\n",
       " ('학생회', 1.4786129546458162),\n",
       " ('전기', 1.2066400820413237),\n",
       " ('범인', 1.0835541224993812),\n",
       " ('코난', 1.0285868555594113),\n",
       " ('성당', 0.9012279189844271),\n",
       " ('에어컨', 0.8047932944798283),\n",
       " ('어린이', 0.7861394025069605),\n",
       " ('실종', 0.7526812093728193),\n",
       " ('캣맘', 0.7436837301002479),\n",
       " ('무죄', 0.6489785383501229),\n",
       " ('어버이날', 0.6076281219154295),\n",
       " ('약육강식', 0.5902651138496333),\n",
       " ('호날두', 0.574112523473142),\n",
       " ('퇴', 0.5604843885505018),\n",
       " ('육지', 0.5199889921983183),\n",
       " ('어린이날', 0.4606035918840763),\n",
       " ('최면', 0.4170355382815962)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('텀페', 1.606603203188053),\n",
       " ('관회', 1.3746085911616708),\n",
       " ('광학', 1.2967518608025441),\n",
       " ('독일', 1.242447823527372),\n",
       " ('팬덤', 1.201700999169101),\n",
       " ('소희', 1.1362068081919847),\n",
       " ('부정행위', 1.094260938677591),\n",
       " ('유로', 0.9619952825122491),\n",
       " ('메리트', 0.9043947269187297),\n",
       " ('중회', 0.6250872479194971),\n",
       " ('경통', 0.60320749747943),\n",
       " ('국무', 0.566041043992044),\n",
       " ('사프컴', 0.5319942501084838),\n",
       " ('현주', 0.5215723113458508),\n",
       " ('에고', 0.49777081290346725),\n",
       " ('잉글랜드', 0.49256289396082537),\n",
       " ('할미', 0.47724325105923293),\n",
       " ('반타작', 0.45792501046152534),\n",
       " ('쁘걸', 0.4462492446186387),\n",
       " ('떡밥', 0.4452337671503154),\n",
       " ('미분', 0.4445983569019486),\n",
       " ('곡선', 0.44408952348419106),\n",
       " ('리믹스', 0.4418088480118401),\n",
       " ('펩시', 0.4320645626434206),\n",
       " ('미적분', 0.4170023692209237),\n",
       " ('프제', 0.41329545502830006),\n",
       " ('열역학', 0.4113587420406447)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "month = 1\n",
    "\n",
    "for month in range(1,7):\n",
    "    display([(idx_extended_key[arg],Points[month,arg]) for arg in np.flip(np.argsort(Points[month])) if Points[month,arg]>0.4])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70458b01",
   "metadata": {},
   "source": [
    "### 단어별 검토"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "aa185949",
   "metadata": {},
   "outputs": [],
   "source": [
    "_word = '피셋'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da83b0",
   "metadata": {},
   "source": [
    "- 월별 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "91f94e74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -1.21918944, -1.37305272,  1.70328498, -1.34172567,\n",
       "       -1.42083641, -1.34372986])"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Points[:,idx_extended[_word]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b0f937",
   "metadata": {},
   "source": [
    "- 전체 등장 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "b0b3e63e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_extended[idx_extended[_word]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242fb0f7",
   "metadata": {},
   "source": [
    "- 월별 등장 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "449e3c49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 79.,  50.,  36., 489.,  45.,  11.,  36.])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BoW_mat[:,idx_extended[_word]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07663378",
   "metadata": {},
   "source": [
    "- 월별 게시글 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "88180caa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11., 14.,  8., 51., 10.,  4.,  8.])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_extended[:,idx_extended[_word]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56549b42",
   "metadata": {},
   "source": [
    "- 지수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "b417c453",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상승률지수 : 1.463536799078829\n",
      "언급지수   : 0.04921103108035467\n",
      "게시글상승 : 0.0565289497131827\n",
      "게시글수   : -0.251312339887548\n",
      "패널티     : -0.021212579182274108\n",
      "최종값     : 1.2967518608025441\n"
     ]
    }
   ],
   "source": [
    "end = 6\n",
    "pp3(BoW_mat[end-1,idx_extended[_word]],BoW_mat[end,idx_extended[_word]],\n",
    "    posts_extended[end-1,idx_extended[_word]], posts_extended[end,idx_extended[_word]],\n",
    "    idx_extended[_word])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60f265",
   "metadata": {},
   "source": [
    "- 내용 검색 툴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "02db56f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_cd(word, x):\n",
    "    try:\n",
    "        return True if word in [y[0] for y in x] else False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def s_search(word, month, show_urls=True):\n",
    "    df_month = df2[df2.upload_date.apply(lambda x: True if x.month==month else False)]\n",
    "    title_cd = df2.title_tokenized.apply(lambda x: search_cd(word,x))\n",
    "    text_cd = df2.text_tokenized.apply(lambda x: search_cd(word,x))\n",
    "    comments_cd = df2.comments_tokenized.apply(lambda x: search_cd(word,x))\n",
    "    comments_writer_cd = df2.comments_writer_tokenized.apply(lambda x: search_cd(word,x))\n",
    "    df = df_month[title_cd | text_cd | comments_cd | comments_writer_cd]\n",
    "    if show_urls==True:\n",
    "        [print('http://www.ssodam.com/content/'+str(number)) for number in df.num]\n",
    "    return df\n",
    "\n",
    "def numofposts(word, month):\n",
    "    df = s_search(word,month,show_urls=False)\n",
    "    return len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "8fa2b978",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.ssodam.com/content/1177711\n",
      "http://www.ssodam.com/content/1177713\n",
      "http://www.ssodam.com/content/1178229\n",
      "http://www.ssodam.com/content/1183701\n",
      "http://www.ssodam.com/content/1183764\n",
      "http://www.ssodam.com/content/1184512\n",
      "http://www.ssodam.com/content/1185045\n",
      "http://www.ssodam.com/content/1185192\n",
      "http://www.ssodam.com/content/1185739\n",
      "http://www.ssodam.com/content/1186858\n",
      "http://www.ssodam.com/content/1187343\n",
      "http://www.ssodam.com/content/1187680\n",
      "http://www.ssodam.com/content/1187685\n",
      "http://www.ssodam.com/content/1187688\n",
      "http://www.ssodam.com/content/1187702\n",
      "http://www.ssodam.com/content/1188046\n",
      "http://www.ssodam.com/content/1188071\n",
      "http://www.ssodam.com/content/1188279\n",
      "http://www.ssodam.com/content/1190762\n",
      "http://www.ssodam.com/content/1190862\n",
      "http://www.ssodam.com/content/1190890\n",
      "http://www.ssodam.com/content/1191093\n",
      "http://www.ssodam.com/content/1191672\n",
      "http://www.ssodam.com/content/1197596\n",
      "http://www.ssodam.com/content/1200076\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>board</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>writer</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>view</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_writer</th>\n",
       "      <th>comments_cnt</th>\n",
       "      <th>popularity</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>comments_writer_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63062</th>\n",
       "      <td>1177711</td>\n",
       "      <td>익게2</td>\n",
       "      <td>현대광학 0601 녹화하신 분 있나여</td>\n",
       "      <td>오캠 녹화햇는데 오류나서 파일이 날라갓네요사례하겟읍니다</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>09:52</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(오, Modifier), (캠, Noun), (녹화, Noun), (햇, Nou...</td>\n",
       "      <td>[(현대, Noun), (광학, Noun), (0601, Number), (녹화, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63063</th>\n",
       "      <td>1177713</td>\n",
       "      <td>자유게시판</td>\n",
       "      <td>현대광학 0601 녹화본 구합니다</td>\n",
       "      <td>기프티콘 사례하겠습니다</td>\n",
       "      <td>사쿠라이</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>09:55</td>\n",
       "      <td>176.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>이왜비</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(기프티콘, Noun), (사례, Noun), (하겠습니다, Verb)]</td>\n",
       "      <td>[(현대, Noun), (광학, Noun), (0601, Number), (녹화, ...</td>\n",
       "      <td>[(이, Determiner), (왜비, Noun)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63389</th>\n",
       "      <td>1178229</td>\n",
       "      <td>익게1</td>\n",
       "      <td>현대광학 ㅈㅈㅇ 교수님 기말 족보 구합니다</td>\n",
       "      <td>사례하겠습니다 댓글주세요</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>23:34</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(사례, Noun), (하겠습니다, Verb), (댓글, Noun), (주세요, ...</td>\n",
       "      <td>[(현대, Noun), (광학, Noun), (ㅈㅈㅇ, KoreanParticle)...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66955</th>\n",
       "      <td>1183701</td>\n",
       "      <td>익게2</td>\n",
       "      <td>물리과 핫한기념 전공 선택과목 추천좀 해주실 분</td>\n",
       "      <td>현재 전선은 광학 하나 들은 5학기생임앞으로전산물리학고체물리정도 들을거 같은데일반상...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>23:49</td>\n",
       "      <td>271.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>일단 전산 고체 꿀잼, 만일 반도체로 취업하고자 한다면 고체는 무적권, ㅇㅇ 파이썬...</td>\n",
       "      <td>고체  학부 치업하려면 무적건임, 전산은 머하는 가목임 혹시 몰라서 이번에 파이썬 ...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(현재, Noun), (전선, Noun), (은, Josa), (광학, Noun)...</td>\n",
       "      <td>[(물리, Noun), (과, Josa), (핫, Noun), (한, Determi...</td>\n",
       "      <td>[(일단, Noun), (전산, Noun), (고체, Noun), (꿀잼, Noun...</td>\n",
       "      <td>[(고체, Noun), (학부, Noun), (치, Noun), (업하려면, Ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66981</th>\n",
       "      <td>1183764</td>\n",
       "      <td>익게2</td>\n",
       "      <td>물리과 살려줘</td>\n",
       "      <td>양자고 광학이고 열역학이고 하나도 모르겠어                       ...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>00:51</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>광학은 진짜 그랫으면 좋겟는데 어림도업지 ㅋㅋㅋ, 양자 정성적으로 해석하는 문제 하...</td>\n",
       "      <td>ㄹㅇㅋㅋ 항상 조져지는건 나였고, 양자는 그나마 문제 경향성을 알듯말듯 하고 광학은...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(양자, Noun), (고, Josa), (광학, Noun), (이고, Josa)...</td>\n",
       "      <td>[(물리, Noun), (과, Josa), (살려줘, Verb)]</td>\n",
       "      <td>[(광학, Noun), (은, Josa), (진짜, Noun), (그랫으, Noun...</td>\n",
       "      <td>[(ㄹㅇㅋㅋ, KoreanParticle), (항상, Noun), (조져지는건, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67433</th>\n",
       "      <td>1184512</td>\n",
       "      <td>익게2</td>\n",
       "      <td>물리학과 광학 기말 족보 있는 사람 있음</td>\n",
       "      <td>치킨 사례함</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>22:54</td>\n",
       "      <td>210.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>광학 족보 엄청 탐, 문제는 족보 있는 애들이 많다는거임, 물리과까지 족보에 잠식당...</td>\n",
       "      <td>ㄹㅇ, 절평인데 좀 돌려보자고, ㄴ 서담 자료실에 올려줘도 치킨 선사함,</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(치킨, Noun), (사례, Noun), (함, Noun)]</td>\n",
       "      <td>[(물리학, Noun), (과, Josa), (광학, Noun), (기, Modif...</td>\n",
       "      <td>[(광학, Noun), (족보, Noun), (엄청, Adverb), (탐, Ver...</td>\n",
       "      <td>[(ㄹㅇ, KoreanParticle), (,, Punctuation), (절평, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67749</th>\n",
       "      <td>1185045</td>\n",
       "      <td>익게2</td>\n",
       "      <td>광학 다들 중간 숙제 몇점나옴</td>\n",
       "      <td>나 30나왓는에 ㅈ댄거냐</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>17:33</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35ㅋㅋ, 20점이었나ㅌㅋ, 저는 40인데 다들 비스무리 하구먼</td>\n",
       "      <td>중간 몇점이엇냐 나 딱 평균ㅋㅋㅋ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(나, Noun), (30, Number), (나왓는, Noun), (에, Jos...</td>\n",
       "      <td>[(광학, Noun), (다, Adverb), (들, Verb), (중간, Noun...</td>\n",
       "      <td>[(35, Number), (ㅋㅋ, KoreanParticle), (,, Punct...</td>\n",
       "      <td>[(중간, Noun), (몇, Modifier), (점, Noun), (이, Det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67837</th>\n",
       "      <td>1185192</td>\n",
       "      <td>익게2</td>\n",
       "      <td>광학 이거 어케푸는거임</td>\n",
       "      <td>이랑  랑 머선 차이인지 모르겠네이 문제라도 맞춰야될거같은데어케푸는지 모르겟다 ㅈ망한듯</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>20:57</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>각 광학장치에 대한 조온스 매트릭스를 곱하시오, 그러면 들어오는 바앙향에 따라 이 ...</td>\n",
       "      <td>, ㅇㅎ 이해함, 기말시험에 나온다고 미리 알려주신 문제인데 못건드리겟음ㅋㅋㅋ, 족...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(이랑, Josa), (랑, Josa), (머선, Noun), (차이, Noun)...</td>\n",
       "      <td>[(광학, Noun), (이, Determiner), (거, Noun), (어케, ...</td>\n",
       "      <td>[(각, Noun), (광학, Noun), (장치, Noun), (에, Josa),...</td>\n",
       "      <td>[(,, Punctuation), (ㅇㅎ, KoreanParticle), (이해, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68196</th>\n",
       "      <td>1185739</td>\n",
       "      <td>익게2</td>\n",
       "      <td>양자공부하다가 광학 하니까 개재밋네</td>\n",
       "      <td>이게 물리지</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-12</td>\n",
       "      <td>16:30</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>흠 난 광학보다 양자가 훨 재밌었음, 광학은 양자보단 직관적이라 덜 짜증나는거 같음</td>\n",
       "      <td>양자그켬</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(이, Noun), (게, Josa), (물리, Noun), (지, Josa)]</td>\n",
       "      <td>[(양자, Noun), (공부, Noun), (하, Suffix), (다가, Nou...</td>\n",
       "      <td>[(흠, Noun), (난, Noun), (광학, Noun), (보다, Josa),...</td>\n",
       "      <td>[(양자, Noun), (그, Noun), (켬, Verb)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68955</th>\n",
       "      <td>1186858</td>\n",
       "      <td>익게2</td>\n",
       "      <td>물리과 살려주</td>\n",
       "      <td>헥트 광학 교재 부랴부랴 풀고있는데 귀찮고 힘들어열역학은 증명문제 안 나올거 같아서...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-14</td>\n",
       "      <td>04:59</td>\n",
       "      <td>199.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>숙제 다 풀었다고 씹가능이네, 그정도면 적어도 중간 이상은 할 수 있을거야, 다 햇...</td>\n",
       "      <td>근데 풀다풀다 답지만 하루종일 붙들고 있었던 문제도 많고 정작 어떻게 푸는건지 잘 ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(헥트, Noun), (광학, Noun), (교재, Noun), (부랴부랴, No...</td>\n",
       "      <td>[(물리, Noun), (과, Josa), (살려주, Verb)]</td>\n",
       "      <td>[(숙제, Noun), (다, Adverb), (풀었다고, Verb), (씹, Ve...</td>\n",
       "      <td>[(근데, Adverb), (풀다, Noun), (풀다, Noun), (답지, No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69295</th>\n",
       "      <td>1187343</td>\n",
       "      <td>익게2</td>\n",
       "      <td>물잘알들 드루와바</td>\n",
       "      <td>내가 좋아하는 유튜버인데 최근에 바람 동력 이동 수단이 과연 바람과 같은 방향으로 ...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-14</td>\n",
       "      <td>20:51</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>지나가던 물리과 내일 광학 열 끝내고 보러올게아 수요일 양자도 끝내고</td>\n",
       "      <td>기다릴께</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(내, Noun), (가, Josa), (좋아하는, Adjective), (유튜버...</td>\n",
       "      <td>[(물잘, Verb), (알, Noun), (들, Suffix), (드루, Noun...</td>\n",
       "      <td>[(지나가던, Verb), (물리, Noun), (과, Josa), (내일, Nou...</td>\n",
       "      <td>[(기다릴께, Verb)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69540</th>\n",
       "      <td>1187680</td>\n",
       "      <td>익게2</td>\n",
       "      <td>광학 책버리면 안되겠다</td>\n",
       "      <td>ㅎ</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-15</td>\n",
       "      <td>10:21</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>광학 미치겠다 하 , 교수님 혹시 착각하셔서 다른 과목 출제하셨나요 , ㅎㅎ몇문제풂...</td>\n",
       "      <td></td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(ㅎ, KoreanParticle)]</td>\n",
       "      <td>[(광학, Noun), (책, Noun), (버리면, Verb), (안되겠다, Ad...</td>\n",
       "      <td>[(광학, Noun), (미치겠다, Adjective), (하, Exclamatio...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69544</th>\n",
       "      <td>1187685</td>\n",
       "      <td>익게2</td>\n",
       "      <td>광학 조졌다</td>\n",
       "      <td>아 ㅋㅋ 왜 안배운거 같은 내용들이 나오냐고  눌러서 조의 표하러 간다</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-15</td>\n",
       "      <td>10:23</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>한문제풂ㅎㅎ</td>\n",
       "      <td>오픈북도 죽쒔는데 좀 이따 열역학은 어쩌냐 답이 없다 하</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(아, Exclamation), (ㅋㅋ, KoreanParticle), (왜, N...</td>\n",
       "      <td>[(광학, Noun), (조졌다, Adjective)]</td>\n",
       "      <td>[(한, Determiner), (문제, Noun), (풂, Verb), (ㅎㅎ, ...</td>\n",
       "      <td>[(오픈, Noun), (북도, Noun), (죽, Noun), (쒔는데, Verb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69547</th>\n",
       "      <td>1187688</td>\n",
       "      <td>익게2</td>\n",
       "      <td>광학 쌉조졋네 ㅋㅋㅋㅋ</td>\n",
       "      <td>문제 보자마자 풀 엄두도 안나서                             ...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-15</td>\n",
       "      <td>10:25</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>군속도 교과서에 있었음 나 그거 낑낑대다가 쳤는데 , 아 씨 있었네 ㅋㅋㅋㅋ 이런거...</td>\n",
       "      <td>그래 1개도 못풀엇네 시ㅂㅋㅋㅋㅋ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(문제, Noun), (보자마자, Verb), (풀, Noun), (엄두, Nou...</td>\n",
       "      <td>[(광학, Noun), (쌉조졋, Noun), (네, Josa), (ㅋㅋㅋㅋ, Ko...</td>\n",
       "      <td>[(군속도, Noun), (교과서, Noun), (에, Josa), (있었음, Ad...</td>\n",
       "      <td>[(그래, Adjective), (1, Number), (개도, Noun), (못풀...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69558</th>\n",
       "      <td>1187702</td>\n",
       "      <td>익게2</td>\n",
       "      <td>열역학 공부하기 개싫어지네</td>\n",
       "      <td>그냥 빨리 자고 싶다나는 공부해도 부질없다는 걸광학에서 느꼇다</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-15</td>\n",
       "      <td>10:41</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>열역학도 되게 어렵게 내실것 같은데, 나도</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(그냥, Noun), (빨리, Adverb), (자고, Noun), (싶다나는, ...</td>\n",
       "      <td>[(열역학, Noun), (공부, Noun), (하기, Verb), (개, Noun...</td>\n",
       "      <td>[(열역학, Noun), (도, Josa), (되게, Adverb), (어렵게, A...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69807</th>\n",
       "      <td>1188046</td>\n",
       "      <td>익게2</td>\n",
       "      <td>전산물리는 왜 이번학기 안열렸는데 담학기에 2가열림</td>\n",
       "      <td>전산물리 1을 이번학기에 안열려서 못들었는데전산물리 2가 열리네1안듣고 전산물리 2...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-15</td>\n",
       "      <td>17:36</td>\n",
       "      <td>173.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ㅋㅋㅋㅋㅋㅋㄹㅇ, 그거 원래 그럴걸 광학 전산물리 다 반년짜리 코스자너, 그럼 1이...</td>\n",
       "      <td>아 진짜 나 물리학과 수업 들어오면서 1,2같은 수업 첨봄ㅋㅋㅋㅋ</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(전산, Noun), (물리, Noun), (1, Number), (을, Josa...</td>\n",
       "      <td>[(전산, Noun), (물리는, Verb), (왜, Noun), (이번, Noun...</td>\n",
       "      <td>[(ㅋㅋㅋㅋㅋㅋㄹㅇ, KoreanParticle), (,, Punctuation),...</td>\n",
       "      <td>[(아, Exclamation), (진짜, Noun), (나, Noun), (물리학...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69824</th>\n",
       "      <td>1188071</td>\n",
       "      <td>익게2</td>\n",
       "      <td>국방과학연구소 아세요</td>\n",
       "      <td>지원해주세요 후배님들</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-15</td>\n",
       "      <td>18:17</td>\n",
       "      <td>341.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>예 제 직장 출연기관이용, 학사는 안받을거면서, 꾸준글 심하다야, 2222, 경영학...</td>\n",
       "      <td>예 맞아용, 석사박사하세요, 33333, 관리직도 뽑아요 연봉 나쁘지 않음, 헐 그...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(지원, Noun), (해주세요, Verb), (후배, Noun), (님, Suf...</td>\n",
       "      <td>[(국방, Noun), (과학, Noun), (연구소, Noun), (아세요, Ve...</td>\n",
       "      <td>[(예, Noun), (제, Noun), (직장, Noun), (출연, Noun),...</td>\n",
       "      <td>[(예, Noun), (맞아용, Verb), (,, Punctuation), (석,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69965</th>\n",
       "      <td>1188279</td>\n",
       "      <td>익게2</td>\n",
       "      <td>이과 꿀과목</td>\n",
       "      <td>이과중에 타전공 학생이 들어도 앵간하다 싶은 자기 전공 과목 뭐있는지 자랑해줘 참고...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-15</td>\n",
       "      <td>22:31</td>\n",
       "      <td>369.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>양자, 컴퓨터통신, 물리과  현대물리, 이거 ㄱㅊ 진짜 추천함ㅇㅇ, ㄴㄴ반응공학임 ...</td>\n",
       "      <td></td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(이과, Noun), (중, Suffix), (에, Josa), (타, Modif...</td>\n",
       "      <td>[(이과, Noun), (꿀, Noun), (과목, Noun)]</td>\n",
       "      <td>[(양자, Noun), (,, Punctuation), (컴퓨터통신, Noun), ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71697</th>\n",
       "      <td>1190762</td>\n",
       "      <td>익게2</td>\n",
       "      <td>광학 시험점수 떳다</td>\n",
       "      <td>확인 ㄱㄱ</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-18</td>\n",
       "      <td>17:24</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ㅠㅠ맞은게없당, 몇점임 , 나 30 나왔는데 다들 몇점이야</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(확인, Noun), (ㄱㄱ, KoreanParticle)]</td>\n",
       "      <td>[(광학, Noun), (시험, Noun), (점수, Noun), (떳다, Noun)]</td>\n",
       "      <td>[(ㅠㅠ, KoreanParticle), (맞은게, Verb), (없당, Adjec...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71762</th>\n",
       "      <td>1190862</td>\n",
       "      <td>익게2</td>\n",
       "      <td>광학 다들 몇점이야ㅜ</td>\n",
       "      <td>15점인데 제로 나오려나ㅜ</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-18</td>\n",
       "      <td>19:48</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50점인데 헉, 50이엇나 과제 점수는 깎인거 잇어, 중간 50이 비쁠이엇던걸루 기...</td>\n",
       "      <td>ㅜ 중간뭐였오, 나 제출못한거많아ㅜㅜ, 부럽다ㅜㅜ</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(15, Number), (점, Noun), (인데, Josa), (제로, Nou...</td>\n",
       "      <td>[(광학, Noun), (다, Adverb), (들, Verb), (몇, Modif...</td>\n",
       "      <td>[(50, Number), (점, Noun), (인데, Josa), (헉, Adve...</td>\n",
       "      <td>[(ㅜ, KoreanParticle), (중간, Noun), (뭐, Noun), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71778</th>\n",
       "      <td>1190890</td>\n",
       "      <td>익게2</td>\n",
       "      <td>화공에 디스플레이 관련 전선과목 있나</td>\n",
       "      <td></td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-18</td>\n",
       "      <td>20:21</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>광학 어때, 없어</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(화공, Noun), (에, Josa), (디스플레이, Noun), (관련, No...</td>\n",
       "      <td>[(광학, Noun), (어때, Adjective), (,, Punctuation)...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71910</th>\n",
       "      <td>1191093</td>\n",
       "      <td>서르비</td>\n",
       "      <td>물리학과  토목공학과</td>\n",
       "      <td>의외로 반도체나 광학 쪽으로 갈곳많은 물리학과  의외로 공무원이나 공기업 쪽으로 자...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-19</td>\n",
       "      <td>02:20</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2, 전, 물리과는 취업 위해 오는 거 아니다 마, 누가 취직하러 물리과를 감 ㅋㅋ...</td>\n",
       "      <td></td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(의외로, Adverb), (반도체, Noun), (나, Josa), (광학, N...</td>\n",
       "      <td>[(물리학, Noun), (과, Josa), (토목공학, Noun), (과, Josa)]</td>\n",
       "      <td>[(2, Number), (,, Punctuation), (전, Noun), (,,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72302</th>\n",
       "      <td>1191672</td>\n",
       "      <td>익게2</td>\n",
       "      <td>광학 에쁠 두명인건가</td>\n",
       "      <td>좀 더 주셔도되는데</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-19</td>\n",
       "      <td>22:09</td>\n",
       "      <td>167.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ㄷㄷㅋㅋ 다워</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(좀, Noun), (더, Noun), (주셔도, Verb), (되는데, Verb)]</td>\n",
       "      <td>[(광학, Noun), (에쁠, Noun), (두, Determiner), (명인,...</td>\n",
       "      <td>[(ㄷㄷㅋㅋ, KoreanParticle), (다, Adverb), (워, Noun)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76220</th>\n",
       "      <td>1197596</td>\n",
       "      <td>익게2</td>\n",
       "      <td>실험물리는 대체 언제까지 이런 방향성을 유지할 셈이지</td>\n",
       "      <td>조교들 바쁜 심정 이해함 근데 우리도 돈 내고 좋은 결과 얻고 싶은데무지성 회로실험...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>18:49</td>\n",
       "      <td>255.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>컴공도 똑같아 물리학과를 컴공으로 바꾸고 실험물리를 컴실로 바꾸면 컴실에 대한 글이...</td>\n",
       "      <td>첫번째 반박은 내가 모르는 게 아니고 내 주장에 대한 반박도 되지 못함 난 회로이론...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(조교, Noun), (들, Suffix), (바쁜, Adjective), (심정...</td>\n",
       "      <td>[(실험, Noun), (물리는, Verb), (대체, Noun), (언제, Nou...</td>\n",
       "      <td>[(컴공, Noun), (도, Josa), (똑같아, Adjective), (물리학...</td>\n",
       "      <td>[(첫, Noun), (번째, Suffix), (반박, Noun), (은, Josa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77848</th>\n",
       "      <td>1200076</td>\n",
       "      <td>익게2</td>\n",
       "      <td>물리학과 전선 보통 머 들어</td>\n",
       "      <td>수물2역학2는 기본으로 듣는다 치고추가로 듣는다면 다들 뭐뭐 들었어나는 물전공1 전...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>19:17</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>나는 입자이론, 상대론, 전산물리, 고체물리, 고전물리 들었음 여기에 수학과 선대랑...</td>\n",
       "      <td>입자론 상대론 고전물리  들을 엄두도 안나는 것들 다 들엇네 대단쓰, 물전2까지는 ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(수, Modifier), (물, Noun), (2, Number), (역학, N...</td>\n",
       "      <td>[(물리학, Noun), (과, Josa), (전선, Noun), (보통, Noun...</td>\n",
       "      <td>[(나, Noun), (는, Josa), (입자, Noun), (이론, Noun),...</td>\n",
       "      <td>[(입자, Noun), (론, Noun), (상대론, Noun), (고전, Modi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           num  board                          title  \\\n",
       "63062  1177711    익게2           현대광학 0601 녹화하신 분 있나여   \n",
       "63063  1177713  자유게시판             현대광학 0601 녹화본 구합니다   \n",
       "63389  1178229    익게1        현대광학 ㅈㅈㅇ 교수님 기말 족보 구합니다   \n",
       "66955  1183701    익게2     물리과 핫한기념 전공 선택과목 추천좀 해주실 분   \n",
       "66981  1183764    익게2                        물리과 살려줘   \n",
       "67433  1184512    익게2         물리학과 광학 기말 족보 있는 사람 있음   \n",
       "67749  1185045    익게2               광학 다들 중간 숙제 몇점나옴   \n",
       "67837  1185192    익게2                   광학 이거 어케푸는거임   \n",
       "68196  1185739    익게2            양자공부하다가 광학 하니까 개재밋네   \n",
       "68955  1186858    익게2                        물리과 살려주   \n",
       "69295  1187343    익게2                      물잘알들 드루와바   \n",
       "69540  1187680    익게2                   광학 책버리면 안되겠다   \n",
       "69544  1187685    익게2                         광학 조졌다   \n",
       "69547  1187688    익게2                   광학 쌉조졋네 ㅋㅋㅋㅋ   \n",
       "69558  1187702    익게2                 열역학 공부하기 개싫어지네   \n",
       "69807  1188046    익게2   전산물리는 왜 이번학기 안열렸는데 담학기에 2가열림   \n",
       "69824  1188071    익게2                    국방과학연구소 아세요   \n",
       "69965  1188279    익게2                         이과 꿀과목   \n",
       "71697  1190762    익게2                     광학 시험점수 떳다   \n",
       "71762  1190862    익게2                    광학 다들 몇점이야ㅜ   \n",
       "71778  1190890    익게2           화공에 디스플레이 관련 전선과목 있나   \n",
       "71910  1191093    서르비                    물리학과  토목공학과   \n",
       "72302  1191672    익게2                    광학 에쁠 두명인건가   \n",
       "76220  1197596    익게2  실험물리는 대체 언제까지 이런 방향성을 유지할 셈이지   \n",
       "77848  1200076    익게2                물리학과 전선 보통 머 들어   \n",
       "\n",
       "                                                    text writer upload_date  \\\n",
       "63062                     오캠 녹화햇는데 오류나서 파일이 날라갓네요사례하겟읍니다     익명  2021-06-01   \n",
       "63063                                       기프티콘 사례하겠습니다   사쿠라이  2021-06-01   \n",
       "63389                                      사례하겠습니다 댓글주세요     익명  2021-06-01   \n",
       "66955  현재 전선은 광학 하나 들은 5학기생임앞으로전산물리학고체물리정도 들을거 같은데일반상...     익명  2021-06-09   \n",
       "66981  양자고 광학이고 열역학이고 하나도 모르겠어                       ...     익명  2021-06-10   \n",
       "67433                                             치킨 사례함     익명  2021-06-10   \n",
       "67749                                      나 30나왓는에 ㅈ댄거냐     익명  2021-06-11   \n",
       "67837   이랑  랑 머선 차이인지 모르겠네이 문제라도 맞춰야될거같은데어케푸는지 모르겟다 ㅈ망한듯     익명  2021-06-11   \n",
       "68196                                             이게 물리지     익명  2021-06-12   \n",
       "68955  헥트 광학 교재 부랴부랴 풀고있는데 귀찮고 힘들어열역학은 증명문제 안 나올거 같아서...     익명  2021-06-14   \n",
       "69295  내가 좋아하는 유튜버인데 최근에 바람 동력 이동 수단이 과연 바람과 같은 방향으로 ...     익명  2021-06-14   \n",
       "69540                                                  ㅎ     익명  2021-06-15   \n",
       "69544            아 ㅋㅋ 왜 안배운거 같은 내용들이 나오냐고  눌러서 조의 표하러 간다     익명  2021-06-15   \n",
       "69547  문제 보자마자 풀 엄두도 안나서                             ...     익명  2021-06-15   \n",
       "69558                 그냥 빨리 자고 싶다나는 공부해도 부질없다는 걸광학에서 느꼇다     익명  2021-06-15   \n",
       "69807  전산물리 1을 이번학기에 안열려서 못들었는데전산물리 2가 열리네1안듣고 전산물리 2...     익명  2021-06-15   \n",
       "69824                                        지원해주세요 후배님들     익명  2021-06-15   \n",
       "69965  이과중에 타전공 학생이 들어도 앵간하다 싶은 자기 전공 과목 뭐있는지 자랑해줘 참고...     익명  2021-06-15   \n",
       "71697                                              확인 ㄱㄱ     익명  2021-06-18   \n",
       "71762                                     15점인데 제로 나오려나ㅜ     익명  2021-06-18   \n",
       "71778                                                        익명  2021-06-18   \n",
       "71910  의외로 반도체나 광학 쪽으로 갈곳많은 물리학과  의외로 공무원이나 공기업 쪽으로 자...     익명  2021-06-19   \n",
       "72302                                         좀 더 주셔도되는데     익명  2021-06-19   \n",
       "76220  조교들 바쁜 심정 이해함 근데 우리도 돈 내고 좋은 결과 얻고 싶은데무지성 회로실험...     익명  2021-06-27   \n",
       "77848  수물2역학2는 기본으로 듣는다 치고추가로 듣는다면 다들 뭐뭐 들었어나는 물전공1 전...     익명  2021-06-30   \n",
       "\n",
       "      upload_time   view  likes  dislikes  \\\n",
       "63062       09:52   80.0    0.0       1.0   \n",
       "63063       09:55  176.0    1.0       4.0   \n",
       "63389       23:34   53.0    0.0       0.0   \n",
       "66955       23:49  271.0    0.0       0.0   \n",
       "66981       00:51  194.0    0.0       0.0   \n",
       "67433       22:54  210.0    5.0       1.0   \n",
       "67749       17:33   84.0    0.0       0.0   \n",
       "67837       20:57  164.0    0.0       0.0   \n",
       "68196       16:30  129.0    0.0       0.0   \n",
       "68955       04:59  199.0    2.0       0.0   \n",
       "69295       20:51   85.0    0.0       0.0   \n",
       "69540       10:21  190.0    0.0       0.0   \n",
       "69544       10:23  123.0    0.0       0.0   \n",
       "69547       10:25  195.0    0.0       0.0   \n",
       "69558       10:41  164.0    1.0       0.0   \n",
       "69807       17:36  173.0    5.0       0.0   \n",
       "69824       18:17  341.0    6.0       5.0   \n",
       "69965       22:31  369.0    2.0       2.0   \n",
       "71697       17:24  115.0    0.0       0.0   \n",
       "71762       19:48  126.0    1.0       1.0   \n",
       "71778       20:21  168.0    0.0       0.0   \n",
       "71910       02:20  161.0    1.0       0.0   \n",
       "72302       22:09  167.0    3.0       0.0   \n",
       "76220       18:49  255.0   13.0       0.0   \n",
       "77848       19:17  110.0    0.0       0.0   \n",
       "\n",
       "                                                comments  \\\n",
       "63062                                                      \n",
       "63063                                                이왜비   \n",
       "63389                                                      \n",
       "66955  일단 전산 고체 꿀잼, 만일 반도체로 취업하고자 한다면 고체는 무적권, ㅇㅇ 파이썬...   \n",
       "66981  광학은 진짜 그랫으면 좋겟는데 어림도업지 ㅋㅋㅋ, 양자 정성적으로 해석하는 문제 하...   \n",
       "67433  광학 족보 엄청 탐, 문제는 족보 있는 애들이 많다는거임, 물리과까지 족보에 잠식당...   \n",
       "67749                35ㅋㅋ, 20점이었나ㅌㅋ, 저는 40인데 다들 비스무리 하구먼   \n",
       "67837  각 광학장치에 대한 조온스 매트릭스를 곱하시오, 그러면 들어오는 바앙향에 따라 이 ...   \n",
       "68196     흠 난 광학보다 양자가 훨 재밌었음, 광학은 양자보단 직관적이라 덜 짜증나는거 같음   \n",
       "68955  숙제 다 풀었다고 씹가능이네, 그정도면 적어도 중간 이상은 할 수 있을거야, 다 햇...   \n",
       "69295             지나가던 물리과 내일 광학 열 끝내고 보러올게아 수요일 양자도 끝내고   \n",
       "69540  광학 미치겠다 하 , 교수님 혹시 착각하셔서 다른 과목 출제하셨나요 , ㅎㅎ몇문제풂...   \n",
       "69544                                             한문제풂ㅎㅎ   \n",
       "69547  군속도 교과서에 있었음 나 그거 낑낑대다가 쳤는데 , 아 씨 있었네 ㅋㅋㅋㅋ 이런거...   \n",
       "69558                            열역학도 되게 어렵게 내실것 같은데, 나도   \n",
       "69807  ㅋㅋㅋㅋㅋㅋㄹㅇ, 그거 원래 그럴걸 광학 전산물리 다 반년짜리 코스자너, 그럼 1이...   \n",
       "69824  예 제 직장 출연기관이용, 학사는 안받을거면서, 꾸준글 심하다야, 2222, 경영학...   \n",
       "69965  양자, 컴퓨터통신, 물리과  현대물리, 이거 ㄱㅊ 진짜 추천함ㅇㅇ, ㄴㄴ반응공학임 ...   \n",
       "71697                   ㅠㅠ맞은게없당, 몇점임 , 나 30 나왔는데 다들 몇점이야   \n",
       "71762  50점인데 헉, 50이엇나 과제 점수는 깎인거 잇어, 중간 50이 비쁠이엇던걸루 기...   \n",
       "71778                                          광학 어때, 없어   \n",
       "71910  2, 전, 물리과는 취업 위해 오는 거 아니다 마, 누가 취직하러 물리과를 감 ㅋㅋ...   \n",
       "72302                                            ㄷㄷㅋㅋ 다워   \n",
       "76220  컴공도 똑같아 물리학과를 컴공으로 바꾸고 실험물리를 컴실로 바꾸면 컴실에 대한 글이...   \n",
       "77848  나는 입자이론, 상대론, 전산물리, 고체물리, 고전물리 들었음 여기에 수학과 선대랑...   \n",
       "\n",
       "                                         comments_writer  comments_cnt  \\\n",
       "63062                                                              0.0   \n",
       "63063                                                              2.0   \n",
       "63389                                                              0.0   \n",
       "66955  고체  학부 치업하려면 무적건임, 전산은 머하는 가목임 혹시 몰라서 이번에 파이썬 ...          27.0   \n",
       "66981  ㄹㅇㅋㅋ 항상 조져지는건 나였고, 양자는 그나마 문제 경향성을 알듯말듯 하고 광학은...           8.0   \n",
       "67433          ㄹㅇ, 절평인데 좀 돌려보자고, ㄴ 서담 자료실에 올려줘도 치킨 선사함,           10.0   \n",
       "67749                                 중간 몇점이엇냐 나 딱 평균ㅋㅋㅋ           4.0   \n",
       "67837  , ㅇㅎ 이해함, 기말시험에 나온다고 미리 알려주신 문제인데 못건드리겟음ㅋㅋㅋ, 족...          14.0   \n",
       "68196                                               양자그켬           3.0   \n",
       "68955  근데 풀다풀다 답지만 하루종일 붙들고 있었던 문제도 많고 정작 어떻게 푸는건지 잘 ...           6.0   \n",
       "69295                                              기다릴께            2.0   \n",
       "69540                                                              5.0   \n",
       "69544                    오픈북도 죽쒔는데 좀 이따 열역학은 어쩌냐 답이 없다 하           2.0   \n",
       "69547                                 그래 1개도 못풀엇네 시ㅂㅋㅋㅋㅋ           5.0   \n",
       "69558                                                              2.0   \n",
       "69807               아 진짜 나 물리학과 수업 들어오면서 1,2같은 수업 첨봄ㅋㅋㅋㅋ           9.0   \n",
       "69824  예 맞아용, 석사박사하세요, 33333, 관리직도 뽑아요 연봉 나쁘지 않음, 헐 그...          47.0   \n",
       "69965                                                             22.0   \n",
       "71697                                                              3.0   \n",
       "71762                        ㅜ 중간뭐였오, 나 제출못한거많아ㅜㅜ, 부럽다ㅜㅜ           8.0   \n",
       "71778                                                              2.0   \n",
       "71910                                                              5.0   \n",
       "72302                                                              1.0   \n",
       "76220  첫번째 반박은 내가 모르는 게 아니고 내 주장에 대한 반박도 되지 못함 난 회로이론...           7.0   \n",
       "77848  입자론 상대론 고전물리  들을 엄두도 안나는 것들 다 들엇네 대단쓰, 물전2까지는 ...           4.0   \n",
       "\n",
       "       popularity                                     text_tokenized  \\\n",
       "63062         NaN  [(오, Modifier), (캠, Noun), (녹화, Noun), (햇, Nou...   \n",
       "63063         NaN          [(기프티콘, Noun), (사례, Noun), (하겠습니다, Verb)]   \n",
       "63389         NaN  [(사례, Noun), (하겠습니다, Verb), (댓글, Noun), (주세요, ...   \n",
       "66955         NaN  [(현재, Noun), (전선, Noun), (은, Josa), (광학, Noun)...   \n",
       "66981         NaN  [(양자, Noun), (고, Josa), (광학, Noun), (이고, Josa)...   \n",
       "67433         NaN                [(치킨, Noun), (사례, Noun), (함, Noun)]   \n",
       "67749         NaN  [(나, Noun), (30, Number), (나왓는, Noun), (에, Jos...   \n",
       "67837         NaN  [(이랑, Josa), (랑, Josa), (머선, Noun), (차이, Noun)...   \n",
       "68196         NaN      [(이, Noun), (게, Josa), (물리, Noun), (지, Josa)]   \n",
       "68955         NaN  [(헥트, Noun), (광학, Noun), (교재, Noun), (부랴부랴, No...   \n",
       "69295         NaN  [(내, Noun), (가, Josa), (좋아하는, Adjective), (유튜버...   \n",
       "69540         NaN                              [(ㅎ, KoreanParticle)]   \n",
       "69544         NaN  [(아, Exclamation), (ㅋㅋ, KoreanParticle), (왜, N...   \n",
       "69547         NaN  [(문제, Noun), (보자마자, Verb), (풀, Noun), (엄두, Nou...   \n",
       "69558         NaN  [(그냥, Noun), (빨리, Adverb), (자고, Noun), (싶다나는, ...   \n",
       "69807         NaN  [(전산, Noun), (물리, Noun), (1, Number), (을, Josa...   \n",
       "69824         NaN  [(지원, Noun), (해주세요, Verb), (후배, Noun), (님, Suf...   \n",
       "69965         NaN  [(이과, Noun), (중, Suffix), (에, Josa), (타, Modif...   \n",
       "71697         NaN                 [(확인, Noun), (ㄱㄱ, KoreanParticle)]   \n",
       "71762         NaN  [(15, Number), (점, Noun), (인데, Josa), (제로, Nou...   \n",
       "71778         NaN                                                 []   \n",
       "71910         NaN  [(의외로, Adverb), (반도체, Noun), (나, Josa), (광학, N...   \n",
       "72302         NaN   [(좀, Noun), (더, Noun), (주셔도, Verb), (되는데, Verb)]   \n",
       "76220         NaN  [(조교, Noun), (들, Suffix), (바쁜, Adjective), (심정...   \n",
       "77848         NaN  [(수, Modifier), (물, Noun), (2, Number), (역학, N...   \n",
       "\n",
       "                                         title_tokenized  \\\n",
       "63062  [(현대, Noun), (광학, Noun), (0601, Number), (녹화, ...   \n",
       "63063  [(현대, Noun), (광학, Noun), (0601, Number), (녹화, ...   \n",
       "63389  [(현대, Noun), (광학, Noun), (ㅈㅈㅇ, KoreanParticle)...   \n",
       "66955  [(물리, Noun), (과, Josa), (핫, Noun), (한, Determi...   \n",
       "66981               [(물리, Noun), (과, Josa), (살려줘, Verb)]   \n",
       "67433  [(물리학, Noun), (과, Josa), (광학, Noun), (기, Modif...   \n",
       "67749  [(광학, Noun), (다, Adverb), (들, Verb), (중간, Noun...   \n",
       "67837  [(광학, Noun), (이, Determiner), (거, Noun), (어케, ...   \n",
       "68196  [(양자, Noun), (공부, Noun), (하, Suffix), (다가, Nou...   \n",
       "68955               [(물리, Noun), (과, Josa), (살려주, Verb)]   \n",
       "69295  [(물잘, Verb), (알, Noun), (들, Suffix), (드루, Noun...   \n",
       "69540  [(광학, Noun), (책, Noun), (버리면, Verb), (안되겠다, Ad...   \n",
       "69544                     [(광학, Noun), (조졌다, Adjective)]   \n",
       "69547  [(광학, Noun), (쌉조졋, Noun), (네, Josa), (ㅋㅋㅋㅋ, Ko...   \n",
       "69558  [(열역학, Noun), (공부, Noun), (하기, Verb), (개, Noun...   \n",
       "69807  [(전산, Noun), (물리는, Verb), (왜, Noun), (이번, Noun...   \n",
       "69824  [(국방, Noun), (과학, Noun), (연구소, Noun), (아세요, Ve...   \n",
       "69965                [(이과, Noun), (꿀, Noun), (과목, Noun)]   \n",
       "71697   [(광학, Noun), (시험, Noun), (점수, Noun), (떳다, Noun)]   \n",
       "71762  [(광학, Noun), (다, Adverb), (들, Verb), (몇, Modif...   \n",
       "71778  [(화공, Noun), (에, Josa), (디스플레이, Noun), (관련, No...   \n",
       "71910  [(물리학, Noun), (과, Josa), (토목공학, Noun), (과, Josa)]   \n",
       "72302  [(광학, Noun), (에쁠, Noun), (두, Determiner), (명인,...   \n",
       "76220  [(실험, Noun), (물리는, Verb), (대체, Noun), (언제, Nou...   \n",
       "77848  [(물리학, Noun), (과, Josa), (전선, Noun), (보통, Noun...   \n",
       "\n",
       "                                      comments_tokenized  \\\n",
       "63062                                                 []   \n",
       "63063                      [(이, Determiner), (왜비, Noun)]   \n",
       "63389                                                 []   \n",
       "66955  [(일단, Noun), (전산, Noun), (고체, Noun), (꿀잼, Noun...   \n",
       "66981  [(광학, Noun), (은, Josa), (진짜, Noun), (그랫으, Noun...   \n",
       "67433  [(광학, Noun), (족보, Noun), (엄청, Adverb), (탐, Ver...   \n",
       "67749  [(35, Number), (ㅋㅋ, KoreanParticle), (,, Punct...   \n",
       "67837  [(각, Noun), (광학, Noun), (장치, Noun), (에, Josa),...   \n",
       "68196  [(흠, Noun), (난, Noun), (광학, Noun), (보다, Josa),...   \n",
       "68955  [(숙제, Noun), (다, Adverb), (풀었다고, Verb), (씹, Ve...   \n",
       "69295  [(지나가던, Verb), (물리, Noun), (과, Josa), (내일, Nou...   \n",
       "69540  [(광학, Noun), (미치겠다, Adjective), (하, Exclamatio...   \n",
       "69544  [(한, Determiner), (문제, Noun), (풂, Verb), (ㅎㅎ, ...   \n",
       "69547  [(군속도, Noun), (교과서, Noun), (에, Josa), (있었음, Ad...   \n",
       "69558  [(열역학, Noun), (도, Josa), (되게, Adverb), (어렵게, A...   \n",
       "69807  [(ㅋㅋㅋㅋㅋㅋㄹㅇ, KoreanParticle), (,, Punctuation),...   \n",
       "69824  [(예, Noun), (제, Noun), (직장, Noun), (출연, Noun),...   \n",
       "69965  [(양자, Noun), (,, Punctuation), (컴퓨터통신, Noun), ...   \n",
       "71697  [(ㅠㅠ, KoreanParticle), (맞은게, Verb), (없당, Adjec...   \n",
       "71762  [(50, Number), (점, Noun), (인데, Josa), (헉, Adve...   \n",
       "71778  [(광학, Noun), (어때, Adjective), (,, Punctuation)...   \n",
       "71910  [(2, Number), (,, Punctuation), (전, Noun), (,,...   \n",
       "72302   [(ㄷㄷㅋㅋ, KoreanParticle), (다, Adverb), (워, Noun)]   \n",
       "76220  [(컴공, Noun), (도, Josa), (똑같아, Adjective), (물리학...   \n",
       "77848  [(나, Noun), (는, Josa), (입자, Noun), (이론, Noun),...   \n",
       "\n",
       "                               comments_writer_tokenized  \n",
       "63062                                                 []  \n",
       "63063                                                 []  \n",
       "63389                                                 []  \n",
       "66955  [(고체, Noun), (학부, Noun), (치, Noun), (업하려면, Ver...  \n",
       "66981  [(ㄹㅇㅋㅋ, KoreanParticle), (항상, Noun), (조져지는건, A...  \n",
       "67433  [(ㄹㅇ, KoreanParticle), (,, Punctuation), (절평, ...  \n",
       "67749  [(중간, Noun), (몇, Modifier), (점, Noun), (이, Det...  \n",
       "67837  [(,, Punctuation), (ㅇㅎ, KoreanParticle), (이해, ...  \n",
       "68196                 [(양자, Noun), (그, Noun), (켬, Verb)]  \n",
       "68955  [(근데, Adverb), (풀다, Noun), (풀다, Noun), (답지, No...  \n",
       "69295                                     [(기다릴께, Verb)]  \n",
       "69540                                                 []  \n",
       "69544  [(오픈, Noun), (북도, Noun), (죽, Noun), (쒔는데, Verb...  \n",
       "69547  [(그래, Adjective), (1, Number), (개도, Noun), (못풀...  \n",
       "69558                                                 []  \n",
       "69807  [(아, Exclamation), (진짜, Noun), (나, Noun), (물리학...  \n",
       "69824  [(예, Noun), (맞아용, Verb), (,, Punctuation), (석,...  \n",
       "69965                                                 []  \n",
       "71697                                                 []  \n",
       "71762  [(ㅜ, KoreanParticle), (중간, Noun), (뭐, Noun), (...  \n",
       "71778                                                 []  \n",
       "71910                                                 []  \n",
       "72302                                                 []  \n",
       "76220  [(첫, Noun), (번째, Suffix), (반박, Noun), (은, Josa...  \n",
       "77848  [(입자, Noun), (론, Noun), (상대론, Noun), (고전, Modi...  "
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_search('광학',6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d140f0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "aa68aefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>board</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>writer</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>view</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_writer</th>\n",
       "      <th>comments_cnt</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>comments_writer_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1082901</td>\n",
       "      <td>익게2</td>\n",
       "      <td>해피뉴이어</td>\n",
       "      <td>2021년은 모두 행복한 한해가 되길</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>앗, 성지다, 첫글 ㅊㅊ, 추천 준다, 내 24살은 인생에서 가장 빛나는 날로 만들...</td>\n",
       "      <td></td>\n",
       "      <td>20.0</td>\n",
       "      <td>[(2021년, Number), (은, Foreign), (모두, Noun), (행...</td>\n",
       "      <td>[(해피뉴이어, Noun)]</td>\n",
       "      <td>[(앗, Noun), (,, Punctuation), (성지, Noun), (다, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1082902</td>\n",
       "      <td>익게2</td>\n",
       "      <td>2021년 새해복 많이받으세요</td>\n",
       "      <td>모든 일이 잘 되기를 12시 땡</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>107.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>늦었네</td>\n",
       "      <td>2빠다 ㅎㅎ, 내년에 도전한다</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(모든, Noun), (일이, Modifier), (잘, Verb), (되, Ve...</td>\n",
       "      <td>[(2021년, Number), (새해, Noun), (복, Noun), (많이, ...</td>\n",
       "      <td>[(늦었네, Verb)]</td>\n",
       "      <td>[(2, Number), (빠다, Noun), (ㅎㅎ, KoreanParticle)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082903</td>\n",
       "      <td>익게2</td>\n",
       "      <td>첫글은 내꼬</td>\n",
       "      <td>예비회계사 나다미</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ㄹㅇ 1등이네 ㅋㅋ, 실패</td>\n",
       "      <td>ㅜㅜ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(예비, Noun), (회계사, Noun), (나, Noun), (다미, Noun)]</td>\n",
       "      <td>[(첫, Modifier), (글, Noun), (은, Josa), (내꼬, Noun)]</td>\n",
       "      <td>[(ㄹㅇ, KoreanParticle), (1등, Number), (이네, Fore...</td>\n",
       "      <td>[(ㅜㅜ, KoreanParticle)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082905</td>\n",
       "      <td>익게2</td>\n",
       "      <td>땡ㅎㅎㅎㅎㅎㅎㅎ</td>\n",
       "      <td>1등</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(1등, Number)]</td>\n",
       "      <td>[(땡, Noun), (ㅎㅎㅎㅎㅎㅎㅎ, KoreanParticle)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1082906</td>\n",
       "      <td>익게2</td>\n",
       "      <td>어디 카운트 다운 하는 곳 없냐</td>\n",
       "      <td>언제바껴</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232번 불교방송</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(언, Modifier), (제바, Noun), (껴, Verb)]</td>\n",
       "      <td>[(어디, Noun), (카운트, Noun), (다운, Noun), (하는, Ver...</td>\n",
       "      <td>[(232, Number), (번, Noun), (불교, Noun), (방송, No...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77975</th>\n",
       "      <td>1200285</td>\n",
       "      <td>익게2</td>\n",
       "      <td>아버지께서 칼럼 쓰셨는데 댓글 한 번씩만 달아줄 수 있을까</td>\n",
       "      <td>2222408544049우리 아버지께서 이번에 짧은 칼럼처럼 블로그에 쓰시는 거 맡...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>23:43</td>\n",
       "      <td>5802.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>비댓으로 달래 너무 귀엽다, 이 글 조회수 늘리려면 제목 바꾸는거 추천 광고글인줄 ...</td>\n",
       "      <td>헉 피드백 반영했어 너무 고마워, 엇 아마 확인은 못하실 텐데 비댓이든 공개댓이든 ...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>[(2222408544049, Number), (우리, Noun), (아버지, No...</td>\n",
       "      <td>[(아버지, Noun), (께서, Josa), (칼럼, Noun), (쓰셨는데, V...</td>\n",
       "      <td>[(비댓, Noun), (으로, Josa), (달래, Noun), (너무, Adve...</td>\n",
       "      <td>[(헉, Adverb), (피드백, Noun), (반영, Noun), (했어, Ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77976</th>\n",
       "      <td>1200287</td>\n",
       "      <td>익게2</td>\n",
       "      <td>프로포폴 하면 기분이 좋음</td>\n",
       "      <td>하는거 신기하네하면 힙해보여서 하는건가</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>23:47</td>\n",
       "      <td>373.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>썰로 들은 거라 정확하지는 않는데 지방흡입할 때 고통 줄이려고 프로포폴 투약하다가 ...</td>\n",
       "      <td></td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(하는거, Verb), (신기하네하면, Adjective), (힙, Noun), ...</td>\n",
       "      <td>[(프로포폴, Noun), (하면, Verb), (기분, Noun), (이, Jos...</td>\n",
       "      <td>[(썰로, Verb), (들은, Verb), (거, Noun), (라, Josa),...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77977</th>\n",
       "      <td>1200288</td>\n",
       "      <td>익게2</td>\n",
       "      <td>취업 후기 쓰려는데 안올라간다ㅠ</td>\n",
       "      <td>손다쳐서 폰으로 열심히 적었는데나한테왜 이래ㅠ혹시 뭔가 지켜야 하는 양식이 있나요ㅠ...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>23:49</td>\n",
       "      <td>387.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>중간에 임티 넣었었어, 임티, 1 이모티콘 빼기2 사진 많으면 업로드 될 동안 조금...</td>\n",
       "      <td>이건 되네</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[(손, Noun), (다쳐서, Verb), (폰, Noun), (으로, Josa)...</td>\n",
       "      <td>[(취업, Noun), (후기, Noun), (쓰려는데, Verb), (안, Ver...</td>\n",
       "      <td>[(중간, Noun), (에, Josa), (임티, Noun), (넣었었어, Ver...</td>\n",
       "      <td>[(이건, Noun), (되네, Verb)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77978</th>\n",
       "      <td>1200291</td>\n",
       "      <td>익게2</td>\n",
       "      <td>간떨어지는동거 보는 사람</td>\n",
       "      <td>아 이번주 기대했는데                                예고편...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>23:55</td>\n",
       "      <td>138.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>너무 오글거리는데 장기용때매 봄 ㅎㅎ, 난 계선우땜에 봐ㅠㅠ, 나도 계선우 때문에 ...</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(아, Exclamation), (이번, Noun), (주, Noun), (기대했...</td>\n",
       "      <td>[(간, Noun), (떨어지는, Verb), (동거, Noun), (보는, Ver...</td>\n",
       "      <td>[(너무, Adverb), (오글거리는데, Verb), (장기, Noun), (용때...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77979</th>\n",
       "      <td>1200293</td>\n",
       "      <td>익게2</td>\n",
       "      <td>오타루 오마카세 후기</td>\n",
       "      <td>전에 어떤 다미가 추천한거 보고 오늘 가봤어ㅎㅎ디너 오마카세 가격은 55,000원이...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>23:59</td>\n",
       "      <td>869.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>맛있겠다, 김을 안 주는게 아쉽다, 너무 괜찮은데 와 나도 가보고싶다지방다미, 와 ...</td>\n",
       "      <td>존맛 꼭가봐ㅎㅎ, 아무래도 가격이 가격인지라 전반적으로 딱 기본에 충실한 느낌이긴 ...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[(전, Noun), (에, Josa), (어떤, Adjective), (다미, N...</td>\n",
       "      <td>[(오타루, Noun), (오, Modifier), (마카, Noun), (세, N...</td>\n",
       "      <td>[(맛있겠다, Adjective), (,, Punctuation), (김, Noun...</td>\n",
       "      <td>[(존맛, Noun), (꼭, Noun), (가봐, Verb), (ㅎㅎ, Korea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77980 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           num board                             title  \\\n",
       "0      1082901   익게2                             해피뉴이어   \n",
       "1      1082902   익게2                  2021년 새해복 많이받으세요   \n",
       "2      1082903   익게2                            첫글은 내꼬   \n",
       "3      1082905   익게2                          땡ㅎㅎㅎㅎㅎㅎㅎ   \n",
       "4      1082906   익게2                 어디 카운트 다운 하는 곳 없냐   \n",
       "...        ...   ...                               ...   \n",
       "77975  1200285   익게2  아버지께서 칼럼 쓰셨는데 댓글 한 번씩만 달아줄 수 있을까   \n",
       "77976  1200287   익게2                    프로포폴 하면 기분이 좋음   \n",
       "77977  1200288   익게2                 취업 후기 쓰려는데 안올라간다ㅠ   \n",
       "77978  1200291   익게2                     간떨어지는동거 보는 사람   \n",
       "77979  1200293   익게2                       오타루 오마카세 후기   \n",
       "\n",
       "                                                    text writer upload_date  \\\n",
       "0                                   2021년은 모두 행복한 한해가 되길     익명  2021-01-01   \n",
       "1                                      모든 일이 잘 되기를 12시 땡     익명  2021-01-01   \n",
       "2                                              예비회계사 나다미     익명  2021-01-01   \n",
       "3                                                     1등     익명  2021-01-01   \n",
       "4                                                   언제바껴     익명  2021-01-01   \n",
       "...                                                  ...    ...         ...   \n",
       "77975  2222408544049우리 아버지께서 이번에 짧은 칼럼처럼 블로그에 쓰시는 거 맡...     익명  2021-06-30   \n",
       "77976                              하는거 신기하네하면 힙해보여서 하는건가     익명  2021-06-30   \n",
       "77977  손다쳐서 폰으로 열심히 적었는데나한테왜 이래ㅠ혹시 뭔가 지켜야 하는 양식이 있나요ㅠ...     익명  2021-06-30   \n",
       "77978  아 이번주 기대했는데                                예고편...     익명  2021-06-30   \n",
       "77979  전에 어떤 다미가 추천한거 보고 오늘 가봤어ㅎㅎ디너 오마카세 가격은 55,000원이...     익명  2021-06-30   \n",
       "\n",
       "      upload_time    view  likes  dislikes  \\\n",
       "0           00:00  1343.0  195.0       0.0   \n",
       "1           00:00   107.0    3.0       0.0   \n",
       "2           00:00   139.0    1.0       0.0   \n",
       "3           00:00    39.0    0.0       0.0   \n",
       "4           00:00    84.0    0.0       0.0   \n",
       "...           ...     ...    ...       ...   \n",
       "77975       23:43  5802.0  374.0      11.0   \n",
       "77976       23:47   373.0    1.0       1.0   \n",
       "77977       23:49   387.0    3.0       0.0   \n",
       "77978       23:55   138.0    6.0       0.0   \n",
       "77979       23:59   869.0   24.0       0.0   \n",
       "\n",
       "                                                comments  \\\n",
       "0      앗, 성지다, 첫글 ㅊㅊ, 추천 준다, 내 24살은 인생에서 가장 빛나는 날로 만들...   \n",
       "1                                                    늦었네   \n",
       "2                                         ㄹㅇ 1등이네 ㅋㅋ, 실패   \n",
       "3                                                          \n",
       "4                                              232번 불교방송   \n",
       "...                                                  ...   \n",
       "77975  비댓으로 달래 너무 귀엽다, 이 글 조회수 늘리려면 제목 바꾸는거 추천 광고글인줄 ...   \n",
       "77976  썰로 들은 거라 정확하지는 않는데 지방흡입할 때 고통 줄이려고 프로포폴 투약하다가 ...   \n",
       "77977  중간에 임티 넣었었어, 임티, 1 이모티콘 빼기2 사진 많으면 업로드 될 동안 조금...   \n",
       "77978  너무 오글거리는데 장기용때매 봄 ㅎㅎ, 난 계선우땜에 봐ㅠㅠ, 나도 계선우 때문에 ...   \n",
       "77979  맛있겠다, 김을 안 주는게 아쉽다, 너무 괜찮은데 와 나도 가보고싶다지방다미, 와 ...   \n",
       "\n",
       "                                         comments_writer  comments_cnt  \\\n",
       "0                                                                 20.0   \n",
       "1                                       2빠다 ㅎㅎ, 내년에 도전한다           3.0   \n",
       "2                                                     ㅜㅜ           3.0   \n",
       "3                                                                  0.0   \n",
       "4                                                                  1.0   \n",
       "...                                                  ...           ...   \n",
       "77975  헉 피드백 반영했어 너무 고마워, 엇 아마 확인은 못하실 텐데 비댓이든 공개댓이든 ...          75.0   \n",
       "77976                                                              5.0   \n",
       "77977                                              이건 되네           7.0   \n",
       "77978                                                              3.0   \n",
       "77979  존맛 꼭가봐ㅎㅎ, 아무래도 가격이 가격인지라 전반적으로 딱 기본에 충실한 느낌이긴 ...          16.0   \n",
       "\n",
       "                                          text_tokenized  \\\n",
       "0      [(2021년, Number), (은, Foreign), (모두, Noun), (행...   \n",
       "1      [(모든, Noun), (일이, Modifier), (잘, Verb), (되, Ve...   \n",
       "2       [(예비, Noun), (회계사, Noun), (나, Noun), (다미, Noun)]   \n",
       "3                                         [(1등, Number)]   \n",
       "4                 [(언, Modifier), (제바, Noun), (껴, Verb)]   \n",
       "...                                                  ...   \n",
       "77975  [(2222408544049, Number), (우리, Noun), (아버지, No...   \n",
       "77976  [(하는거, Verb), (신기하네하면, Adjective), (힙, Noun), ...   \n",
       "77977  [(손, Noun), (다쳐서, Verb), (폰, Noun), (으로, Josa)...   \n",
       "77978  [(아, Exclamation), (이번, Noun), (주, Noun), (기대했...   \n",
       "77979  [(전, Noun), (에, Josa), (어떤, Adjective), (다미, N...   \n",
       "\n",
       "                                         title_tokenized  \\\n",
       "0                                        [(해피뉴이어, Noun)]   \n",
       "1      [(2021년, Number), (새해, Noun), (복, Noun), (많이, ...   \n",
       "2      [(첫, Modifier), (글, Noun), (은, Josa), (내꼬, Noun)]   \n",
       "3                 [(땡, Noun), (ㅎㅎㅎㅎㅎㅎㅎ, KoreanParticle)]   \n",
       "4      [(어디, Noun), (카운트, Noun), (다운, Noun), (하는, Ver...   \n",
       "...                                                  ...   \n",
       "77975  [(아버지, Noun), (께서, Josa), (칼럼, Noun), (쓰셨는데, V...   \n",
       "77976  [(프로포폴, Noun), (하면, Verb), (기분, Noun), (이, Jos...   \n",
       "77977  [(취업, Noun), (후기, Noun), (쓰려는데, Verb), (안, Ver...   \n",
       "77978  [(간, Noun), (떨어지는, Verb), (동거, Noun), (보는, Ver...   \n",
       "77979  [(오타루, Noun), (오, Modifier), (마카, Noun), (세, N...   \n",
       "\n",
       "                                      comments_tokenized  \\\n",
       "0      [(앗, Noun), (,, Punctuation), (성지, Noun), (다, ...   \n",
       "1                                          [(늦었네, Verb)]   \n",
       "2      [(ㄹㅇ, KoreanParticle), (1등, Number), (이네, Fore...   \n",
       "3                                                     []   \n",
       "4      [(232, Number), (번, Noun), (불교, Noun), (방송, No...   \n",
       "...                                                  ...   \n",
       "77975  [(비댓, Noun), (으로, Josa), (달래, Noun), (너무, Adve...   \n",
       "77976  [(썰로, Verb), (들은, Verb), (거, Noun), (라, Josa),...   \n",
       "77977  [(중간, Noun), (에, Josa), (임티, Noun), (넣었었어, Ver...   \n",
       "77978  [(너무, Adverb), (오글거리는데, Verb), (장기, Noun), (용때...   \n",
       "77979  [(맛있겠다, Adjective), (,, Punctuation), (김, Noun...   \n",
       "\n",
       "                               comments_writer_tokenized  \n",
       "0                                                     []  \n",
       "1      [(2, Number), (빠다, Noun), (ㅎㅎ, KoreanParticle)...  \n",
       "2                                 [(ㅜㅜ, KoreanParticle)]  \n",
       "3                                                     []  \n",
       "4                                                     []  \n",
       "...                                                  ...  \n",
       "77975  [(헉, Adverb), (피드백, Noun), (반영, Noun), (했어, Ve...  \n",
       "77976                                                 []  \n",
       "77977                           [(이건, Noun), (되네, Verb)]  \n",
       "77978                                                 []  \n",
       "77979  [(존맛, Noun), (꼭, Noun), (가봐, Verb), (ㅎㅎ, Korea...  \n",
       "\n",
       "[77980 rows x 17 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "502eb0cd",
   "metadata": {},
   "source": [
    "## ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "id": "e87b2de4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "4\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15264/2476273054.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mPosts_mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumofposts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15264/1827098987.py\u001b[0m in \u001b[0;36mnumofposts\u001b[1;34m(word, month)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnumofposts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_urls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15264/1827098987.py\u001b[0m in \u001b[0;36ms_search\u001b[1;34m(word, month, show_urls)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0ms_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_urls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdf_month\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload_date\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mmonth\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtitle_cd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle_tokenized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msearch_cd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtext_cd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_tokenized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msearch_cd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4135\u001b[0m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4137\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4138\u001b[0m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5875\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5876\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5877\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5878\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m     ) -> \"BlockManager\":\n\u001b[1;32m--> 631\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     def convert(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   2280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2281\u001b[0m         \u001b[1;31m# delegate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2282\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2284\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_can_hold_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m             \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mget_values\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2173\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m             \u001b[1;31m# DTA/TDA constructor and astype can handle 2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2175\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_holder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2176\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_period_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_period\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdtl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatetimeLikeArrayMixin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[1;31m# -----------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masi8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_string_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py\u001b[0m in \u001b[0;36m_box_values\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mapply\u001b[0m \u001b[0mbox\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0mto\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36m_box_func\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[1;31m# Descriptive Properties\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m_box_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNaTType\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Posts_mat = np.zeros((7,len(idx_extended)))\n",
    "for i, key in enumerate(idx_extended):\n",
    "    print(i)\n",
    "    for j in range(1,7):\n",
    "        print(j)\n",
    "        Posts_mat[j,i] = numofposts(key,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bafde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('posts_mat.pkl','wb') as f:\n",
    "    pickle.dump(Posts_mat,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
