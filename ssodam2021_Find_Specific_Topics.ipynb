{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57cecfd",
   "metadata": {},
   "source": [
    "## Load_Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28e335c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe93dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7cec958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data_l/ssodam2021_tokenized.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69abbb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num                                                                    1082901\n",
       "board                                                                      익게2\n",
       "title                                                                    해피뉴이어\n",
       "text                                                      2021년은 모두 행복한 한해가 되길\n",
       "writer                                                                      익명\n",
       "upload_date                                                         2021/01/01\n",
       "upload_time                                                              00:00\n",
       "view                                                                    1343.0\n",
       "likes                                                                    195.0\n",
       "dislikes                                                                   0.0\n",
       "comments                     앗, 성지다, 첫글 ㅊㅊ, 추천 준다, 내 24살은 인생에서 가장 빛나는 날로 만들...\n",
       "comments_writer                                                            NaN\n",
       "comments_cnt                                                              20.0\n",
       "text_tokenized               [('2021년', 'Number'), ('은', 'Foreign'), ('모두',...\n",
       "title_tokenized                                            [('해피뉴이어', 'Noun')]\n",
       "comments_tokenized           [('앗', 'Noun'), (',', 'Punctuation'), ('성지', '...\n",
       "comments_writer_tokenized                                                  NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af5a477",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87e537a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_list_from_str(msg):\n",
    "    try :\n",
    "        return [tuple([re.sub(\"'\",'',y) for y in re.findall('\\'.*?\\'',x)]) for x in re.findall('\\(.*?\\)',msg)]\n",
    "    except :\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9a4bb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')\n",
    "df.text_tokenized = df.text_tokenized.apply(lambda x: get_noun_list_from_str(x))\n",
    "df.title_tokenized = df.title_tokenized.apply(lambda x: get_noun_list_from_str(x))\n",
    "df.comments_tokenized = df.comments_tokenized.apply(lambda x: get_noun_list_from_str(x))\n",
    "df.comments_writer_tokenized = df.comments_writer_tokenized.apply(lambda x: get_noun_list_from_str(x))\n",
    "df.upload_date = pd.to_datetime(df.upload_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e47fcdb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>board</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>writer</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>view</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_writer</th>\n",
       "      <th>comments_cnt</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>comments_writer_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1082901</td>\n",
       "      <td>익게2</td>\n",
       "      <td>해피뉴이어</td>\n",
       "      <td>2021년은 모두 행복한 한해가 되길</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>앗, 성지다, 첫글 ㅊㅊ, 추천 준다, 내 24살은 인생에서 가장 빛나는 날로 만들...</td>\n",
       "      <td></td>\n",
       "      <td>20.0</td>\n",
       "      <td>[(2021년, Number), (은, Foreign), (모두, Noun), (행...</td>\n",
       "      <td>[(해피뉴이어, Noun)]</td>\n",
       "      <td>[(앗, Noun), (,, Punctuation), (성지, Noun), (다, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1082902</td>\n",
       "      <td>익게2</td>\n",
       "      <td>2021년 새해복 많이받으세요</td>\n",
       "      <td>모든 일이 잘 되기를 12시 땡</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>107.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>늦었네</td>\n",
       "      <td>2빠다 ㅎㅎ, 내년에 도전한다</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(모든, Noun), (일이, Modifier), (잘, Verb), (되, Ve...</td>\n",
       "      <td>[(2021년, Number), (새해, Noun), (복, Noun), (많이, ...</td>\n",
       "      <td>[(늦었네, Verb)]</td>\n",
       "      <td>[(2, Number), (빠다, Noun), (ㅎㅎ, KoreanParticle)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082903</td>\n",
       "      <td>익게2</td>\n",
       "      <td>첫글은 내꼬</td>\n",
       "      <td>예비회계사 나다미</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ㄹㅇ 1등이네 ㅋㅋ, 실패</td>\n",
       "      <td>ㅜㅜ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(예비, Noun), (회계사, Noun), (나, Noun), (다미, Noun)]</td>\n",
       "      <td>[(첫, Modifier), (글, Noun), (은, Josa), (내꼬, Noun)]</td>\n",
       "      <td>[(ㄹㅇ, KoreanParticle), (1등, Number), (이네, Fore...</td>\n",
       "      <td>[(ㅜㅜ, KoreanParticle)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082905</td>\n",
       "      <td>익게2</td>\n",
       "      <td>땡ㅎㅎㅎㅎㅎㅎㅎ</td>\n",
       "      <td>1등</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(1등, Number)]</td>\n",
       "      <td>[(땡, Noun), (ㅎㅎㅎㅎㅎㅎㅎ, KoreanParticle)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1082906</td>\n",
       "      <td>익게2</td>\n",
       "      <td>어디 카운트 다운 하는 곳 없냐</td>\n",
       "      <td>언제바껴</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232번 불교방송</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(언, Modifier), (제바, Noun), (껴, Verb)]</td>\n",
       "      <td>[(어디, Noun), (카운트, Noun), (다운, Noun), (하는, Ver...</td>\n",
       "      <td>[(232, Number), (번, Noun), (불교, Noun), (방송, No...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num board              title                  text writer upload_date  \\\n",
       "0  1082901   익게2              해피뉴이어  2021년은 모두 행복한 한해가 되길     익명  2021-01-01   \n",
       "1  1082902   익게2   2021년 새해복 많이받으세요     모든 일이 잘 되기를 12시 땡     익명  2021-01-01   \n",
       "2  1082903   익게2             첫글은 내꼬             예비회계사 나다미     익명  2021-01-01   \n",
       "3  1082905   익게2           땡ㅎㅎㅎㅎㅎㅎㅎ                    1등     익명  2021-01-01   \n",
       "4  1082906   익게2  어디 카운트 다운 하는 곳 없냐                  언제바껴     익명  2021-01-01   \n",
       "\n",
       "  upload_time    view  likes  dislikes  \\\n",
       "0       00:00  1343.0  195.0       0.0   \n",
       "1       00:00   107.0    3.0       0.0   \n",
       "2       00:00   139.0    1.0       0.0   \n",
       "3       00:00    39.0    0.0       0.0   \n",
       "4       00:00    84.0    0.0       0.0   \n",
       "\n",
       "                                            comments   comments_writer  \\\n",
       "0  앗, 성지다, 첫글 ㅊㅊ, 추천 준다, 내 24살은 인생에서 가장 빛나는 날로 만들...                     \n",
       "1                                                늦었네  2빠다 ㅎㅎ, 내년에 도전한다   \n",
       "2                                     ㄹㅇ 1등이네 ㅋㅋ, 실패                ㅜㅜ   \n",
       "3                                                                        \n",
       "4                                          232번 불교방송                     \n",
       "\n",
       "   comments_cnt                                     text_tokenized  \\\n",
       "0          20.0  [(2021년, Number), (은, Foreign), (모두, Noun), (행...   \n",
       "1           3.0  [(모든, Noun), (일이, Modifier), (잘, Verb), (되, Ve...   \n",
       "2           3.0   [(예비, Noun), (회계사, Noun), (나, Noun), (다미, Noun)]   \n",
       "3           0.0                                     [(1등, Number)]   \n",
       "4           1.0             [(언, Modifier), (제바, Noun), (껴, Verb)]   \n",
       "\n",
       "                                     title_tokenized  \\\n",
       "0                                    [(해피뉴이어, Noun)]   \n",
       "1  [(2021년, Number), (새해, Noun), (복, Noun), (많이, ...   \n",
       "2  [(첫, Modifier), (글, Noun), (은, Josa), (내꼬, Noun)]   \n",
       "3             [(땡, Noun), (ㅎㅎㅎㅎㅎㅎㅎ, KoreanParticle)]   \n",
       "4  [(어디, Noun), (카운트, Noun), (다운, Noun), (하는, Ver...   \n",
       "\n",
       "                                  comments_tokenized  \\\n",
       "0  [(앗, Noun), (,, Punctuation), (성지, Noun), (다, ...   \n",
       "1                                      [(늦었네, Verb)]   \n",
       "2  [(ㄹㅇ, KoreanParticle), (1등, Number), (이네, Fore...   \n",
       "3                                                 []   \n",
       "4  [(232, Number), (번, Noun), (불교, Noun), (방송, No...   \n",
       "\n",
       "                           comments_writer_tokenized  \n",
       "0                                                 []  \n",
       "1  [(2, Number), (빠다, Noun), (ㅎㅎ, KoreanParticle)...  \n",
       "2                             [(ㅜㅜ, KoreanParticle)]  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182b8e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data_l/ssodam2021_tokenized_df.pkl','rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9c89b4",
   "metadata": {},
   "source": [
    "## BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "050c3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 load\n",
    "with open('./data/stopwords.txt',encoding='utf-8') as f:\n",
    "    stopwords = f.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "8d74cd0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('잘', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n",
      "('못', 'VerbPrefix')\n",
      "('잘', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n",
      "('잘', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n",
      "('잘', 'VerbPrefix')\n",
      "('안', 'VerbPrefix')\n"
     ]
    }
   ],
   "source": [
    "#형태소 체크\n",
    "limit = 0\n",
    "for row in df.total_tokens:\n",
    "    if limit > 10:\n",
    "        break\n",
    "    for tup in row:\n",
    "        if tup[1]=='VerbPrefix':\n",
    "            print(tup)\n",
    "            limit += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c7693a",
   "metadata": {},
   "source": [
    "### 익게2 데이터로부터 BoW 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "f7521b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Token's Bag of Words\n",
    "corpus = []\n",
    "for column in ['total_tokens']:\n",
    "    for text in df.loc[df['board']=='익게2',column]:\n",
    "        for word in text:\n",
    "            if word[1]=='Noun':\n",
    "                if word[0] not in stopwords:\n",
    "                    corpus.append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "851e406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_total = {}\n",
    "bow_total = []\n",
    "\n",
    "for token in corpus:\n",
    "    if token not in idx_total.keys():\n",
    "        idx_total[token] = len(idx_total)\n",
    "        bow_total.insert(len(idx_total)-1,1)\n",
    "    else:\n",
    "        bow_total[idx_total[token]] += 1\n",
    "        \n",
    "idx_key = list(idx_total.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9314b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/idx_total.pkl','rb') as f:\n",
    "    idx_total = pickle.load(f)\n",
    "with open('./data/bow_total.pkl','rb') as f:\n",
    "    bow_total = pickle.load(f)\n",
    "idx_key = list(idx_total.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29484a6a",
   "metadata": {},
   "source": [
    "### 익게2의 각 날짜별 BoW 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4c42e40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe5178af9cc4ec4ba155783cc44cf2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "#corpus for each day\n",
    "cfd = pd.DataFrame(columns=['upload_date','BoW'])\n",
    "\n",
    "for date in tqdm(pd.date_range(datetime(2021,1,1), datetime(2021,7,1))):\n",
    "    bow = np.zeros(len(idx_total.keys()))\n",
    "    \n",
    "    for token in df.loc[(df.board=='익게2') & (df.upload_date==date),'total_tokens']:\n",
    "        bow_temp = np.zeros(len(idx_total.keys()))\n",
    "        for word in token:\n",
    "            if (word[1]=='Noun') and (word[0] not in stopwords):\n",
    "                try:\n",
    "                    bow_temp[idx_total[word[0]]] += 1\n",
    "                except:\n",
    "                    print('Error occured')\n",
    "        bow_temp[bow_temp>10] = 0\n",
    "        bow += bow_temp            \n",
    "    cfd.loc[len(cfd)] = [date, bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c46ed8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_l/cfd.pkl','rb') as f:\n",
    "    cfd = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04ca3b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.,  1., 29., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 41., ...,  0.,  0.,  0.],\n",
       "       [ 2.,  3., 42., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 1.,  3., 53., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  3., 54., ...,  1.,  2.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BoW 매트릭스\n",
    "BoW_mat = np.array([list(value) for value in cfd.BoW.values])\n",
    "BoW_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc9a3c0",
   "metadata": {},
   "source": [
    "###  Word별 일일 게시글 수 탐색 (시간 관계상 실패)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "257f18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_words(x):\n",
    "    output = []\n",
    "    for token in x:\n",
    "        if len(token)>1:\n",
    "            output.append(token[0])\n",
    "        else:\n",
    "            pass\n",
    "    return output\n",
    "\n",
    "df['total_tokens'] = df.title_tokenized + df.text_tokenized + df.comments_tokenized + df.comments_writer_tokenized\n",
    "df['_total_tokens'] = df['total_tokens'].apply(lambda x : return_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "34648e79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>board</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>writer</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>view</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_writer</th>\n",
       "      <th>comments_cnt</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>comments_writer_tokenized</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>_total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1082901</td>\n",
       "      <td>익게2</td>\n",
       "      <td>해피뉴이어</td>\n",
       "      <td>2021년은 모두 행복한 한해가 되길</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>앗, 성지다, 첫글 ㅊㅊ, 추천 준다, 내 24살은 인생에서 가장 빛나는 날로 만들...</td>\n",
       "      <td></td>\n",
       "      <td>20.0</td>\n",
       "      <td>[(2021년, Number), (은, Foreign), (모두, Noun), (행...</td>\n",
       "      <td>[(해피뉴이어, Noun)]</td>\n",
       "      <td>[(앗, Noun), (,, Punctuation), (성지, Noun), (다, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(해피뉴이어, Noun), (2021년, Number), (은, Foreign),...</td>\n",
       "      <td>[해피뉴이어, 2021년, 은, 모두, 행복한, 한해, 가, 되길, 앗, ,, 성지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1082902</td>\n",
       "      <td>익게2</td>\n",
       "      <td>2021년 새해복 많이받으세요</td>\n",
       "      <td>모든 일이 잘 되기를 12시 땡</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>107.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>늦었네</td>\n",
       "      <td>2빠다 ㅎㅎ, 내년에 도전한다</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(모든, Noun), (일이, Modifier), (잘, Verb), (되, Ve...</td>\n",
       "      <td>[(2021년, Number), (새해, Noun), (복, Noun), (많이, ...</td>\n",
       "      <td>[(늦었네, Verb)]</td>\n",
       "      <td>[(2, Number), (빠다, Noun), (ㅎㅎ, KoreanParticle)...</td>\n",
       "      <td>[(2021년, Number), (새해, Noun), (복, Noun), (많이, ...</td>\n",
       "      <td>[2021년, 새해, 복, 많이, 받으세요, 모든, 일이, 잘, 되, 기를, 12시...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082903</td>\n",
       "      <td>익게2</td>\n",
       "      <td>첫글은 내꼬</td>\n",
       "      <td>예비회계사 나다미</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ㄹㅇ 1등이네 ㅋㅋ, 실패</td>\n",
       "      <td>ㅜㅜ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(예비, Noun), (회계사, Noun), (나, Noun), (다미, Noun)]</td>\n",
       "      <td>[(첫, Modifier), (글, Noun), (은, Josa), (내꼬, Noun)]</td>\n",
       "      <td>[(ㄹㅇ, KoreanParticle), (1등, Number), (이네, Fore...</td>\n",
       "      <td>[(ㅜㅜ, KoreanParticle)]</td>\n",
       "      <td>[(첫, Modifier), (글, Noun), (은, Josa), (내꼬, Nou...</td>\n",
       "      <td>[첫, 글, 은, 내꼬, 예비, 회계사, 나, 다미, ㄹㅇ, 1등, 이네, ㅋㅋ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082905</td>\n",
       "      <td>익게2</td>\n",
       "      <td>땡ㅎㅎㅎㅎㅎㅎㅎ</td>\n",
       "      <td>1등</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(1등, Number)]</td>\n",
       "      <td>[(땡, Noun), (ㅎㅎㅎㅎㅎㅎㅎ, KoreanParticle)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(땡, Noun), (ㅎㅎㅎㅎㅎㅎㅎ, KoreanParticle), (1등, Nu...</td>\n",
       "      <td>[땡, ㅎㅎㅎㅎㅎㅎㅎ, 1등]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1082906</td>\n",
       "      <td>익게2</td>\n",
       "      <td>어디 카운트 다운 하는 곳 없냐</td>\n",
       "      <td>언제바껴</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232번 불교방송</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(언, Modifier), (제바, Noun), (껴, Verb)]</td>\n",
       "      <td>[(어디, Noun), (카운트, Noun), (다운, Noun), (하는, Ver...</td>\n",
       "      <td>[(232, Number), (번, Noun), (불교, Noun), (방송, No...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(어디, Noun), (카운트, Noun), (다운, Noun), (하는, Ver...</td>\n",
       "      <td>[어디, 카운트, 다운, 하는, 곳, 없냐, 언, 제바, 껴, 232, 번, 불교,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num board              title                  text writer upload_date  \\\n",
       "0  1082901   익게2              해피뉴이어  2021년은 모두 행복한 한해가 되길     익명  2021-01-01   \n",
       "1  1082902   익게2   2021년 새해복 많이받으세요     모든 일이 잘 되기를 12시 땡     익명  2021-01-01   \n",
       "2  1082903   익게2             첫글은 내꼬             예비회계사 나다미     익명  2021-01-01   \n",
       "3  1082905   익게2           땡ㅎㅎㅎㅎㅎㅎㅎ                    1등     익명  2021-01-01   \n",
       "4  1082906   익게2  어디 카운트 다운 하는 곳 없냐                  언제바껴     익명  2021-01-01   \n",
       "\n",
       "  upload_time    view  likes  dislikes  \\\n",
       "0       00:00  1343.0  195.0       0.0   \n",
       "1       00:00   107.0    3.0       0.0   \n",
       "2       00:00   139.0    1.0       0.0   \n",
       "3       00:00    39.0    0.0       0.0   \n",
       "4       00:00    84.0    0.0       0.0   \n",
       "\n",
       "                                            comments   comments_writer  \\\n",
       "0  앗, 성지다, 첫글 ㅊㅊ, 추천 준다, 내 24살은 인생에서 가장 빛나는 날로 만들...                     \n",
       "1                                                늦었네  2빠다 ㅎㅎ, 내년에 도전한다   \n",
       "2                                     ㄹㅇ 1등이네 ㅋㅋ, 실패                ㅜㅜ   \n",
       "3                                                                        \n",
       "4                                          232번 불교방송                     \n",
       "\n",
       "   comments_cnt                                     text_tokenized  \\\n",
       "0          20.0  [(2021년, Number), (은, Foreign), (모두, Noun), (행...   \n",
       "1           3.0  [(모든, Noun), (일이, Modifier), (잘, Verb), (되, Ve...   \n",
       "2           3.0   [(예비, Noun), (회계사, Noun), (나, Noun), (다미, Noun)]   \n",
       "3           0.0                                     [(1등, Number)]   \n",
       "4           1.0             [(언, Modifier), (제바, Noun), (껴, Verb)]   \n",
       "\n",
       "                                     title_tokenized  \\\n",
       "0                                    [(해피뉴이어, Noun)]   \n",
       "1  [(2021년, Number), (새해, Noun), (복, Noun), (많이, ...   \n",
       "2  [(첫, Modifier), (글, Noun), (은, Josa), (내꼬, Noun)]   \n",
       "3             [(땡, Noun), (ㅎㅎㅎㅎㅎㅎㅎ, KoreanParticle)]   \n",
       "4  [(어디, Noun), (카운트, Noun), (다운, Noun), (하는, Ver...   \n",
       "\n",
       "                                  comments_tokenized  \\\n",
       "0  [(앗, Noun), (,, Punctuation), (성지, Noun), (다, ...   \n",
       "1                                      [(늦었네, Verb)]   \n",
       "2  [(ㄹㅇ, KoreanParticle), (1등, Number), (이네, Fore...   \n",
       "3                                                 []   \n",
       "4  [(232, Number), (번, Noun), (불교, Noun), (방송, No...   \n",
       "\n",
       "                           comments_writer_tokenized  \\\n",
       "0                                                 []   \n",
       "1  [(2, Number), (빠다, Noun), (ㅎㅎ, KoreanParticle)...   \n",
       "2                             [(ㅜㅜ, KoreanParticle)]   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                        total_tokens  \\\n",
       "0  [(해피뉴이어, Noun), (2021년, Number), (은, Foreign),...   \n",
       "1  [(2021년, Number), (새해, Noun), (복, Noun), (많이, ...   \n",
       "2  [(첫, Modifier), (글, Noun), (은, Josa), (내꼬, Nou...   \n",
       "3  [(땡, Noun), (ㅎㅎㅎㅎㅎㅎㅎ, KoreanParticle), (1등, Nu...   \n",
       "4  [(어디, Noun), (카운트, Noun), (다운, Noun), (하는, Ver...   \n",
       "\n",
       "                                       _total_tokens  \n",
       "0  [해피뉴이어, 2021년, 은, 모두, 행복한, 한해, 가, 되길, 앗, ,, 성지...  \n",
       "1  [2021년, 새해, 복, 많이, 받으세요, 모든, 일이, 잘, 되, 기를, 12시...  \n",
       "2  [첫, 글, 은, 내꼬, 예비, 회계사, 나, 다미, ㄹㅇ, 1등, 이네, ㅋㅋ, ...  \n",
       "3                                   [땡, ㅎㅎㅎㅎㅎㅎㅎ, 1등]  \n",
       "4  [어디, 카운트, 다운, 하는, 곳, 없냐, 언, 제바, 껴, 232, 번, 불교,...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fedeec",
   "metadata": {},
   "source": [
    "__일별 토큰 합치기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6752f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "#날짜 인덱스 정의\n",
    "date_range = pd.date_range(datetime(2021,1,1), periods=181)\n",
    "#빈 array 생성\n",
    "day_total = [[] for i in range(181)]\n",
    "for i, day in enumerate(date_range):\n",
    "    # 해당 일자 탐색\n",
    "    _df = df[df.upload_date==day].reset_index(drop=True)\n",
    "    # 당일 토큰 병합\n",
    "    for idx in range(len(_df)):\n",
    "        # 익게2로 제한\n",
    "        if _df.board[idx] == '익게2':\n",
    "            row = _df.loc[idx]\n",
    "            day_total[i] += row._total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce3df7a",
   "metadata": {},
   "source": [
    "__단어별 일일 게시글 수 계산__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ab8931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(word ,X):\n",
    "    count = 0\n",
    "    for x in X:\n",
    "        if x == word:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "posts_total = np.zeros((181,len(idx_total)))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for j in tqdm(range(0,181)):\n",
    "    _day_total = day_total[j]\n",
    "    for i, word in tqdm(enumerate(idx_total)):\n",
    "        counts = get_count(word, _day_total)\n",
    "        posts_total[j,i] = counts\n",
    "    if j%10 == 0:\n",
    "        print(i,'번째 단어 처리중...',i-1000,'번째로부터',time.time()-start_time,'초 경과.')\n",
    "        start_time = time.time()\n",
    "        \n",
    "#with open('./data/posts_total.pkl','wb') as f:\n",
    "#    pickle.dump(posts_total, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07e0c794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [해피뉴이어, 2021년, 은, 모두, 행복한, 한해, 가, 되길, 앗, ,, 성지...\n",
       "1        [2021년, 새해, 복, 많이, 받으세요, 모든, 일이, 잘, 되, 기를, 12시...\n",
       "2        [첫, 글, 은, 내꼬, 예비, 회계사, 나, 다미, ㄹㅇ, 1등, 이네, ㅋㅋ, ...\n",
       "3                                         [땡, ㅎㅎㅎㅎㅎㅎㅎ, 1등]\n",
       "4        [어디, 카운트, 다운, 하는, 곳, 없냐, 언, 제바, 껴, 232, 번, 불교,...\n",
       "                               ...                        \n",
       "77975    [아버지, 께서, 칼럼, 쓰셨는데, 댓글, 한, 번, 씩, 만, 달아줄, 수, 있을...\n",
       "77976    [프로포폴, 하면, 기분, 이, 좋음, 하는거, 신기하네하면, 힙, 해보여서, 하는...\n",
       "77977    [취업, 후기, 쓰려는데, 안, 올라간다, ㅠ, 손, 다쳐서, 폰, 으로, 열심히,...\n",
       "77978    [간, 떨어지는, 동거, 보는, 사람, 아, 이번, 주, 기대했는데, 예고편, 에,...\n",
       "77979    [오타루, 오, 마카, 세, 후기, 전, 에, 어떤, 다미, 가, 추천, 한, 거,...\n",
       "Name: _total_tokens, Length: 77980, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df._total_tokens.apply(lambda x : get_count('해피뉴이어',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50053e",
   "metadata": {},
   "source": [
    "### 날짜별 인기 키워드 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdf59ba",
   "metadata": {},
   "source": [
    "#### 지수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc671c9",
   "metadata": {},
   "source": [
    "급상승 지수\n",
    "1. 전일 언급 횟수 a\n",
    "2. 당일 언급된 횟수 b\n",
    "3. 전체 기간 중 언급 횟수 c\n",
    "4. 가중치 w0, w1, w2\n",
    "5. 적당한 상수 K, 아주 작은 상수 E\n",
    "\n",
    "w0 x log(1+(b - a)/(a + K1)) + w1 x tanh( 0.1 x (b - K2) ) - w2 x (1+E)^c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a52f0971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    if x<0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# [ w0,w1, w2,  K1, K2, E]    \n",
    "W = [1,0.5,-0.05, 5, 15, 0.0015]\n",
    "\n",
    "def _hot_point(a,b,c):\n",
    "    x0 = np.log(0.5*(b-a)/(a+W[3]) + 1)\n",
    "    x1 = np.tanh(0.1*(b-W[4]))\n",
    "    x2 = pow(1+W[5],c)\n",
    "    \n",
    "    return W[0]*x0, W[1]*x1, W[2]*x2\n",
    "    \n",
    "def hot_point(a,b,c):\n",
    "    x,y,z = _hot_point(a,b,c)\n",
    "    return x + y + z\n",
    "\n",
    "def pp2(a,b,idx):\n",
    "    c = BoW_mat[:,idx].sum()\n",
    "    x, y, z = _hot_point(a,b,c)\n",
    "    print(f'상승률지수 : {x}')\n",
    "    print(f'언급지수   : {y}')\n",
    "    print(f'패널티     : {z}')\n",
    "    print(f'최종값     : {x+y+z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c17be",
   "metadata": {},
   "source": [
    "#### 날짜/단어별 지수 columns 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f267c1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c459135f8fa34c64bda439a873c50212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#각 날짜/단어별 급상승 지수 계산\n",
    "cfd['points'] = [np.zeros(len(bow_total)) for i in range(len(cfd))]\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(1,len(BoW_mat))):\n",
    "    for j in range(len(bow_total)):\n",
    "        cfd.points[i][j] = hot_point(BoW_mat[i-1,j],BoW_mat[i,j],BoW_mat[:,j].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "de4c4425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-9.33461232e-01, -5.94702049e-01, -2.20162633e+03, ...,\n",
       "        -5.02649127e-01, -5.02724239e-01, -5.02649127e-01],\n",
       "       [-3.08213663e-01, -2.09579585e-01, -2.20177705e+03, ...,\n",
       "        -5.02649127e-01, -5.02724239e-01, -5.02649127e-01],\n",
       "       ...,\n",
       "       [-6.35880857e-01, -3.17793169e-01, -2.20189827e+03, ...,\n",
       "        -5.02649127e-01, -5.02724239e-01, -5.02649127e-01],\n",
       "       [-5.02349464e-01, -4.71943849e-01, -2.20177519e+03, ...,\n",
       "        -3.97440644e-01, -2.98690135e-01, -3.97440644e-01],\n",
       "       [-5.99259144e-01, -7.15330037e-01, -2.20334774e+03, ...,\n",
       "        -5.89660504e-01, -6.56874919e-01, -5.89660504e-01]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Points 매트릭스\n",
    "Points = np.array([list(value) for value in cfd.points.values])\n",
    "Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0267b3",
   "metadata": {},
   "source": [
    "__일별 상위 10개/20개 키워드 추려내기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0a944eb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index 찾아 True로 저장할 ndarray 정의\n",
    "top10s = np.zeros(Points.shape, dtype=bool)\n",
    "top20s = np.zeros(Points.shape, dtype=bool)\n",
    "\n",
    "for i in range(1,len(Points)):\n",
    "    #날짜별 점수 상위 10개만 추림\n",
    "    limit_10 = np.sort(Points[i,:])[-10]\n",
    "    limit_20 = np.sort(Points[i,:])[-20]\n",
    "    for j in range(Points.shape[1]):\n",
    "        if Points[i,j]>=limit_20:\n",
    "            #상위 20개에 대해 True값으로 저장\n",
    "            top20s[i,j] = True\n",
    "            \n",
    "            if Points[i,j]>=limit_10:\n",
    "                #상위 10개에 대해 True값으로 저장\n",
    "                top10s[i,j] = True\n",
    "\n",
    "top10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9ef26562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#일별 상위 10개 키워드 저장\n",
    "top10_keywords = [[[idx_key[int(j)],day] for j in np.arange(top10s.shape[1])[top10s[day]]] for day in range(len(top10s))]\n",
    "#일별 상위 20개 키워드 저장\n",
    "top20_keywords = [[[idx_key[int(j)],day] for j in np.arange(top20s.shape[1])[top20s[day]]] for day in range(len(top20s))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1eb9fd",
   "metadata": {},
   "source": [
    "__top10s의 BoW 생성__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "da49035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10s_idx = {}\n",
    "top10s_dates = {}\n",
    "top10s_bow = []\n",
    "\n",
    "for day_keywords in top10_keywords:\n",
    "    for keyword, day in day_keywords:\n",
    "        if keyword not in top10s_idx.keys():\n",
    "            top10s_idx[keyword]=len(top10s_idx)\n",
    "            top10s_dates[keyword]=[day]\n",
    "            top10s_bow.insert(len(top10s_idx)-1,1)\n",
    "        else :\n",
    "            top10s_dates[keyword].append(day)\n",
    "            top10s_bow[top10s_idx[keyword]]+=1\n",
    "            \n",
    "top10s_bow = np.array(top10s_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6deb4d",
   "metadata": {},
   "source": [
    "__BoW를 DataFrame화__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9f508030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>count</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>식당</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>방역</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>서로</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>필수</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 36, 49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>조언</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 157]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword  count        dates\n",
       "0      식당      1          [1]\n",
       "1      방역      2      [1, 90]\n",
       "2      서로      1          [1]\n",
       "3      필수      3  [1, 36, 49]\n",
       "4      조언      2     [1, 157]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10s_keys = [key for key, value in top10s_idx.items()]\n",
    "\n",
    "df_10bow = pd.DataFrame(np.array([top10s_keys,top10s_bow]).T,\n",
    "                      columns = ['keyword','count'])\n",
    "df_10bow['count'] = df_10bow['count'].astype(int)\n",
    "df_10bow['dates'] = top10s_dates.values()\n",
    "\n",
    "df_10bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "eae1b2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>count</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>서울대</td>\n",
       "      <td>7</td>\n",
       "      <td>[36, 53, 56, 65, 76, 95, 116]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>조교</td>\n",
       "      <td>6</td>\n",
       "      <td>[33, 109, 115, 127, 131, 154]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>로욜라</td>\n",
       "      <td>6</td>\n",
       "      <td>[10, 32, 82, 102, 116, 139]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>대출</td>\n",
       "      <td>6</td>\n",
       "      <td>[34, 45, 48, 114, 140, 148]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>치킨</td>\n",
       "      <td>6</td>\n",
       "      <td>[77, 96, 113, 134, 166, 172]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>수능</td>\n",
       "      <td>6</td>\n",
       "      <td>[5, 24, 58, 149, 162, 169]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>확</td>\n",
       "      <td>6</td>\n",
       "      <td>[83, 85, 87, 151, 173, 179]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>외모</td>\n",
       "      <td>6</td>\n",
       "      <td>[5, 51, 69, 143, 161, 171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>합격</td>\n",
       "      <td>5</td>\n",
       "      <td>[12, 18, 19, 63, 98]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>한강</td>\n",
       "      <td>5</td>\n",
       "      <td>[9, 119, 122, 125, 137]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>학벌</td>\n",
       "      <td>5</td>\n",
       "      <td>[31, 74, 93, 121, 143]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>예수회</td>\n",
       "      <td>5</td>\n",
       "      <td>[40, 95, 97, 116, 133]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>아이패드</td>\n",
       "      <td>5</td>\n",
       "      <td>[6, 11, 103, 143, 158]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>주식</td>\n",
       "      <td>5</td>\n",
       "      <td>[7, 28, 31, 91, 102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>투표</td>\n",
       "      <td>5</td>\n",
       "      <td>[79, 90, 96, 134, 135]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>마스크</td>\n",
       "      <td>5</td>\n",
       "      <td>[46, 83, 122, 151, 179]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>가정</td>\n",
       "      <td>5</td>\n",
       "      <td>[4, 75, 147, 157, 166]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>지방</td>\n",
       "      <td>5</td>\n",
       "      <td>[33, 57, 129, 152, 155]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>비대</td>\n",
       "      <td>5</td>\n",
       "      <td>[3, 24, 54, 78, 171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>자랑</td>\n",
       "      <td>5</td>\n",
       "      <td>[3, 7, 40, 77, 178]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>이과</td>\n",
       "      <td>5</td>\n",
       "      <td>[21, 40, 89, 147, 162]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>병원</td>\n",
       "      <td>5</td>\n",
       "      <td>[49, 80, 125, 129, 157]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>총장</td>\n",
       "      <td>5</td>\n",
       "      <td>[82, 95, 116, 120, 172]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>의대</td>\n",
       "      <td>5</td>\n",
       "      <td>[51, 110, 149, 152, 162]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>삼성</td>\n",
       "      <td>5</td>\n",
       "      <td>[27, 34, 103, 128, 164]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>진자</td>\n",
       "      <td>5</td>\n",
       "      <td>[83, 85, 87, 151, 179]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>상담</td>\n",
       "      <td>5</td>\n",
       "      <td>[23, 76, 105, 141, 147]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>아파트</td>\n",
       "      <td>5</td>\n",
       "      <td>[22, 33, 34, 175, 177]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>검사</td>\n",
       "      <td>5</td>\n",
       "      <td>[2, 10, 83, 104, 146]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>휴학</td>\n",
       "      <td>4</td>\n",
       "      <td>[21, 25, 58, 150]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    keyword  count                          dates\n",
       "303     서울대      7  [36, 53, 56, 65, 76, 95, 116]\n",
       "282      조교      6  [33, 109, 115, 127, 131, 154]\n",
       "89      로욜라      6    [10, 32, 82, 102, 116, 139]\n",
       "290      대출      6    [34, 45, 48, 114, 140, 148]\n",
       "605      치킨      6   [77, 96, 113, 134, 166, 172]\n",
       "39       수능      6     [5, 24, 58, 149, 162, 169]\n",
       "643       확      6    [83, 85, 87, 151, 173, 179]\n",
       "46       외모      6     [5, 51, 69, 143, 161, 171]\n",
       "105      합격      5           [12, 18, 19, 63, 98]\n",
       "79       한강      5        [9, 119, 122, 125, 137]\n",
       "269      학벌      5         [31, 74, 93, 121, 143]\n",
       "336     예수회      5         [40, 95, 97, 116, 133]\n",
       "51     아이패드      5         [6, 11, 103, 143, 158]\n",
       "60       주식      5           [7, 28, 31, 91, 102]\n",
       "614      투표      5         [79, 90, 96, 134, 135]\n",
       "382     마스크      5        [46, 83, 122, 151, 179]\n",
       "31       가정      5         [4, 75, 147, 157, 166]\n",
       "284      지방      5        [33, 57, 129, 152, 155]\n",
       "26       비대      5           [3, 24, 54, 78, 171]\n",
       "21       자랑      5            [3, 7, 40, 77, 178]\n",
       "188      이과      5         [21, 40, 89, 147, 162]\n",
       "409      병원      5        [49, 80, 125, 129, 157]\n",
       "639      총장      5        [82, 95, 116, 120, 172]\n",
       "423      의대      5       [51, 110, 149, 152, 162]\n",
       "233      삼성      5        [27, 34, 103, 128, 164]\n",
       "645      진자      5         [83, 85, 87, 151, 179]\n",
       "207      상담      5        [23, 76, 105, 141, 147]\n",
       "195     아파트      5         [22, 33, 34, 175, 177]\n",
       "11       검사      5          [2, 10, 83, 104, 146]\n",
       "183      휴학      4              [21, 25, 58, 150]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_10bow.sort_values('count',ascending=False).iloc[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c0b1dc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>count</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>선택</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>진로</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 76, 115]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>유지</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>감사</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 128]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>코</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 76, 80]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword  count         dates\n",
       "0      선택      1           [1]\n",
       "1      진로      3  [1, 76, 115]\n",
       "2      유지      2       [1, 13]\n",
       "3      감사      2      [1, 128]\n",
       "4       코      3   [1, 76, 80]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20s_idx = {}\n",
    "top20s_dates = {}\n",
    "top20s_bow = []\n",
    "\n",
    "for day_keywords in top20_keywords:\n",
    "    for keyword, day in day_keywords:\n",
    "        if keyword not in top20s_idx.keys():\n",
    "            top20s_idx[keyword]=len(top20s_idx)\n",
    "            top20s_dates[keyword]=[day]\n",
    "            top20s_bow.insert(len(top20s_idx)-1,1)\n",
    "        else :\n",
    "            top20s_dates[keyword].append(day)\n",
    "            top20s_bow[top20s_idx[keyword]]+=1\n",
    "            \n",
    "top20s_keys = [key for key, value in top20s_idx.items()]\n",
    "\n",
    "df_20bow = pd.DataFrame(np.array([top20s_keys,top20s_bow]).T,\n",
    "                      columns = ['keyword','count'])\n",
    "df_20bow['count'] = df_20bow['count'].astype(int)\n",
    "df_20bow['dates'] = top20s_dates.values()\n",
    "\n",
    "df_20bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8c5078d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/4th_bow_10.pkl','wb') as f:\n",
    "    pickle.dump(df_10bow,f)\n",
    "with open('./data/4th_bow_20.pkl','wb') as f:\n",
    "    pickle.dump(df_20bow,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebaad90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010de5c1",
   "metadata": {},
   "source": [
    "### 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "988bd4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('입결', 2.373325629631565),\n",
       " ('이과', 1.829739541065965),\n",
       " ('예수회', 1.3161102220241703),\n",
       " ('문과', 1.042272065285665),\n",
       " ('자랑', 0.9410646152597407),\n",
       " ('한의대', 0.7325395982206176),\n",
       " ('웹툰', 0.3951677320191124),\n",
       " ('설', 0.3664008148546232),\n",
       " ('진이뽀', 0.34768761330245007),\n",
       " ('기관', 0.33259918496428237),\n",
       " ('이벤트', 0.3066309636660743),\n",
       " ('균', 0.30105677041418116)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('북한', 0.5683121478189266), ('이사회', 0.4515376504475768)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('인스타', 1.3521135328386467),\n",
       " ('인구', 0.35738509357722503),\n",
       " ('행시', 0.32082851185080197)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('단계', 0.600608385919511), ('중국인', 0.40111022861203977)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('수강신청', 1.6269814306480028),\n",
       " ('수익률', 0.8048542208859417),\n",
       " ('짱깨', 0.6661299920438088),\n",
       " ('국민연금', 0.607261371999406),\n",
       " ('팩트', 0.4906162811328027)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('로그인', 1.0192774903094368),\n",
       " ('크롬', 0.893991607579015),\n",
       " ('창', 0.8820916760337818),\n",
       " ('시계', 0.7907923355860234),\n",
       " ('대기', 0.7045105346774294),\n",
       " ('수강신청', 0.703733313783917),\n",
       " ('익스', 0.6061168423167886),\n",
       " ('코딩', 0.598396131551214),\n",
       " ('장학금', 0.5878627684223631),\n",
       " ('용돈', 0.5538452391927635),\n",
       " ('네이버', 0.492956937234137),\n",
       " ('대출', 0.4829555521674384),\n",
       " ('거래', 0.4335939367729251),\n",
       " ('잠', 0.36184325936923345),\n",
       " ('조교', 0.348521545155721),\n",
       " ('번호', 0.33731729055047244),\n",
       " ('연습', 0.31993705781931364),\n",
       " ('생활비', 0.319006655310344),\n",
       " ('피방', 0.3013947361545994)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('저장', 0.6885981715723116),\n",
       " ('싸인', 0.4571032954869918),\n",
       " ('대여', 0.4142801478670041)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "arg = idx_total['조교']\n",
    "\n",
    "for day in range(40,47):\n",
    "    display([(idx_key[arg],Points[day,arg]) for arg in np.flip(np.argsort(Points[day])) if Points[day,arg]>0.3])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fa494bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.44733066, -1.38962605, -1.01933752, -1.49138052,\n",
       "       -0.88678269, -1.38962605, -1.41769461, -1.4611197 , -1.5122089 ,\n",
       "       -1.51999903, -1.22901625, -1.50277746, -1.41133781, -1.5122089 ,\n",
       "       -1.32432643, -1.31801886, -1.2073045 , -1.44132309, -1.4611197 ,\n",
       "       -1.51999903, -1.3204559 , -1.15364102, -1.47764   , -1.3077917 ,\n",
       "       -1.47764   , -1.39212683, -1.5122089 , -1.15096477, -1.49138052,\n",
       "       -1.40353203, -1.13831162, -1.5122089 , -0.98237653, -1.33246764,\n",
       "       -1.41769461, -1.51999903, -1.41689872,  1.16670179, -1.38962605,\n",
       "       -1.41769461, -1.41769461, -1.5122089 , -1.23647794, -1.22353859,\n",
       "        0.8261009 ,  0.13473357,  0.7568307 , -1.47764   ,  0.07259906,\n",
       "       -1.09302101, -1.50277746, -0.03635384, -1.41769461,  1.66388974,\n",
       "        1.09311556,  0.44401627,  0.41977168, -1.38962605,  1.17658007,\n",
       "        0.85539361,  0.43064285, -1.0180886 , -1.4611197 , -1.50277746,\n",
       "       -0.98416094, -1.38962605, -1.38962605,  0.57112202, -1.4611197 ,\n",
       "       -1.29253146, -1.49138052, -1.5122089 , -1.41576608, -0.89693814,\n",
       "       -1.51999903, -1.22901625, -0.79269624, -1.4611197 , -1.50277746,\n",
       "       -1.15364102, -1.4611197 , -1.4611197 , -1.47764   , -1.50277746,\n",
       "       -1.23797615, -1.47764   , -1.47764   , -1.47764   , -1.49138052,\n",
       "       -1.06420365, -1.41769461, -1.51999903, -1.22901625, -1.40353203,\n",
       "       -1.49138052, -1.5122089 , -0.7197286 , -1.41769461, -1.50277746,\n",
       "       -1.41133781, -1.50277746, -1.32348932, -1.39212683, -1.47764   ,\n",
       "       -1.49138052, -1.50277746, -1.41133781,  0.01390839, -1.35647047,\n",
       "       -1.07340474, -1.44132309, -1.35706998, -1.49138052, -1.49138052,\n",
       "        0.28027658, -1.22000822, -1.44132309, -1.44132309, -1.27184302,\n",
       "       -1.21220509, -0.79494505, -0.24119207, -1.3175656 , -1.38962605,\n",
       "       -1.47764   , -0.76802309, -1.41769461, -1.50277746, -1.50277746,\n",
       "       -1.23797615, -1.47764   , -1.05108882, -1.44132309, -1.0003356 ,\n",
       "       -1.3175656 , -1.38962605, -1.49138052, -1.31801886, -1.50277746,\n",
       "       -1.50277746, -1.51999903, -1.41689872, -1.23647794, -1.13831162,\n",
       "       -1.51999903, -1.41689872, -0.98237653, -1.4611197 , -1.49138052,\n",
       "       -0.69391512, -1.41769461, -1.50277746, -1.50277746, -1.50277746,\n",
       "       -1.5122089 , -1.32432643, -1.31801886, -1.29253146, -1.15504667,\n",
       "       -1.47764   , -1.47764   , -1.39212683, -1.50277746, -1.50277746,\n",
       "       -1.23797615, -1.4611197 ,  0.26963355, -1.35647047, -1.44132309,\n",
       "       -1.09442205, -0.79494505, -1.16033922, -0.02835444, -1.16033922,\n",
       "       -1.47764   , -1.22353859, -0.85805835,  0.87985856, -1.35647047,\n",
       "       -1.07340474, -1.51999903])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Points[:,idx_total['메일']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c79f16fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>count</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>수강신청</td>\n",
       "      <td>7</td>\n",
       "      <td>[38, 44, 45, 46, 54, 56, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>치킨</td>\n",
       "      <td>6</td>\n",
       "      <td>[77, 96, 113, 134, 166, 172]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>로욜라</td>\n",
       "      <td>6</td>\n",
       "      <td>[10, 32, 82, 102, 116, 139]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>조교</td>\n",
       "      <td>6</td>\n",
       "      <td>[33, 109, 115, 127, 131, 154]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>확</td>\n",
       "      <td>5</td>\n",
       "      <td>[83, 85, 87, 173, 179]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>교직원</td>\n",
       "      <td>1</td>\n",
       "      <td>[68]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>출장</td>\n",
       "      <td>1</td>\n",
       "      <td>[68]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>박병준</td>\n",
       "      <td>1</td>\n",
       "      <td>[68]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>스터디</td>\n",
       "      <td>1</td>\n",
       "      <td>[69]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>게놈</td>\n",
       "      <td>1</td>\n",
       "      <td>[181]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1317 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword  count                          dates\n",
       "333     수강신청      7   [38, 44, 45, 46, 54, 56, 60]\n",
       "629       치킨      6   [77, 96, 113, 134, 166, 172]\n",
       "91       로욜라      6    [10, 32, 82, 102, 116, 139]\n",
       "291       조교      6  [33, 109, 115, 127, 131, 154]\n",
       "672        확      5         [83, 85, 87, 173, 179]\n",
       "...      ...    ...                            ...\n",
       "560      교직원      1                           [68]\n",
       "561       출장      1                           [68]\n",
       "562      박병준      1                           [68]\n",
       "563      스터디      1                           [69]\n",
       "1316      게놈      1                          [181]\n",
       "\n",
       "[1317 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_10bow.sort_values('count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6176d628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.,  47., 115., 105.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BoW_mat[:,idx_total['수강신청']][43:47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4aef3311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상승률지수 : -0.04255961441879589\n",
      "언급지수   : 0.4999998874648379\n",
      "패널티     : -0.2993702486581838\n",
      "최종값     : 0.15807002438785822\n"
     ]
    }
   ],
   "source": [
    "pp2(115,105,idx_total['수강신청'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "da71441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_cd(word, x):\n",
    "    try:\n",
    "        return True if word in [y[0] for y in x] else False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def s_search(word, month, df2, show_urls=True):\n",
    "    df_month = df2[df2.upload_date.apply(lambda x: True if x.month==month else False)]\n",
    "    title_cd = df2.title_tokenized.apply(lambda x: search_cd(word,x))\n",
    "    text_cd = df2.text_tokenized.apply(lambda x: search_cd(word,x))\n",
    "    comments_cd = df2.comments_tokenized.apply(lambda x: search_cd(word,x))\n",
    "    comments_writer_cd = df2.comments_writer_tokenized.apply(lambda x: search_cd(word,x))\n",
    "    df = df_month[title_cd | text_cd | comments_cd | comments_writer_cd]\n",
    "    if show_urls==True:\n",
    "        [print('http://www.ssodam.com/content/'+str(number)) for number in df.num]\n",
    "    return df\n",
    "\n",
    "def numofposts(word, month):\n",
    "    df = s_search(word,month,show_urls=False)\n",
    "    return len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7230d6c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.ssodam.com/content/1084467\n",
      "http://www.ssodam.com/content/1084741\n",
      "http://www.ssodam.com/content/1085424\n",
      "http://www.ssodam.com/content/1085435\n",
      "http://www.ssodam.com/content/1086255\n",
      "http://www.ssodam.com/content/1086941\n",
      "http://www.ssodam.com/content/1088232\n",
      "http://www.ssodam.com/content/1089908\n",
      "http://www.ssodam.com/content/1089919\n",
      "http://www.ssodam.com/content/1089925\n",
      "http://www.ssodam.com/content/1089941\n",
      "http://www.ssodam.com/content/1089953\n",
      "http://www.ssodam.com/content/1090022\n",
      "http://www.ssodam.com/content/1091137\n",
      "http://www.ssodam.com/content/1092894\n",
      "http://www.ssodam.com/content/1093030\n",
      "http://www.ssodam.com/content/1093870\n",
      "http://www.ssodam.com/content/1096319\n",
      "http://www.ssodam.com/content/1096472\n",
      "http://www.ssodam.com/content/1098601\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>board</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>writer</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>view</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_writer</th>\n",
       "      <th>comments_cnt</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>comments_writer_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>1084467</td>\n",
       "      <td>익게2</td>\n",
       "      <td>해리포터는 떡밥을 알고 보니까</td>\n",
       "      <td>더 재밌어</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>13:58</td>\n",
       "      <td>333.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>뭔데 나도 같이 알자, 해리포터랑 볼드모트랑 이복형제인거, 롸, 롸 익2 뭔솔, 그...</td>\n",
       "      <td></td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(더, Noun), (재밌어, Adjective)]</td>\n",
       "      <td>[(해리포터, Noun), (는, Josa), (떡밥, Noun), (을, Josa...</td>\n",
       "      <td>[(뭔, Modifier), (데, Noun), (나도, Verb), (같이, Ad...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>1084741</td>\n",
       "      <td>서르비</td>\n",
       "      <td>입법고시  법원행정고시  5급공채  변리사</td>\n",
       "      <td>자주 나오는 떡밥다미들의 선호도는</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>21:15</td>\n",
       "      <td>395.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>솔직히 최근 경향으로는 가 제일 좋지, 내가 회계사라서 회계사 함ㅋ, 내가 사무관이...</td>\n",
       "      <td></td>\n",
       "      <td>8.0</td>\n",
       "      <td>[(자주, Noun), (나오는, Verb), (떡밥, Noun), (다미, Nou...</td>\n",
       "      <td>[(입법고시, Noun), (법원, Noun), (행정고시, Noun), (5, N...</td>\n",
       "      <td>[(솔직히, Adjective), (최근, Noun), (경향, Noun), (으로...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>1085424</td>\n",
       "      <td>익게2</td>\n",
       "      <td>타대 언급글은 무조건 서르비임학점분포 기준</td>\n",
       "      <td>내 친구들 중에서 유독 학점 인증 많이 하는 몇 학교들을 보면서 그간 진심으로 궁금...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>19:44</td>\n",
       "      <td>213.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>그런글 몇개 있음 이미, 이미 여러번 식은 떡밥 , 인기글도 여럿갔었옹, 서연고 다...</td>\n",
       "      <td>아 몰랐었다 난 이제 알아서 꽤 충격맨날 궁금했었거든 내 친구들 다 맨날 에이만 받...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>[(내, Noun), (친구, Noun), (들, Suffix), (중, Noun)...</td>\n",
       "      <td>[(타대, Verb), (언급, Noun), (글, Noun), (은, Josa),...</td>\n",
       "      <td>[(그런, Modifier), (글, Noun), (몇개, Noun), (있음, A...</td>\n",
       "      <td>[(아, Exclamation), (몰랐었다, Verb), (난, Noun), (이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>1085435</td>\n",
       "      <td>익게2</td>\n",
       "      <td>잼일 너무 잼있어 ㅠㅠ</td>\n",
       "      <td>이건 ㄹㅈㄷ 영상이건 학점 떡밥에 맞는 영상서강대 교수님들 어디 없나요오오</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>19:54</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>, 항상알림 켜놨는데이분 정모하면 가고싶음 집도 성남이라</td>\n",
       "      <td>설마 진짜 교미, 언넝 대면 팬미팅 기원 ㅜㅜ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[(이건, Noun), (ㄹㅈㄷ, KoreanParticle), (영상, Noun)...</td>\n",
       "      <td>[(잼일, Noun), (너무, Adverb), (잼있어, Verb), (ㅠㅠ, K...</td>\n",
       "      <td>[(,, Punctuation), (항상, Noun), (알림, Noun), (켜놨...</td>\n",
       "      <td>[(설마, Noun), (진짜, Noun), (교미, Noun), (,, Punct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>1086255</td>\n",
       "      <td>익게2</td>\n",
       "      <td>펜트하우스</td>\n",
       "      <td>이렇게 끝난다고</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>23:09</td>\n",
       "      <td>517.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>시즌3 막판에 결론지을건가봐, 시즌1이 끝난거잖아, , 약간의 완결성이 있어야지ㅠㅠ...</td>\n",
       "      <td>차라리 차 전복하고 끝내지, 시즌제로 해서 그런가 갑자기 고무마 켁, 그렇긴한데 끝...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>[(이렇게, Adverb), (끝난다고, Verb)]</td>\n",
       "      <td>[(펜트하우스, Noun)]</td>\n",
       "      <td>[(시즌, Noun), (3, Number), (막판, Noun), (에, Josa...</td>\n",
       "      <td>[(차라리, Noun), (차, Noun), (전복, Noun), (하고, Josa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>1086941</td>\n",
       "      <td>익게2</td>\n",
       "      <td>법까지 건들기 시작하는 인공지능</td>\n",
       "      <td>변호사마저</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>00:11</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ㄹㅇ 이러다가 유나바머 시즌2 찍는 건 아닌지 모르겠네, 진지충 유나바머는 아니지만...</td>\n",
       "      <td>데이터 처리같은건 가 하고 그걸 보면서 최소한의 인력의 회계사가 판단한다는 거지 회...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>[(변호사, Noun), (마저, Josa)]</td>\n",
       "      <td>[(법, Noun), (까지, Josa), (건들, Adverb), (기, Noun...</td>\n",
       "      <td>[(ㄹㅇ, KoreanParticle), (이러다가, Adverb), (유나바머, ...</td>\n",
       "      <td>[(데이터, Noun), (처리, Noun), (같은건, Adjective), (가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>1088232</td>\n",
       "      <td>익게2</td>\n",
       "      <td>갑자기 의대 약대 핫하네</td>\n",
       "      <td>왜고용시장 박살나서갈수록 직업들 하향평준화되서</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-09</td>\n",
       "      <td>12:11</td>\n",
       "      <td>606.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>의대 약대는 늘 핫하지 않아, 그냥 정기 떡밥임, 이번에 약대가 수능으로 풀려서, ...</td>\n",
       "      <td></td>\n",
       "      <td>6.0</td>\n",
       "      <td>[(왜, Noun), (고용, Noun), (시장, Noun), (박살, Noun)...</td>\n",
       "      <td>[(갑자기, Noun), (의대, Noun), (약대, Noun), (핫, Noun...</td>\n",
       "      <td>[(의대, Noun), (약대, Noun), (는, Josa), (늘, Noun),...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4821</th>\n",
       "      <td>1089908</td>\n",
       "      <td>익게2</td>\n",
       "      <td>근데 알페스랑 딥페이크</td>\n",
       "      <td>알페스랑 딥페이크 둘다 좆같은거 맞고둘다 당사자 입장에선 존나 끔찍하고  생길거같고...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>11:31</td>\n",
       "      <td>605.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>108990015이걸 보면 생각이 바뀜 합성 알페스도 있음ㅋㅋ그게 그거라고 생각함,...</td>\n",
       "      <td>ㅇㅇ ㅜ 합성 알페스는 그러면 이제 합성알페스가 아니고 딥페이크인거아님알페스 피해자...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>[(알, Noun), (페스, Noun), (랑, Josa), (딥, Noun), ...</td>\n",
       "      <td>[(근데, Adverb), (알, Noun), (페스, Noun), (랑, Josa...</td>\n",
       "      <td>[(108990015, Number), (이, Determiner), (걸, Nou...</td>\n",
       "      <td>[(ㅇㅇ, KoreanParticle), (ㅜ, KoreanParticle), (합...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>1089919</td>\n",
       "      <td>익게2</td>\n",
       "      <td>번방은 알페스나 딥페랑은 아예 결이 다름</td>\n",
       "      <td>협박을 통해 실제 성착취행위가 이뤄진건데                        ...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>11:48</td>\n",
       "      <td>1711.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>나도  동의애초에 왜 같이 거론되는지 몰겠음, ㅇㅈ 완전 같지는 않은듯김 변호사는 ...</td>\n",
       "      <td>ㄴㄴ 근데 자꾸 번방이랑 묶어서 비교하길래번방은 범죄의 심각성 정도를 떠나서 유형 ...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>[(협박, Noun), (을, Josa), (통해, Noun), (실제, Noun)...</td>\n",
       "      <td>[(번방, Noun), (은, Josa), (알, Noun), (페스나, Noun)...</td>\n",
       "      <td>[(나도, Verb), (동의, Noun), (애초, Noun), (에, Josa)...</td>\n",
       "      <td>[(ㄴㄴ, KoreanParticle), (근데, Adverb), (자꾸, Noun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4833</th>\n",
       "      <td>1089925</td>\n",
       "      <td>익게2</td>\n",
       "      <td>알페스 즐겼던 다미들도 눈팅중이겠네 ㅋㅋ</td>\n",
       "      <td>꾸준히 비추 박던거 너네 였냐 에라이 ㅋㅋ</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>12:01</td>\n",
       "      <td>3522.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>다른 범죄와는 결이 다르다는 댓글 하나써주면 완벽, 당연시하던게 역겨울뿐 ㅋㅋㅋ, ...</td>\n",
       "      <td></td>\n",
       "      <td>30.0</td>\n",
       "      <td>[(꾸준히, Adjective), (비추, Verb), (박던거, Verb), (너...</td>\n",
       "      <td>[(알, Noun), (페스, Noun), (즐겼던, Verb), (다미, Noun...</td>\n",
       "      <td>[(다른, Noun), (범죄, Noun), (와는, Josa), (결, Noun)...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4840</th>\n",
       "      <td>1089941</td>\n",
       "      <td>익게2</td>\n",
       "      <td>이번엔 또 뭔 떡밥이야</td>\n",
       "      <td>서담 일주일만 쉴게요흑흑일상게시판 만들어달라</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>12:30</td>\n",
       "      <td>203.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>흑흑 나도 슬퍼</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(서담, Verb), (일주일, Noun), (만, Josa), (쉴게요, Ver...</td>\n",
       "      <td>[(이번, Noun), (엔, Josa), (또, Noun), (뭔, Modifie...</td>\n",
       "      <td>[(흑, Adverb), (흑, Adverb), (나도, Verb), (슬퍼, Ad...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846</th>\n",
       "      <td>1089953</td>\n",
       "      <td>익게2</td>\n",
       "      <td>트위터에 알페스 검색했더니</td>\n",
       "      <td>하도 난리인데 인기글 댓글에서 누가 그럼 트위터 직접 가서 해결하래서 검색해봤더니 ...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>12:43</td>\n",
       "      <td>672.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>내로남불의 말로지 뭐, 그분들은 그런것보다 고양이에 더 관심이 많음, 삭제된 댓글입...</td>\n",
       "      <td>나도 딱 이 생각했다</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[(하도, Verb), (난리, Noun), (인데, Josa), (인기, Noun...</td>\n",
       "      <td>[(트위터, Noun), (에, Josa), (알, Noun), (페스, Noun)...</td>\n",
       "      <td>[(내, Determiner), (로남, Noun), (불의, Noun), (말로,...</td>\n",
       "      <td>[(나도, Verb), (딱, Adverb), (이, Noun), (생각, Noun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>1090022</td>\n",
       "      <td>익게2</td>\n",
       "      <td>현직 남돌 여돌 엔터 관계자들 입장 들어보고 싶다</td>\n",
       "      <td>이번에 이슈돼서 찾아봤더니 비게퍼라는 게 있던데비즈니스 게이 퍼포먼스라더라 개웃김ㅋ...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>14:40</td>\n",
       "      <td>630.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ㄹㅇㄹㅇ 어떻게 대응할까대응 아예 안할라나 궁금해, 아재 맞음, 소속사들 걍 넘어갈...</td>\n",
       "      <td>여돌 좋아했는데 지금은 공중분해됨, 와 오프라인에서 그런걸 한다고진짜 무슨 세계지 ...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[(이번, Noun), (에, Josa), (이슈, Noun), (돼서, Verb)...</td>\n",
       "      <td>[(현직, Noun), (남돌, Noun), (여, Modifier), (돌, No...</td>\n",
       "      <td>[(ㄹㅇㄹㅇ, KoreanParticle), (어떻게, Adjective), (대응...</td>\n",
       "      <td>[(여, Modifier), (돌, Noun), (좋아했는데, Adjective),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5588</th>\n",
       "      <td>1091137</td>\n",
       "      <td>익게2</td>\n",
       "      <td>한국드라마 추천 좀</td>\n",
       "      <td>드라마 완결을 해본 적이 많이 없는 남다미인데이번 방학을 맞아 넷플릭스로 드라마 정...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>01:12</td>\n",
       "      <td>149.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>비숲, 보이스 강추난 진짜 넷플에서 안본거 없는데 저거 듀개 짜릿햇어, 보이스 진짜...</td>\n",
       "      <td>옹 고맙다, 스위트홈은 웹툰으로 봤어서경이로운 소문은 찾아볼게고마워, 지정생존자는 ...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[(드라마, Noun), (완결, Noun), (을, Josa), (해본, Verb...</td>\n",
       "      <td>[(한국, Noun), (드라마, Noun), (추천, Noun), (좀, Noun)]</td>\n",
       "      <td>[(비숲, Noun), (,, Punctuation), (보이스, Noun), (강...</td>\n",
       "      <td>[(옹, Noun), (고맙다, Adjective), (,, Punctuation)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6751</th>\n",
       "      <td>1092894</td>\n",
       "      <td>익게2</td>\n",
       "      <td>진짜 입결 실화냐</td>\n",
       "      <td>올해 입시는 레전드다</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-17</td>\n",
       "      <td>11:37</td>\n",
       "      <td>4480.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>와 ㅁㅊ, 와 아무리 서강대가 인식이 어쩌구 저쩌구 해도입결 방어는 대박이네 ㅋㅋㅋ...</td>\n",
       "      <td>누백, 누백이 예전만큼 의미는 별로 없고각 학교별 위치를 놓고 원래 있어야될 것 같...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>[(올해, Noun), (입시, Noun), (는, Josa), (레전드, Noun...</td>\n",
       "      <td>[(진짜, Noun), (입결, Noun), (실화, Noun), (냐, Josa)]</td>\n",
       "      <td>[(와, Verb), (ㅁㅊ, KoreanParticle), (,, Punctuat...</td>\n",
       "      <td>[(누, Noun), (백, Suffix), (,, Punctuation), (누,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6851</th>\n",
       "      <td>1093030</td>\n",
       "      <td>익게2</td>\n",
       "      <td>웹툰 추천좀 해주라ㅜㅜ캐릭터 서사 좋은걸로</td>\n",
       "      <td>판타지든 현대물이든 다 좋은데                              ...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-17</td>\n",
       "      <td>15:49</td>\n",
       "      <td>264.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>웹툰을 이미 어느 정도 본 편이야좋아하는 작품 써놓으면 추천하기 더 편할 듯, 인도...</td>\n",
       "      <td>음 그 진짜 옛날에서 멈춰있어 트레이스 강풀 치인트 이런거ㅋㅋ큐ㅠㅠ신의탑은 보다 중...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>[(판타지, Noun), (든, Josa), (현, Modifier), (대물, N...</td>\n",
       "      <td>[(웹툰, Noun), (추천, Noun), (좀, Noun), (해주, Noun)...</td>\n",
       "      <td>[(웹툰, Noun), (을, Josa), (이미, Adverb), (어느, Adv...</td>\n",
       "      <td>[(음, Noun), (그, Noun), (진짜, Noun), (옛날, Noun),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7440</th>\n",
       "      <td>1093870</td>\n",
       "      <td>익게2</td>\n",
       "      <td>요즘 내 일상 무료, 나눔합니다</td>\n",
       "      <td>요즘 일상이 너무 무료해코로나 핑계로 어차피 아싸라 만날 사람도 거의 없다만 밖에를...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>22:05</td>\n",
       "      <td>88.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(요즘, Noun), (일상, Noun), (이, Josa), (너무, Adver...</td>\n",
       "      <td>[(요즘, Noun), (내, Noun), (일상, Noun), (무료, Noun)...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9120</th>\n",
       "      <td>1096319</td>\n",
       "      <td>익게2</td>\n",
       "      <td>착짱죽짱도 냉동감임</td>\n",
       "      <td>아니면 인기글감임</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-23</td>\n",
       "      <td>12:04</td>\n",
       "      <td>357.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>인기글 갔다가 응애세력으로 정게로 보내짐, 혐오표현이 좋게 보이진 않음요즘 서담에서...</td>\n",
       "      <td>응애세력이 무슨뜻, 야야 그렇다고 드립력까지 중국에 두고오면 어떡함 ㅠㅠ</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[(아니면, Adjective), (인기, Noun), (글, Noun), (감임,...</td>\n",
       "      <td>[(착, Noun), (짱, Suffix), (죽, Noun), (짱, Suffix...</td>\n",
       "      <td>[(인기, Noun), (글, Noun), (갔다가, Verb), (응애, Noun...</td>\n",
       "      <td>[(응애, Noun), (세력, Noun), (이, Josa), (무슨, Modif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9219</th>\n",
       "      <td>1096472</td>\n",
       "      <td>익게2</td>\n",
       "      <td>시즌이 벌써 입결, 수시, 수능점수 떡밥이 돌 시즌인건가</td>\n",
       "      <td>이제 국어 몇점이었는지 기억이 안나</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-23</td>\n",
       "      <td>17:27</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>나두 점수는 기억안나고 등급만 기억나</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(이제, Noun), (국어, Noun), (몇, Modifier), (점, No...</td>\n",
       "      <td>[(시즌, Noun), (이, Josa), (벌써, Noun), (입결, Noun)...</td>\n",
       "      <td>[(나, Noun), (두, Josa), (점수, Noun), (는, Josa), ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10673</th>\n",
       "      <td>1098601</td>\n",
       "      <td>익게2</td>\n",
       "      <td>강철의 연금술사같은 스토리 탄탄한 애니있나</td>\n",
       "      <td>진짜 초중반부는 유치하고 그냥그냥이라 대충봤는데 후반부 ㄹㅇ 개재밌어서 후딱봄ㅠㅠ ...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>08:23</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>카우보이 비밥 재밌엉그림체가 낯설 수도 있지만 ㄹㅇ 후회 안 할 명작, 이거 최고지...</td>\n",
       "      <td>오 땡큐 한번 볼게, 그거 아직 완결 안 나지 않았나, 올해 3월, 그건 다봤당ㅎㅎ...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>[(진짜, Noun), (초, Noun), (중반, Noun), (부는, Verb)...</td>\n",
       "      <td>[(강철, Noun), (의, Josa), (연금술사, Noun), (같은, Adj...</td>\n",
       "      <td>[(카우보이, Noun), (비밥, Noun), (재밌, Adjective), (엉...</td>\n",
       "      <td>[(오, Noun), (땡큐, Noun), (한번, Noun), (볼, Noun),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           num board                            title  \\\n",
       "1067   1084467   익게2                 해리포터는 떡밥을 알고 보니까   \n",
       "1260   1084741   서르비        입법고시  법원행정고시  5급공채  변리사     \n",
       "1744   1085424   익게2          타대 언급글은 무조건 서르비임학점분포 기준   \n",
       "1755   1085435   익게2                     잼일 너무 잼있어 ㅠㅠ   \n",
       "2328   1086255   익게2                            펜트하우스   \n",
       "2808   1086941   익게2                법까지 건들기 시작하는 인공지능   \n",
       "3696   1088232   익게2                    갑자기 의대 약대 핫하네   \n",
       "4821   1089908   익게2                     근데 알페스랑 딥페이크   \n",
       "4829   1089919   익게2           번방은 알페스나 딥페랑은 아예 결이 다름   \n",
       "4833   1089925   익게2           알페스 즐겼던 다미들도 눈팅중이겠네 ㅋㅋ   \n",
       "4840   1089941   익게2                     이번엔 또 뭔 떡밥이야   \n",
       "4846   1089953   익게2                   트위터에 알페스 검색했더니   \n",
       "4886   1090022   익게2      현직 남돌 여돌 엔터 관계자들 입장 들어보고 싶다   \n",
       "5588   1091137   익게2                       한국드라마 추천 좀   \n",
       "6751   1092894   익게2                        진짜 입결 실화냐   \n",
       "6851   1093030   익게2          웹툰 추천좀 해주라ㅜㅜ캐릭터 서사 좋은걸로   \n",
       "7440   1093870   익게2                요즘 내 일상 무료, 나눔합니다   \n",
       "9120   1096319   익게2                       착짱죽짱도 냉동감임   \n",
       "9219   1096472   익게2  시즌이 벌써 입결, 수시, 수능점수 떡밥이 돌 시즌인건가   \n",
       "10673  1098601   익게2          강철의 연금술사같은 스토리 탄탄한 애니있나   \n",
       "\n",
       "                                                    text writer upload_date  \\\n",
       "1067                                               더 재밌어     익명  2021-01-03   \n",
       "1260                                  자주 나오는 떡밥다미들의 선호도는     익명  2021-01-03   \n",
       "1744   내 친구들 중에서 유독 학점 인증 많이 하는 몇 학교들을 보면서 그간 진심으로 궁금...     익명  2021-01-04   \n",
       "1755           이건 ㄹㅈㄷ 영상이건 학점 떡밥에 맞는 영상서강대 교수님들 어디 없나요오오     익명  2021-01-04   \n",
       "2328                                            이렇게 끝난다고     익명  2021-01-05   \n",
       "2808                                               변호사마저     익명  2021-01-07   \n",
       "3696                           왜고용시장 박살나서갈수록 직업들 하향평준화되서     익명  2021-01-09   \n",
       "4821   알페스랑 딥페이크 둘다 좆같은거 맞고둘다 당사자 입장에선 존나 끔찍하고  생길거같고...     익명  2021-01-12   \n",
       "4829   협박을 통해 실제 성착취행위가 이뤄진건데                        ...     익명  2021-01-12   \n",
       "4833                             꾸준히 비추 박던거 너네 였냐 에라이 ㅋㅋ     익명  2021-01-12   \n",
       "4840                            서담 일주일만 쉴게요흑흑일상게시판 만들어달라     익명  2021-01-12   \n",
       "4846   하도 난리인데 인기글 댓글에서 누가 그럼 트위터 직접 가서 해결하래서 검색해봤더니 ...     익명  2021-01-12   \n",
       "4886   이번에 이슈돼서 찾아봤더니 비게퍼라는 게 있던데비즈니스 게이 퍼포먼스라더라 개웃김ㅋ...     익명  2021-01-12   \n",
       "5588   드라마 완결을 해본 적이 많이 없는 남다미인데이번 방학을 맞아 넷플릭스로 드라마 정...     익명  2021-01-14   \n",
       "6751                                         올해 입시는 레전드다     익명  2021-01-17   \n",
       "6851   판타지든 현대물이든 다 좋은데                              ...     익명  2021-01-17   \n",
       "7440   요즘 일상이 너무 무료해코로나 핑계로 어차피 아싸라 만날 사람도 거의 없다만 밖에를...     익명  2021-01-18   \n",
       "9120                                           아니면 인기글감임     익명  2021-01-23   \n",
       "9219                                 이제 국어 몇점이었는지 기억이 안나     익명  2021-01-23   \n",
       "10673  진짜 초중반부는 유치하고 그냥그냥이라 대충봤는데 후반부 ㄹㅇ 개재밌어서 후딱봄ㅠㅠ ...     익명  2021-01-27   \n",
       "\n",
       "      upload_time    view  likes  dislikes  \\\n",
       "1067        13:58   333.0    1.0       0.0   \n",
       "1260        21:15   395.0    3.0       3.0   \n",
       "1744        19:44   213.0    0.0       0.0   \n",
       "1755        19:54    50.0    2.0       0.0   \n",
       "2328        23:09   517.0    8.0       0.0   \n",
       "2808        00:11  1043.0   27.0       3.0   \n",
       "3696        12:11   606.0    1.0       0.0   \n",
       "4821        11:31   605.0   26.0      30.0   \n",
       "4829        11:48  1711.0   68.0      32.0   \n",
       "4833        12:01  3522.0  159.0      20.0   \n",
       "4840        12:30   203.0    3.0       0.0   \n",
       "4846        12:43   672.0   25.0       0.0   \n",
       "4886        14:40   630.0   13.0       1.0   \n",
       "5588        01:12   149.0    2.0       0.0   \n",
       "6751        11:37  4480.0  111.0       5.0   \n",
       "6851        15:49   264.0    3.0       0.0   \n",
       "7440        22:05    88.0    8.0       0.0   \n",
       "9120        12:04   357.0   22.0       4.0   \n",
       "9219        17:27   106.0    1.0       1.0   \n",
       "10673       08:23   343.0    0.0       0.0   \n",
       "\n",
       "                                                comments  \\\n",
       "1067   뭔데 나도 같이 알자, 해리포터랑 볼드모트랑 이복형제인거, 롸, 롸 익2 뭔솔, 그...   \n",
       "1260   솔직히 최근 경향으로는 가 제일 좋지, 내가 회계사라서 회계사 함ㅋ, 내가 사무관이...   \n",
       "1744   그런글 몇개 있음 이미, 이미 여러번 식은 떡밥 , 인기글도 여럿갔었옹, 서연고 다...   \n",
       "1755                    , 항상알림 켜놨는데이분 정모하면 가고싶음 집도 성남이라    \n",
       "2328   시즌3 막판에 결론지을건가봐, 시즌1이 끝난거잖아, , 약간의 완결성이 있어야지ㅠㅠ...   \n",
       "2808   ㄹㅇ 이러다가 유나바머 시즌2 찍는 건 아닌지 모르겠네, 진지충 유나바머는 아니지만...   \n",
       "3696   의대 약대는 늘 핫하지 않아, 그냥 정기 떡밥임, 이번에 약대가 수능으로 풀려서, ...   \n",
       "4821   108990015이걸 보면 생각이 바뀜 합성 알페스도 있음ㅋㅋ그게 그거라고 생각함,...   \n",
       "4829   나도  동의애초에 왜 같이 거론되는지 몰겠음, ㅇㅈ 완전 같지는 않은듯김 변호사는 ...   \n",
       "4833   다른 범죄와는 결이 다르다는 댓글 하나써주면 완벽, 당연시하던게 역겨울뿐 ㅋㅋㅋ, ...   \n",
       "4840                                            흑흑 나도 슬퍼   \n",
       "4846   내로남불의 말로지 뭐, 그분들은 그런것보다 고양이에 더 관심이 많음, 삭제된 댓글입...   \n",
       "4886   ㄹㅇㄹㅇ 어떻게 대응할까대응 아예 안할라나 궁금해, 아재 맞음, 소속사들 걍 넘어갈...   \n",
       "5588   비숲, 보이스 강추난 진짜 넷플에서 안본거 없는데 저거 듀개 짜릿햇어, 보이스 진짜...   \n",
       "6751   와 ㅁㅊ, 와 아무리 서강대가 인식이 어쩌구 저쩌구 해도입결 방어는 대박이네 ㅋㅋㅋ...   \n",
       "6851   웹툰을 이미 어느 정도 본 편이야좋아하는 작품 써놓으면 추천하기 더 편할 듯, 인도...   \n",
       "7440                                                       \n",
       "9120   인기글 갔다가 응애세력으로 정게로 보내짐, 혐오표현이 좋게 보이진 않음요즘 서담에서...   \n",
       "9219                                나두 점수는 기억안나고 등급만 기억나   \n",
       "10673  카우보이 비밥 재밌엉그림체가 낯설 수도 있지만 ㄹㅇ 후회 안 할 명작, 이거 최고지...   \n",
       "\n",
       "                                         comments_writer  comments_cnt  \\\n",
       "1067                                                               5.0   \n",
       "1260                                                               8.0   \n",
       "1744   아 몰랐었다 난 이제 알아서 꽤 충격맨날 궁금했었거든 내 친구들 다 맨날 에이만 받...          11.0   \n",
       "1755                           설마 진짜 교미, 언넝 대면 팬미팅 기원 ㅜㅜ           4.0   \n",
       "2328   차라리 차 전복하고 끝내지, 시즌제로 해서 그런가 갑자기 고무마 켁, 그렇긴한데 끝...          19.0   \n",
       "2808   데이터 처리같은건 가 하고 그걸 보면서 최소한의 인력의 회계사가 판단한다는 거지 회...          29.0   \n",
       "3696                                                               6.0   \n",
       "4821   ㅇㅇ ㅜ 합성 알페스는 그러면 이제 합성알페스가 아니고 딥페이크인거아님알페스 피해자...          26.0   \n",
       "4829   ㄴㄴ 근데 자꾸 번방이랑 묶어서 비교하길래번방은 범죄의 심각성 정도를 떠나서 유형 ...          33.0   \n",
       "4833                                                              30.0   \n",
       "4840                                                               1.0   \n",
       "4846                                         나도 딱 이 생각했다           8.0   \n",
       "4886   여돌 좋아했는데 지금은 공중분해됨, 와 오프라인에서 그런걸 한다고진짜 무슨 세계지 ...          15.0   \n",
       "5588   옹 고맙다, 스위트홈은 웹툰으로 봤어서경이로운 소문은 찾아볼게고마워, 지정생존자는 ...          20.0   \n",
       "6751   누백, 누백이 예전만큼 의미는 별로 없고각 학교별 위치를 놓고 원래 있어야될 것 같...          44.0   \n",
       "6851   음 그 진짜 옛날에서 멈춰있어 트레이스 강풀 치인트 이런거ㅋㅋ큐ㅠㅠ신의탑은 보다 중...          51.0   \n",
       "7440                                                               0.0   \n",
       "9120            응애세력이 무슨뜻, 야야 그렇다고 드립력까지 중국에 두고오면 어떡함 ㅠㅠ          20.0   \n",
       "9219                                                               1.0   \n",
       "10673  오 땡큐 한번 볼게, 그거 아직 완결 안 나지 않았나, 올해 3월, 그건 다봤당ㅎㅎ...          31.0   \n",
       "\n",
       "                                          text_tokenized  \\\n",
       "1067                       [(더, Noun), (재밌어, Adjective)]   \n",
       "1260   [(자주, Noun), (나오는, Verb), (떡밥, Noun), (다미, Nou...   \n",
       "1744   [(내, Noun), (친구, Noun), (들, Suffix), (중, Noun)...   \n",
       "1755   [(이건, Noun), (ㄹㅈㄷ, KoreanParticle), (영상, Noun)...   \n",
       "2328                       [(이렇게, Adverb), (끝난다고, Verb)]   \n",
       "2808                           [(변호사, Noun), (마저, Josa)]   \n",
       "3696   [(왜, Noun), (고용, Noun), (시장, Noun), (박살, Noun)...   \n",
       "4821   [(알, Noun), (페스, Noun), (랑, Josa), (딥, Noun), ...   \n",
       "4829   [(협박, Noun), (을, Josa), (통해, Noun), (실제, Noun)...   \n",
       "4833   [(꾸준히, Adjective), (비추, Verb), (박던거, Verb), (너...   \n",
       "4840   [(서담, Verb), (일주일, Noun), (만, Josa), (쉴게요, Ver...   \n",
       "4846   [(하도, Verb), (난리, Noun), (인데, Josa), (인기, Noun...   \n",
       "4886   [(이번, Noun), (에, Josa), (이슈, Noun), (돼서, Verb)...   \n",
       "5588   [(드라마, Noun), (완결, Noun), (을, Josa), (해본, Verb...   \n",
       "6751   [(올해, Noun), (입시, Noun), (는, Josa), (레전드, Noun...   \n",
       "6851   [(판타지, Noun), (든, Josa), (현, Modifier), (대물, N...   \n",
       "7440   [(요즘, Noun), (일상, Noun), (이, Josa), (너무, Adver...   \n",
       "9120   [(아니면, Adjective), (인기, Noun), (글, Noun), (감임,...   \n",
       "9219   [(이제, Noun), (국어, Noun), (몇, Modifier), (점, No...   \n",
       "10673  [(진짜, Noun), (초, Noun), (중반, Noun), (부는, Verb)...   \n",
       "\n",
       "                                         title_tokenized  \\\n",
       "1067   [(해리포터, Noun), (는, Josa), (떡밥, Noun), (을, Josa...   \n",
       "1260   [(입법고시, Noun), (법원, Noun), (행정고시, Noun), (5, N...   \n",
       "1744   [(타대, Verb), (언급, Noun), (글, Noun), (은, Josa),...   \n",
       "1755   [(잼일, Noun), (너무, Adverb), (잼있어, Verb), (ㅠㅠ, K...   \n",
       "2328                                     [(펜트하우스, Noun)]   \n",
       "2808   [(법, Noun), (까지, Josa), (건들, Adverb), (기, Noun...   \n",
       "3696   [(갑자기, Noun), (의대, Noun), (약대, Noun), (핫, Noun...   \n",
       "4821   [(근데, Adverb), (알, Noun), (페스, Noun), (랑, Josa...   \n",
       "4829   [(번방, Noun), (은, Josa), (알, Noun), (페스나, Noun)...   \n",
       "4833   [(알, Noun), (페스, Noun), (즐겼던, Verb), (다미, Noun...   \n",
       "4840   [(이번, Noun), (엔, Josa), (또, Noun), (뭔, Modifie...   \n",
       "4846   [(트위터, Noun), (에, Josa), (알, Noun), (페스, Noun)...   \n",
       "4886   [(현직, Noun), (남돌, Noun), (여, Modifier), (돌, No...   \n",
       "5588    [(한국, Noun), (드라마, Noun), (추천, Noun), (좀, Noun)]   \n",
       "6751     [(진짜, Noun), (입결, Noun), (실화, Noun), (냐, Josa)]   \n",
       "6851   [(웹툰, Noun), (추천, Noun), (좀, Noun), (해주, Noun)...   \n",
       "7440   [(요즘, Noun), (내, Noun), (일상, Noun), (무료, Noun)...   \n",
       "9120   [(착, Noun), (짱, Suffix), (죽, Noun), (짱, Suffix...   \n",
       "9219   [(시즌, Noun), (이, Josa), (벌써, Noun), (입결, Noun)...   \n",
       "10673  [(강철, Noun), (의, Josa), (연금술사, Noun), (같은, Adj...   \n",
       "\n",
       "                                      comments_tokenized  \\\n",
       "1067   [(뭔, Modifier), (데, Noun), (나도, Verb), (같이, Ad...   \n",
       "1260   [(솔직히, Adjective), (최근, Noun), (경향, Noun), (으로...   \n",
       "1744   [(그런, Modifier), (글, Noun), (몇개, Noun), (있음, A...   \n",
       "1755   [(,, Punctuation), (항상, Noun), (알림, Noun), (켜놨...   \n",
       "2328   [(시즌, Noun), (3, Number), (막판, Noun), (에, Josa...   \n",
       "2808   [(ㄹㅇ, KoreanParticle), (이러다가, Adverb), (유나바머, ...   \n",
       "3696   [(의대, Noun), (약대, Noun), (는, Josa), (늘, Noun),...   \n",
       "4821   [(108990015, Number), (이, Determiner), (걸, Nou...   \n",
       "4829   [(나도, Verb), (동의, Noun), (애초, Noun), (에, Josa)...   \n",
       "4833   [(다른, Noun), (범죄, Noun), (와는, Josa), (결, Noun)...   \n",
       "4840   [(흑, Adverb), (흑, Adverb), (나도, Verb), (슬퍼, Ad...   \n",
       "4846   [(내, Determiner), (로남, Noun), (불의, Noun), (말로,...   \n",
       "4886   [(ㄹㅇㄹㅇ, KoreanParticle), (어떻게, Adjective), (대응...   \n",
       "5588   [(비숲, Noun), (,, Punctuation), (보이스, Noun), (강...   \n",
       "6751   [(와, Verb), (ㅁㅊ, KoreanParticle), (,, Punctuat...   \n",
       "6851   [(웹툰, Noun), (을, Josa), (이미, Adverb), (어느, Adv...   \n",
       "7440                                                  []   \n",
       "9120   [(인기, Noun), (글, Noun), (갔다가, Verb), (응애, Noun...   \n",
       "9219   [(나, Noun), (두, Josa), (점수, Noun), (는, Josa), ...   \n",
       "10673  [(카우보이, Noun), (비밥, Noun), (재밌, Adjective), (엉...   \n",
       "\n",
       "                               comments_writer_tokenized  \n",
       "1067                                                  []  \n",
       "1260                                                  []  \n",
       "1744   [(아, Exclamation), (몰랐었다, Verb), (난, Noun), (이...  \n",
       "1755   [(설마, Noun), (진짜, Noun), (교미, Noun), (,, Punct...  \n",
       "2328   [(차라리, Noun), (차, Noun), (전복, Noun), (하고, Josa...  \n",
       "2808   [(데이터, Noun), (처리, Noun), (같은건, Adjective), (가...  \n",
       "3696                                                  []  \n",
       "4821   [(ㅇㅇ, KoreanParticle), (ㅜ, KoreanParticle), (합...  \n",
       "4829   [(ㄴㄴ, KoreanParticle), (근데, Adverb), (자꾸, Noun...  \n",
       "4833                                                  []  \n",
       "4840                                                  []  \n",
       "4846   [(나도, Verb), (딱, Adverb), (이, Noun), (생각, Noun...  \n",
       "4886   [(여, Modifier), (돌, Noun), (좋아했는데, Adjective),...  \n",
       "5588   [(옹, Noun), (고맙다, Adjective), (,, Punctuation)...  \n",
       "6751   [(누, Noun), (백, Suffix), (,, Punctuation), (누,...  \n",
       "6851   [(음, Noun), (그, Noun), (진짜, Noun), (옛날, Noun),...  \n",
       "7440                                                  []  \n",
       "9120   [(응애, Noun), (세력, Noun), (이, Josa), (무슨, Modif...  \n",
       "9219                                                  []  \n",
       "10673  [(오, Noun), (땡큐, Noun), (한번, Noun), (볼, Noun),...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_search('떡밥',1,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f63073",
   "metadata": {},
   "source": [
    "## 월별 인기 키워드 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d76da6e",
   "metadata": {},
   "source": [
    "### 작년 12월 데이터를 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f521e03d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>board</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>writer</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>view</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_writer</th>\n",
       "      <th>comments_cnt</th>\n",
       "      <th>popularity</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>comment_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>813032</td>\n",
       "      <td>익게2</td>\n",
       "      <td>2020년 파이팅!!</td>\n",
       "      <td>모두들 파이팅</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>1375</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>['올 첫글 ㅋㅋ', '아 너 뭔데 나보다 일찍 썼냐ㅡㅡ추천이나 먹어라', '첫글 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>[('파이팅', 'Noun')]</td>\n",
       "      <td>[('2020년', 'Number'), ('파이팅', 'Noun'), ('!!', ...</td>\n",
       "      <td>[(\"['\", 'Punctuation'), ('올', 'Verb'), ('첫', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>813033</td>\n",
       "      <td>익게2</td>\n",
       "      <td>새해</td>\n",
       "      <td>ㅊㅊ</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[('ㅊㅊ', 'KoreanParticle')]</td>\n",
       "      <td>[('새해', 'Noun')]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>813034</td>\n",
       "      <td>익게2</td>\n",
       "      <td>2020 첫 글 ㄱㅈㅇ</td>\n",
       "      <td>ㅇㅇ</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[('ㅇㅇ', 'KoreanParticle')]</td>\n",
       "      <td>[('2020', 'Number'), ('첫', 'Noun'), ('글', 'Nou...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>813037</td>\n",
       "      <td>익게2</td>\n",
       "      <td>ㅅㅅ</td>\n",
       "      <td>ㅅㅅ</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[('ㅅㅅ', 'KoreanParticle')]</td>\n",
       "      <td>[('ㅅㅅ', 'KoreanParticle')]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>813038</td>\n",
       "      <td>익게2</td>\n",
       "      <td>스물넷이다</td>\n",
       "      <td>뭐했다고 벌써</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>['어? 너두?', '난방금전까지 스물넷..']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[('뭐', 'Noun'), ('했다고', 'Verb'), ('벌써', 'Noun')]</td>\n",
       "      <td>[('스물넷', 'Noun'), ('이다', 'Josa')]</td>\n",
       "      <td>[(\"['\", 'Punctuation'), ('?', 'Punctuation'), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num board         title     text writer upload_date upload_time  view  \\\n",
       "0  813032   익게2   2020년 파이팅!!  모두들 파이팅     익명  2020-01-01       00:00  1375   \n",
       "1  813033   익게2            새해       ㅊㅊ     익명  2020-01-01       00:00    97   \n",
       "2  813034   익게2  2020 첫 글 ㄱㅈㅇ       ㅇㅇ     익명  2020-01-01       00:00   128   \n",
       "3  813037   익게2            ㅅㅅ       ㅅㅅ     익명  2020-01-01       00:00    70   \n",
       "4  813038   익게2         스물넷이다  뭐했다고 벌써     익명  2020-01-01       00:00   124   \n",
       "\n",
       "   likes  dislikes                                           comments  \\\n",
       "0    168         0  ['올 첫글 ㅋㅋ', '아 너 뭔데 나보다 일찍 썼냐ㅡㅡ추천이나 먹어라', '첫글 ...   \n",
       "1      2         0                                                NaN   \n",
       "2      1         0                                                NaN   \n",
       "3      0         0                                                NaN   \n",
       "4      3         0                         ['어? 너두?', '난방금전까지 스물넷..']   \n",
       "\n",
       "  comments_writer  comments_cnt  popularity  \\\n",
       "0             NaN            14           1   \n",
       "1             NaN             0           0   \n",
       "2             NaN             0           0   \n",
       "3             NaN             0           0   \n",
       "4             NaN             2           0   \n",
       "\n",
       "                                     text_tokenized  \\\n",
       "0                                 [('파이팅', 'Noun')]   \n",
       "1                        [('ㅊㅊ', 'KoreanParticle')]   \n",
       "2                        [('ㅇㅇ', 'KoreanParticle')]   \n",
       "3                        [('ㅅㅅ', 'KoreanParticle')]   \n",
       "4  [('뭐', 'Noun'), ('했다고', 'Verb'), ('벌써', 'Noun')]   \n",
       "\n",
       "                                     title_tokenized  \\\n",
       "0  [('2020년', 'Number'), ('파이팅', 'Noun'), ('!!', ...   \n",
       "1                                   [('새해', 'Noun')]   \n",
       "2  [('2020', 'Number'), ('첫', 'Noun'), ('글', 'Nou...   \n",
       "3                         [('ㅅㅅ', 'KoreanParticle')]   \n",
       "4                  [('스물넷', 'Noun'), ('이다', 'Josa')]   \n",
       "\n",
       "                                   comment_tokenized  \n",
       "0  [(\"['\", 'Punctuation'), ('올', 'Verb'), ('첫', '...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  [(\"['\", 'Punctuation'), ('?', 'Punctuation'), ...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_20 = pd.read_csv('./data_l/ssodam2020_all_tokened_final.csv', encoding='utf-8')\n",
    "#날짜 데이터를 datetime으로.\n",
    "tokens_20.upload_date = pd.to_datetime(tokens_20.upload_date)\n",
    "tokens_20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ad24deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_list_from_str(msg):\n",
    "    try :\n",
    "        return [tuple([re.sub(\"'\",'',y) for y in re.findall('\\'.*?\\'',x)]) for x in re.findall('\\(.*?\\)',msg)]\n",
    "    except :\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6b04347c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>board</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>writer</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>view</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_writer</th>\n",
       "      <th>comments_cnt</th>\n",
       "      <th>popularity</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>comments_writer_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161968</th>\n",
       "      <td>1058725</td>\n",
       "      <td>익게2</td>\n",
       "      <td>엽기붕어빵ㅋㅋ</td>\n",
       "      <td>붕어빵10개 1만 6천원ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>00:06</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['ㅈ같은 프리미엄화 좀 하지마라ㅠ']</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[(붕어빵, Noun), (10, Number), (개, Noun), (1만, Nu...</td>\n",
       "      <td>[(엽기, Noun), (붕어빵, Noun), (ㅋㅋ, KoreanParticle)]</td>\n",
       "      <td>[(\", ,), (ㅈ, KoreanParticle), (같은, Adjective),...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161969</th>\n",
       "      <td>1058727</td>\n",
       "      <td>익게2</td>\n",
       "      <td>다미들 푸우욱 잘 자라옹</td>\n",
       "      <td>졸리다냥</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>00:07</td>\n",
       "      <td>143</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(졸리다냥, Verb)]</td>\n",
       "      <td>[(푸우, Noun), (욱, Noun), (자라, Noun), (옹, Noun)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161970</th>\n",
       "      <td>1058728</td>\n",
       "      <td>익게2</td>\n",
       "      <td>나 시 써봤는데 어때</td>\n",
       "      <td>거울 속에 한 사내가 서있다사내는 거울 속 자신의 모습이 볼품없다사내는 그런 자신의...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>00:08</td>\n",
       "      <td>245</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>['거사사 너때 때멈 살그... 라고요???? 말이 너무 심하시네요!! 비추드립니다...</td>\n",
       "      <td>['뭐라는거야ㅋㅋㅋㅋ', '저도 쓰고보니 이상 거울이랑 윤동주 자화상이랑 살짝 섞인...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[(거울, Noun), (속, Noun), (사내, Noun), (서있다, Verb...</td>\n",
       "      <td>[(시, Noun), (써, Verb), (봤는데, Verb)]</td>\n",
       "      <td>[(\", ,), (사사, Noun), (때멈, Noun), (살그, Noun), (...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161971</th>\n",
       "      <td>1058729</td>\n",
       "      <td>익게2</td>\n",
       "      <td>민법 한번 공부해 보고싶은데.. 인강 뭐 들어야할지 모르겠어ㅜ</td>\n",
       "      <td>세무사 민법이랑                                법무사 민법...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>00:09</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>['로스쿨 민법 어때? - 로스쿨다미', '자기계발용으로는 적합한지 모르겠지만ㅋㅋㅋ...</td>\n",
       "      <td>['헤헤 그거 들어볼까?? 혹시 추천 강사님 물어봐도돼?ㅎ', 'ㅋㅋㅋㅋ']</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[(세무사, Noun), (민법, Noun), (법무사, Noun), (민법, No...</td>\n",
       "      <td>[(민법, Noun), (한번, Noun), (공부, Noun), (해, Verb)...</td>\n",
       "      <td>[(\", ,), (로스쿨, Noun), (민법, Noun), (?, Punctuat...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161972</th>\n",
       "      <td>1058730</td>\n",
       "      <td>익게2</td>\n",
       "      <td>가정내에서도 결국 사회생활하듯이 살아야할까</td>\n",
       "      <td>나는 엄마랑 감정적으로 친해지고 싶지 않아말하는 관점이 너어어어무 다르고 남 험담을...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>00:10</td>\n",
       "      <td>376</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>['솔직히 내가 그 상황이 아니니까 답은 알 수 없지만, 나라면 안 드려 이번에 드...</td>\n",
       "      <td>['진짜 고민이야 ㅠㅠ 정말 오늘 아침도 또 아빠욕하길래 못들어주겟다고 하고 나왔는...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[(엄마, Noun), (랑, Josa), (감정, Noun), (적, Suffix...</td>\n",
       "      <td>[(가정, Noun), (내, Noun), (에서도, Josa), (사회생활, No...</td>\n",
       "      <td>[(\", ,), (솔직히, Adjective), (내, Noun), (상황, Nou...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            num board                               title  \\\n",
       "161968  1058725   익게2                             엽기붕어빵ㅋㅋ   \n",
       "161969  1058727   익게2                       다미들 푸우욱 잘 자라옹   \n",
       "161970  1058728   익게2                         나 시 써봤는데 어때   \n",
       "161971  1058729   익게2  민법 한번 공부해 보고싶은데.. 인강 뭐 들어야할지 모르겠어ㅜ   \n",
       "161972  1058730   익게2             가정내에서도 결국 사회생활하듯이 살아야할까   \n",
       "\n",
       "                                                     text writer upload_date  \\\n",
       "161968  붕어빵10개 1만 6천원ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ...     익명  2020-12-01   \n",
       "161969                                               졸리다냥     익명  2020-12-01   \n",
       "161970  거울 속에 한 사내가 서있다사내는 거울 속 자신의 모습이 볼품없다사내는 그런 자신의...     익명  2020-12-01   \n",
       "161971  세무사 민법이랑                                법무사 민법...     익명  2020-12-01   \n",
       "161972  나는 엄마랑 감정적으로 친해지고 싶지 않아말하는 관점이 너어어어무 다르고 남 험담을...     익명  2020-12-01   \n",
       "\n",
       "       upload_time  view  likes  dislikes  \\\n",
       "161968       00:06   124      0         0   \n",
       "161969       00:07   143      7         0   \n",
       "161970       00:08   245      7         0   \n",
       "161971       00:09   221      0         2   \n",
       "161972       00:10   376     11         0   \n",
       "\n",
       "                                                 comments  \\\n",
       "161968                              ['ㅈ같은 프리미엄화 좀 하지마라ㅠ']   \n",
       "161969                                                      \n",
       "161970  ['거사사 너때 때멈 살그... 라고요???? 말이 너무 심하시네요!! 비추드립니다...   \n",
       "161971  ['로스쿨 민법 어때? - 로스쿨다미', '자기계발용으로는 적합한지 모르겠지만ㅋㅋㅋ...   \n",
       "161972  ['솔직히 내가 그 상황이 아니니까 답은 알 수 없지만, 나라면 안 드려 이번에 드...   \n",
       "\n",
       "                                          comments_writer  comments_cnt  \\\n",
       "161968                                                                1   \n",
       "161969                                                                0   \n",
       "161970  ['뭐라는거야ㅋㅋㅋㅋ', '저도 쓰고보니 이상 거울이랑 윤동주 자화상이랑 살짝 섞인...             8   \n",
       "161971         ['헤헤 그거 들어볼까?? 혹시 추천 강사님 물어봐도돼?ㅎ', 'ㅋㅋㅋㅋ']             8   \n",
       "161972  ['진짜 고민이야 ㅠㅠ 정말 오늘 아침도 또 아빠욕하길래 못들어주겟다고 하고 나왔는...            11   \n",
       "\n",
       "        popularity                                     text_tokenized  \\\n",
       "161968           0  [(붕어빵, Noun), (10, Number), (개, Noun), (1만, Nu...   \n",
       "161969           0                                     [(졸리다냥, Verb)]   \n",
       "161970           0  [(거울, Noun), (속, Noun), (사내, Noun), (서있다, Verb...   \n",
       "161971           0  [(세무사, Noun), (민법, Noun), (법무사, Noun), (민법, No...   \n",
       "161972           0  [(엄마, Noun), (랑, Josa), (감정, Noun), (적, Suffix...   \n",
       "\n",
       "                                          title_tokenized  \\\n",
       "161968    [(엽기, Noun), (붕어빵, Noun), (ㅋㅋ, KoreanParticle)]   \n",
       "161969     [(푸우, Noun), (욱, Noun), (자라, Noun), (옹, Noun)]   \n",
       "161970                [(시, Noun), (써, Verb), (봤는데, Verb)]   \n",
       "161971  [(민법, Noun), (한번, Noun), (공부, Noun), (해, Verb)...   \n",
       "161972  [(가정, Noun), (내, Noun), (에서도, Josa), (사회생활, No...   \n",
       "\n",
       "                                       comments_tokenized  \\\n",
       "161968  [(\", ,), (ㅈ, KoreanParticle), (같은, Adjective),...   \n",
       "161969                                                 []   \n",
       "161970  [(\", ,), (사사, Noun), (때멈, Noun), (살그, Noun), (...   \n",
       "161971  [(\", ,), (로스쿨, Noun), (민법, Noun), (?, Punctuat...   \n",
       "161972  [(\", ,), (솔직히, Adjective), (내, Noun), (상황, Nou...   \n",
       "\n",
       "       comments_writer_tokenized  \n",
       "161968                        []  \n",
       "161969                        []  \n",
       "161970                        []  \n",
       "161971                        []  \n",
       "161972                        []  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12월 데이터만 추려내어 처리\n",
    "tokens_20_12 = tokens_20[tokens_20.upload_date.apply(lambda x: True if x.month==12 else False)]\n",
    "tokens_20_12 = tokens_20_12.fillna('')\n",
    "tokens_20_12.text_tokenized = tokens_20_12.text_tokenized.apply(lambda x: get_noun_list_from_str(x))\n",
    "tokens_20_12.title_tokenized = tokens_20_12.title_tokenized.apply(lambda x: get_noun_list_from_str(x))\n",
    "tokens_20_12.comment_tokenized = tokens_20_12.comment_tokenized.apply(lambda x: get_noun_list_from_str(x))\n",
    "tokens_20_12['comments_writer_tokenized'] = [[] for _ in range(len(tokens_20_12))]\n",
    "tokens_20_12.rename(columns={'comment_tokenized':'comments_tokenized'},inplace=True)\n",
    "tokens_20_12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2ce77b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num', 'board', 'title', 'text', 'writer', 'upload_date', 'upload_time',\n",
       "       'view', 'likes', 'dislikes', 'comments', 'comments_writer',\n",
       "       'comments_cnt', 'popularity', 'text_tokenized', 'title_tokenized',\n",
       "       'comments_tokenized', 'comments_writer_tokenized'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_20_12.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a84bb8e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num', 'board', 'title', 'text', 'writer', 'upload_date', 'upload_time',\n",
       "       'view', 'likes', 'dislikes', 'comments', 'comments_writer',\n",
       "       'comments_cnt', 'text_tokenized', 'title_tokenized',\n",
       "       'comments_tokenized', 'comments_writer_tokenized'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac5a2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([tokens_20_12,df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc0b984",
   "metadata": {},
   "source": [
    "### 익게2 12월~6월간 BoW 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f65218",
   "metadata": {},
   "source": [
    "전체 데이터프레임을 월별로 groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f838f903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upload_month': [12, 1, 2, 3, 4, 5, 6],\n",
       " 'title_tokenized': [[], [], [], [], [], [], []],\n",
       " 'text_tokenized': [[], [], [], [], [], [], []],\n",
       " 'comments_tokenized': [[], [], [], [], [], [], []],\n",
       " 'comments_writer_tokenized': [[], [], [], [], [], [], []]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm_dict = dict.fromkeys(['upload_month','title_tokenized','text_tokenized','comments_tokenized','comments_writer_tokenized'])\n",
    "\n",
    "for key in cfm_dict.keys():\n",
    "    if key == 'upload_month':\n",
    "        cfm_dict[key] = [12]+[i+1 for i in range(6)]\n",
    "    else:\n",
    "        cfm_dict[key] = [[] for i in range(7)]\n",
    "\n",
    "cfm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "a7beb5fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index : 9999 processing...\n",
      "index : 19999 processing...\n",
      "index : 29999 processing...\n",
      "index : 39999 processing...\n",
      "index : 49999 processing...\n",
      "index : 59999 processing...\n",
      "index : 69999 processing...\n"
     ]
    }
   ],
   "source": [
    "_df = df2.loc[df2.board=='익게2']\n",
    "\n",
    "for idx in range(len(_df)):\n",
    "    if (idx+1)%10000==0:\n",
    "        print('index :',idx,'processing...')\n",
    "    row = _df.iloc[idx]\n",
    "    #데이터프레임으로부터 월 인덱스 탐색\n",
    "    month = 0 if row.upload_date.month==12 else row.upload_date.month\n",
    "    #칼럼별 해당 인덱스에 해당되는 토큰 저장\n",
    "    #50단어가 넘는 장문의 글은 제거하고 댓글과 제목만 남김.\n",
    "    if len(row.text_tokenized) > 50:\n",
    "        pass\n",
    "    else :\n",
    "        cfm_dict['text_tokenized'][month] += row.text_tokenized\n",
    "    cfm_dict['title_tokenized'][month] += row.title_tokenized\n",
    "    cfm_dict['comments_tokenized'][month] += row.comments_tokenized\n",
    "    cfm_dict['comments_writer_tokenized'][month] += row.comments_writer_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "4cb9a6a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upload_month</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>comments_writer_tokenized</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>[(엽기, Noun), (붕어빵, Noun), (ㅋㅋ, KoreanParticle)...</td>\n",
       "      <td>[(붕어빵, Noun), (10, Number), (개, Noun), (1만, Nu...</td>\n",
       "      <td>[(\", ,), (ㅈ, KoreanParticle), (같은, Adjective),...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(엽기, Noun), (붕어빵, Noun), (ㅋㅋ, KoreanParticle)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[(해피뉴이어, Noun), (2021년, Number), (새해, Noun), (...</td>\n",
       "      <td>[(2021년, Number), (은, Foreign), (모두, Noun), (행...</td>\n",
       "      <td>[(앗, Noun), (,, Punctuation), (성지, Noun), (다, ...</td>\n",
       "      <td>[(2, Number), (빠다, Noun), (ㅎㅎ, KoreanParticle)...</td>\n",
       "      <td>[(해피뉴이어, Noun), (2021년, Number), (새해, Noun), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[(않이, Verb), (모해, Noun), (따고, Verb), (벌써, Noun...</td>\n",
       "      <td>[(2월, Number), (이냐, Foreign), (지인, Noun), (이, ...</td>\n",
       "      <td>[(난, Noun), (마카롱, Noun), (세트, Noun), (했아, Verb...</td>\n",
       "      <td>[(오, Noun), (좋다, Adjective), (고마워, Adjective),...</td>\n",
       "      <td>[(않이, Verb), (모해, Noun), (따고, Verb), (벌써, Noun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[(약, Noun), (19, Number), (저가, Noun), (코스프레, N...</td>\n",
       "      <td>[(취미, Noun), (로, Josa), (배워, Verb), (보고싶어, Ver...</td>\n",
       "      <td>[(진짜, Noun), (이형, Noun), (꾸준하네, Adjective), (,...</td>\n",
       "      <td>[(고마워, Adjective), (덕분, Noun), (에, Josa), (등업,...</td>\n",
       "      <td>[(약, Noun), (19, Number), (저가, Noun), (코스프레, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[(만우절, Noun), (이, Josa), (벌써, Noun), (끝나, Verb...</td>\n",
       "      <td>[(아쉽다, Adjective), (아쉬워, Adjective), (연애, Noun...</td>\n",
       "      <td>[(스타트, Noun), (가, Josa), (좋구만, Adjective), (ㄱㄱ...</td>\n",
       "      <td>[(나, Noun), (에게, Josa), (있다고, Adjective), (,, ...</td>\n",
       "      <td>[(만우절, Noun), (이, Josa), (벌써, Noun), (끝나, Verb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[(2021년, Number), (5월, Number), (첫, Noun), (글,...</td>\n",
       "      <td>[(새로운, Adjective), (달도, Noun), (희망, Noun), (차게...</td>\n",
       "      <td>[(뭔, Modifier), (데, Noun), (벌써, Noun), (5월, Nu...</td>\n",
       "      <td>[(아, Exclamation), (진짜, Noun), (로, Josa), (그럼,...</td>\n",
       "      <td>[(2021년, Number), (5월, Number), (첫, Noun), (글,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[(지금, Noun), (퇴근, Noun), (하는, Verb), (길, Noun)...</td>\n",
       "      <td>[(입사, Noun), (1년, Number), (아직, Adverb), (안된, ...</td>\n",
       "      <td>[(화이팅, Noun), (시간, Noun), (이, Josa), (지나면, Ver...</td>\n",
       "      <td>[(전망, Noun), (좋고, Adjective), (과제, Noun), (하기,...</td>\n",
       "      <td>[(지금, Noun), (퇴근, Noun), (하는, Verb), (길, Noun)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   upload_month                                    title_tokenized  \\\n",
       "0            12  [(엽기, Noun), (붕어빵, Noun), (ㅋㅋ, KoreanParticle)...   \n",
       "1             1  [(해피뉴이어, Noun), (2021년, Number), (새해, Noun), (...   \n",
       "2             2  [(않이, Verb), (모해, Noun), (따고, Verb), (벌써, Noun...   \n",
       "3             3  [(약, Noun), (19, Number), (저가, Noun), (코스프레, N...   \n",
       "4             4  [(만우절, Noun), (이, Josa), (벌써, Noun), (끝나, Verb...   \n",
       "5             5  [(2021년, Number), (5월, Number), (첫, Noun), (글,...   \n",
       "6             6  [(지금, Noun), (퇴근, Noun), (하는, Verb), (길, Noun)...   \n",
       "\n",
       "                                      text_tokenized  \\\n",
       "0  [(붕어빵, Noun), (10, Number), (개, Noun), (1만, Nu...   \n",
       "1  [(2021년, Number), (은, Foreign), (모두, Noun), (행...   \n",
       "2  [(2월, Number), (이냐, Foreign), (지인, Noun), (이, ...   \n",
       "3  [(취미, Noun), (로, Josa), (배워, Verb), (보고싶어, Ver...   \n",
       "4  [(아쉽다, Adjective), (아쉬워, Adjective), (연애, Noun...   \n",
       "5  [(새로운, Adjective), (달도, Noun), (희망, Noun), (차게...   \n",
       "6  [(입사, Noun), (1년, Number), (아직, Adverb), (안된, ...   \n",
       "\n",
       "                                  comments_tokenized  \\\n",
       "0  [(\", ,), (ㅈ, KoreanParticle), (같은, Adjective),...   \n",
       "1  [(앗, Noun), (,, Punctuation), (성지, Noun), (다, ...   \n",
       "2  [(난, Noun), (마카롱, Noun), (세트, Noun), (했아, Verb...   \n",
       "3  [(진짜, Noun), (이형, Noun), (꾸준하네, Adjective), (,...   \n",
       "4  [(스타트, Noun), (가, Josa), (좋구만, Adjective), (ㄱㄱ...   \n",
       "5  [(뭔, Modifier), (데, Noun), (벌써, Noun), (5월, Nu...   \n",
       "6  [(화이팅, Noun), (시간, Noun), (이, Josa), (지나면, Ver...   \n",
       "\n",
       "                           comments_writer_tokenized  \\\n",
       "0                                                 []   \n",
       "1  [(2, Number), (빠다, Noun), (ㅎㅎ, KoreanParticle)...   \n",
       "2  [(오, Noun), (좋다, Adjective), (고마워, Adjective),...   \n",
       "3  [(고마워, Adjective), (덕분, Noun), (에, Josa), (등업,...   \n",
       "4  [(나, Noun), (에게, Josa), (있다고, Adjective), (,, ...   \n",
       "5  [(아, Exclamation), (진짜, Noun), (로, Josa), (그럼,...   \n",
       "6  [(전망, Noun), (좋고, Adjective), (과제, Noun), (하기,...   \n",
       "\n",
       "                                        total_tokens  \n",
       "0  [(엽기, Noun), (붕어빵, Noun), (ㅋㅋ, KoreanParticle)...  \n",
       "1  [(해피뉴이어, Noun), (2021년, Number), (새해, Noun), (...  \n",
       "2  [(않이, Verb), (모해, Noun), (따고, Verb), (벌써, Noun...  \n",
       "3  [(약, Noun), (19, Number), (저가, Noun), (코스프레, N...  \n",
       "4  [(만우절, Noun), (이, Josa), (벌써, Noun), (끝나, Verb...  \n",
       "5  [(2021년, Number), (5월, Number), (첫, Noun), (글,...  \n",
       "6  [(지금, Noun), (퇴근, Noun), (하는, Verb), (길, Noun)...  "
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm = pd.DataFrame(cfm_dict)\n",
    "cfm['total_tokens'] = cfm.title_tokenized + cfm.text_tokenized + cfm.comments_tokenized + cfm.comments_writer_tokenized\n",
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "0cdb9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Token's Bag of Words\n",
    "corpus_extended = []\n",
    "for column in ['total_tokens']:\n",
    "    for text in cfm[column]:\n",
    "        for word in text:\n",
    "            try:\n",
    "                if word[1]=='Noun':\n",
    "                    if word[0] not in stopwords:\n",
    "                        corpus_extended.append(word[0])\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "c0b3f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_extended = {}\n",
    "bow_extended = []\n",
    "\n",
    "for token in corpus_extended:\n",
    "    if token not in idx_extended.keys():\n",
    "        idx_extended[token] = len(idx_extended)\n",
    "        bow_extended.insert(len(idx_extended)-1,1)\n",
    "    else:\n",
    "        bow_extended[idx_extended[token]] += 1\n",
    "        \n",
    "idx_extended_key = list(idx_extended.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b98b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open('./data/idx_extended.pkl','wb') as f:\n",
    "    pickle.dump(idx_extended,f)\n",
    "with open('./data/bow_extended.pkl','wb') as f:\n",
    "    pickle.dump(bow_extended,f)\n",
    "'''\n",
    "with open('./data/idx_extended.pkl','rb') as f:\n",
    "    idx_extended = pickle.load(f)\n",
    "with open('./data/bow_extended.pkl','rb') as f:\n",
    "    bow_extended = pickle.load(f)\n",
    "idx_extended_key = list(idx_extended.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4651aba",
   "metadata": {},
   "source": [
    "###  Word별 게시글 수 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "id": "f1960ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_words(x):\n",
    "    output = []\n",
    "    for token in x:\n",
    "        if len(token)>1:\n",
    "            output.append(token[0])\n",
    "        else:\n",
    "            pass\n",
    "    return output\n",
    "\n",
    "df2['total_tokens'] = df2.title_tokenized + df2.text_tokenized + df2.comments_tokenized + df2.comments_writer_tokenized\n",
    "df2['_total_tokens'] = df2['total_tokens'].apply(lambda x : return_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1554,
   "id": "41822988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "month_filter = []\n",
    "for i in range(7):\n",
    "    if i==0:\n",
    "        month_filter.append((datetime(2020,12,1)<=df2.upload_date) & (df2.upload_date<datetime(2021,1,1)) & (df2.board=='익게2'))\n",
    "    else:\n",
    "        month_filter.append((datetime(2021,i,1)<=df2.upload_date) & (df2.upload_date<datetime(2021,i+1,1)) & (df2.board=='익게2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca81f4",
   "metadata": {},
   "source": [
    "import time\n",
    "\n",
    "posts_extended = np.zeros((7,len(idx_extended)))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, word in enumerate(idx_extended):\n",
    "    if i%1000 == 0:\n",
    "        print(i,'번째 단어 처리중...',i-1000,'번째로부터',time.time()-start_time,'초 경과.')\n",
    "        start_time = time.time()\n",
    "    _all_posts = df2._total_tokens.apply(lambda x: True if word in x else False)\n",
    "    for j in range(0,7):\n",
    "        posts_extended[j,i] = _all_posts[month_filter[j]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccda7497",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/posts_extended.pkl','rb') as f:\n",
    "    posts_extended = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b6e137",
   "metadata": {},
   "source": [
    "### 익게2 데이터로부터 월별 BoW 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc8a31",
   "metadata": {},
   "source": [
    "__BoW 생성__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "e341fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bows = []\n",
    "\n",
    "for month in range(7):\n",
    "    bow = np.zeros(len(idx_extended.keys()))\n",
    "    \n",
    "    for word in cfm.iloc[month].total_tokens:\n",
    "        #()등 빈 단어들은 패스\n",
    "        if len(word)!=2:\n",
    "            continue\n",
    "        if (word[1]=='Noun') and (word[0] not in stopwords):\n",
    "            try:\n",
    "                bow[idx_extended[word[0]]] += 1\n",
    "            except:\n",
    "                print('Error occured')\n",
    "                \n",
    "    bows.append(bow)\n",
    "\n",
    "cfm['BoW'] = bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e8d16ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "with open('./data_l/cfm.pkl','wb') as f:\n",
    "    pickle.dump(cfm,f)\n",
    "'''\n",
    "with open('./data_l/cfm.pkl','rb') as f:\n",
    "    cfm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c110e5c",
   "metadata": {},
   "source": [
    "### 급상승 지수 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd31e173",
   "metadata": {},
   "source": [
    "idx_total & bow_total로부터 각 월마다 키워드별 급상승지수 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48e183",
   "metadata": {},
   "source": [
    "월별 급상승 지수\n",
    "1. 전월 언급 횟수 a\n",
    "2. 당월 언급된 횟수 b\n",
    "3. 전월 게시글 작성 횟수 c\n",
    "3. 당월 게시글 작성 횟수 d\n",
    "4. 전체 기간(2020.12~2021.6) 중 언급 횟수 e\n",
    "5. 가중치 w0, w1, w2, w3, w4\n",
    "6. 적당한 상수 K, 아주 작은 상수 E\n",
    "\n",
    "w0 x sigmoid((b-a)/(a+K1)) + w1 x {tanh(0.05 x (b-K2)) - 0.5} + w2 x sigmoid((d-c)/(c+K3)) + w3 x {tanh(0.1 x (d-20)) - 0.7} + w4 x e^E\n",
    "\n",
    "- 월별 등장 횟수는 일별 등장 횟수에 비해 양에 대한 기준치를 높여야 하므로, K1과 K2를 상향 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "fa1290d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    if x<0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def sigmoid2(x):\n",
    "    return 1/( 1+np.exp( -(x-5) ) )\n",
    "\n",
    "#   [w0,   w1,  w2,  w3,    w4,  K1,  K2, K3, E]    \n",
    "W = [1.5, 0.3, 1.3, 0.5, -0.05, 10, 100, 10, 0.002]\n",
    "\n",
    "def _hot_point3(a,b,c,d,e):\n",
    "    x0 = sigmoid2((b-a)/(a+W[5]))\n",
    "    x1 = np.tanh(0.05*(b-W[6]))-0.5\n",
    "    x2 = sigmoid2((d-c)/(c+W[7]))\n",
    "    x3 = np.tanh(0.1*(d-20))-0.7\n",
    "    x4 = pow(1+W[8],e) - 1\n",
    "    \n",
    "    return W[0]*x0, W[1]*x1, W[2]*x2, W[3]*x3, W[4]*x4\n",
    "    \n",
    "def hot_point3(a,b,c,d,e):\n",
    "    x,y,z,w,v = _hot_point3(a,b,c,d,e)\n",
    "    return x + y + z + w + v\n",
    "\n",
    "def pp3(a,b,c,d,idx):\n",
    "    e = BoW_mat[:,idx].sum()\n",
    "    x, y, z, w, v = _hot_point3(a,b,c,d,e)\n",
    "    print(f'상승률지수 : {x}')\n",
    "    print(f'언급지수   : {y}')\n",
    "    print(f'게시글상승 : {z}')\n",
    "    print(f'게시글수   : {w}')\n",
    "    print(f'패널티     : {v}')\n",
    "    print(f'최종값     : {x+y+z+w+v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "01057100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 36., 194.,   6., ...,   0.,   0.,   0.],\n",
       "       [ 18.,  29.,   4., ...,   0.,   0.,   0.],\n",
       "       [  4.,  20.,   0., ...,   0.,   0.,   0.],\n",
       "       ...,\n",
       "       [  3.,  38.,   8., ...,   0.,   0.,   0.],\n",
       "       [ 22.,  18.,   3., ...,   0.,   0.,   0.],\n",
       "       [ 12.,  39.,   3., ...,   3.,   3.,   3.]])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BoW 매트릭스\n",
    "BoW_mat = np.array([list(value) for value in cfm.BoW.values])\n",
    "BoW_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "a47c42f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 날짜/단어별 급상승 지수 계산\n",
    "cfm['points'] = [np.zeros(len(bow_extended)) for i in range(len(cfm))]\n",
    "\n",
    "for i in range(1,len(BoW_mat)):\n",
    "    for j in range(len(bow_extended)):\n",
    "        cfm.points[i][j] = hot_point3(BoW_mat[i-1,j],BoW_mat[i,j],\n",
    "                                      posts_extended[i-1,j],posts_extended[i,j],\n",
    "                                      BoW_mat[:,j].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "00d7cdeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.26481776, -1.2968079 , -1.26402542, ..., -1.26354717,\n",
       "        -1.26354717, -1.26354717],\n",
       "       [-1.27580816, -1.31301699, -1.26999508, ..., -1.26354717,\n",
       "        -1.26354717, -1.26354717],\n",
       "       ...,\n",
       "       [-1.27342948, -1.28727906, -1.25261751, ..., -1.26354717,\n",
       "        -1.26354717, -1.26354717],\n",
       "       [-1.16918425, -1.29200404, -1.26651268, ..., -1.26354717,\n",
       "        -1.26354717, -1.26354717],\n",
       "       [-1.27101071, -1.26587024, -1.26285661, ..., -1.25525361,\n",
       "        -1.25525361, -1.25525361]])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Points 매트릭스\n",
    "Points = np.array([list(value) for value in cfm.points.values])\n",
    "Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeb6f39",
   "metadata": {},
   "source": [
    "__추가 불용어 정의__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "83d9179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#도배된 단어 등 제외\n",
    "for x_word in ['는','걍','을해','얀','인데','꿀꿀','끝내','쿠','원','쿠나','게로','사지','능','조만간','알폰소','아론']:\n",
    "    Points[:,idx_extended[x_word]] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2232608a",
   "metadata": {},
   "source": [
    "### 상위 키워드 추리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "42f97d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index 찾아 True로 저장할 ndarray 정의\n",
    "top10s = np.zeros(Points.shape, dtype=bool)\n",
    "top20s = np.zeros(Points.shape, dtype=bool)\n",
    "\n",
    "for i in range(1,len(Points)):\n",
    "    #날짜별 점수 상위 10개만 추림\n",
    "    limit_10 = np.sort(Points[i,:])[-10]\n",
    "    limit_20 = np.sort(Points[i,:])[-20]\n",
    "    for j in range(Points.shape[1]):\n",
    "        if Points[i,j]>=limit_20:\n",
    "            #상위 20개에 대해 True값으로 저장\n",
    "            top20s[i,j] = True\n",
    "            \n",
    "            if Points[i,j]>=limit_10:\n",
    "                #상위 10개에 대해 True값으로 저장\n",
    "                top10s[i,j] = True\n",
    "\n",
    "top10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "a980756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#일별 상위 10개 키워드 저장\n",
    "top10_keywords = [[idx_extended_key[int(j)] for j in np.arange(top10s.shape[1])[top10s[i]]] for i in range(len(top10s))]\n",
    "#일별 상위 20개 키워드 저장\n",
    "top20_keywords = [[idx_extended_key[int(j)] for j in np.arange(top20s.shape[1])[top20s[i]]] for i in range(len(top20s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "8ac2360d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['눈사람', '능검', '공론', '재래시장', '페스', '페이크', '정인', '로토', '팬픽', '강민철'],\n",
       " ['증원', '쿼터', '뻔뻔', '연강', '괴롭힘', '뻔선', '뻔후', '폭로', '학폭', '학교폭력'],\n",
       " ['피셋', '결석', '벚꽃', '로나', '검찰', '토지', '신도시', '투기', '단태', '브레이브걸스'],\n",
       " ['파상', '벼락치기', '클로즈', '분포', '슈퍼리그', '비제', '권혁', '만우절', '서예지', '김정현'],\n",
       " ['참가자', '퇴소', '자진', '파이', '정민', '퍼즐', '이루리', '공혁준', '또즐', '니갸르'],\n",
       " ['부정행위', '텀페', '중회', '독일', '관회', '메리트', '광학', '팬덤', '유로', '소희']]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "ee240aba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['눈사람',\n",
       "  '능검',\n",
       "  '공론',\n",
       "  '재래시장',\n",
       "  '페스',\n",
       "  '페이크',\n",
       "  '손예진',\n",
       "  '삽자루',\n",
       "  '정인',\n",
       "  '로토',\n",
       "  '팬픽',\n",
       "  '보따리',\n",
       "  '강민철',\n",
       "  '불평',\n",
       "  '와이번스',\n",
       "  '동포',\n",
       "  '담배값',\n",
       "  '냉면',\n",
       "  '아나콘다',\n",
       "  '오줌싸개'],\n",
       " ['증원',\n",
       "  '물성',\n",
       "  '성폭행',\n",
       "  '쿼터',\n",
       "  '설날',\n",
       "  '뻔뻔',\n",
       "  '사인',\n",
       "  '연강',\n",
       "  '괴롭힘',\n",
       "  '뻔선',\n",
       "  '연휴',\n",
       "  '방관',\n",
       "  '뻔후',\n",
       "  '폭로',\n",
       "  '학폭',\n",
       "  '학교폭력',\n",
       "  '탈세',\n",
       "  '동물원',\n",
       "  '김연경',\n",
       "  '역군'],\n",
       " ['장관',\n",
       "  '피셋',\n",
       "  '에이프릴',\n",
       "  '결석',\n",
       "  '벚꽃',\n",
       "  '로나',\n",
       "  '검찰',\n",
       "  '역주행',\n",
       "  '토지',\n",
       "  '신도시',\n",
       "  '서진',\n",
       "  '투기',\n",
       "  '유신',\n",
       "  '롤린',\n",
       "  '단태',\n",
       "  '브레이브걸스',\n",
       "  '마사',\n",
       "  '몰수',\n",
       "  '하윤',\n",
       "  '꼬북좌'],\n",
       " ['부정행위',\n",
       "  '파상',\n",
       "  '벼락치기',\n",
       "  '테뱅',\n",
       "  '클로즈',\n",
       "  '토트넘',\n",
       "  '분포',\n",
       "  '슈퍼리그',\n",
       "  '비제',\n",
       "  '너비',\n",
       "  '간담',\n",
       "  '애정',\n",
       "  '작',\n",
       "  '윽박',\n",
       "  '결식',\n",
       "  '권혁',\n",
       "  '만우절',\n",
       "  '서예지',\n",
       "  '진순',\n",
       "  '김정현'],\n",
       " ['코난',\n",
       "  '범인',\n",
       "  '전기',\n",
       "  '참가자',\n",
       "  '학생회',\n",
       "  '성당',\n",
       "  '퇴소',\n",
       "  '사물함',\n",
       "  '실종',\n",
       "  '자진',\n",
       "  '파이',\n",
       "  '어린이',\n",
       "  '에어컨',\n",
       "  '정민',\n",
       "  '퍼즐',\n",
       "  '이루리',\n",
       "  '캣맘',\n",
       "  '공혁준',\n",
       "  '또즐',\n",
       "  '니갸르'],\n",
       " ['부정행위',\n",
       "  '경통',\n",
       "  '텀페',\n",
       "  '중회',\n",
       "  '떡밥',\n",
       "  '국무',\n",
       "  '독일',\n",
       "  '할미',\n",
       "  '사프컴',\n",
       "  '관회',\n",
       "  '반타작',\n",
       "  '메리트',\n",
       "  '광학',\n",
       "  '팬덤',\n",
       "  '잉글랜드',\n",
       "  '현주',\n",
       "  '유로',\n",
       "  '에고',\n",
       "  '소희',\n",
       "  '쁘걸']]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f4815c",
   "metadata": {},
   "source": [
    "__월별 키워드 보기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "0ef9d038",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('능검', 2.260767814533165),\n",
       " ('눈사람', 1.6846429495194757),\n",
       " ('페스', 1.610230077040688),\n",
       " ('로토', 1.0773097870681805),\n",
       " ('팬픽', 1.0042855362774332),\n",
       " ('페이크', 1.0042390116242759),\n",
       " ('강민철', 0.8337913365931837),\n",
       " ('재래시장', 0.8249923193467364),\n",
       " ('정인', 0.7824369188747704),\n",
       " ('공론', 0.7237889856652208),\n",
       " ('냉면', 0.7000926140740011),\n",
       " ('오줌싸개', 0.6285326091369418),\n",
       " ('아나콘다', 0.5467134683125027),\n",
       " ('와이번스', 0.5331136670134958),\n",
       " ('보따리', 0.5063553456897618),\n",
       " ('삽자루', 0.4552971322576629)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('뻔뻔', 2.9060766694286704),\n",
       " ('학폭', 2.17729433603298),\n",
       " ('뻔선', 1.8340011697949712),\n",
       " ('학교폭력', 1.7158133778593483),\n",
       " ('쿼터', 1.5240046743778157),\n",
       " ('증원', 1.4487172599266391),\n",
       " ('뻔후', 1.238929017862722),\n",
       " ('폭로', 1.2205242316051437),\n",
       " ('괴롭힘', 1.1032633441401642),\n",
       " ('연강', 0.9081321681763606),\n",
       " ('동물원', 0.877751313243363),\n",
       " ('탈세', 0.8742128362653893),\n",
       " ('김연경', 0.8676058012943388),\n",
       " ('물성', 0.8389613842387756),\n",
       " ('역군', 0.8090530675135683),\n",
       " ('사인', 0.7851861517363047),\n",
       " ('연휴', 0.6764222193690317),\n",
       " ('방관', 0.6759785392670195),\n",
       " ('성폭행', 0.6582000882432335),\n",
       " ('설날', 0.6501837356569178),\n",
       " ('돌고래', 0.6475324203931211),\n",
       " ('매매혼', 0.645106973790332),\n",
       " ('강인원', 0.6242970899004467),\n",
       " ('박물관', 0.5779721602587583),\n",
       " ('뜻뜻', 0.5572805601042105),\n",
       " ('이진욱', 0.5127268180871906),\n",
       " ('읏', 0.4925825322501887),\n",
       " ('박혜수', 0.48565225162724185),\n",
       " ('명절', 0.48543285974844463),\n",
       " ('연가', 0.4368597579045375),\n",
       " ('라미', 0.42408578661221585),\n",
       " ('학보', 0.423844042948899),\n",
       " ('세뱃돈', 0.41938121923030325),\n",
       " ('분반', 0.41502840050637846)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('브레이브걸스', 2.22933911185193),\n",
       " ('단태', 2.0792541562070443),\n",
       " ('피셋', 1.703284982834478),\n",
       " ('신도시', 1.642462685846044),\n",
       " ('투기', 1.6165370239971752),\n",
       " ('검찰', 1.5690809043020542),\n",
       " ('결석', 1.5168880880759443),\n",
       " ('토지', 1.478933863061037),\n",
       " ('벚꽃', 1.4000063024463174),\n",
       " ('로나', 1.3672450068133981),\n",
       " ('마사', 1.3500116675752236),\n",
       " ('몰수', 1.2590418314014218),\n",
       " ('롤린', 1.2443783911042554),\n",
       " ('하윤', 1.2395557600221048),\n",
       " ('에이프릴', 1.2199456431016544),\n",
       " ('장관', 1.099773246730592),\n",
       " ('역주행', 1.0995421181074967),\n",
       " ('유신', 1.049941839395576),\n",
       " ('서진', 0.99970779535535),\n",
       " ('꼬북좌', 0.9836643072225276),\n",
       " ('수사', 0.9438734921055012),\n",
       " ('압수수색', 0.9182709420771997),\n",
       " ('자진', 0.8843710011701326),\n",
       " ('소급', 0.8766788875087869),\n",
       " ('버닝썬', 0.828980397868778),\n",
       " ('민주화', 0.8229285479641979),\n",
       " ('성매매', 0.811031207467534),\n",
       " ('룸살롱', 0.7873029929898611),\n",
       " ('향영', 0.7253117704861348),\n",
       " ('그래미', 0.7150509382790209),\n",
       " ('박수홍', 0.6941311631646634),\n",
       " ('임효준', 0.6317820125674505),\n",
       " ('수련', 0.614662265168781),\n",
       " ('쁘걸', 0.6074678333528786),\n",
       " ('동선', 0.5984709908292568),\n",
       " ('노처녀', 0.5760022032913371),\n",
       " ('환수', 0.5596460315295846),\n",
       " ('등업', 0.5586322988712654),\n",
       " ('카츠', 0.5561821747976696),\n",
       " ('가계약', 0.5414083548771053),\n",
       " ('공직자', 0.5134218746353706),\n",
       " ('스프링', 0.48478769961565893),\n",
       " ('비리', 0.4809067758456969),\n",
       " ('하은', 0.47642452303991895),\n",
       " ('혈소판', 0.4752109170110645),\n",
       " ('고위', 0.4505345102898079),\n",
       " ('집회', 0.44949842408299473),\n",
       " ('감사원', 0.4428786557154101),\n",
       " ('폐쇄', 0.4297318599605482),\n",
       " ('서머', 0.4164194620590456)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('서예지', 1.9022807834692488),\n",
       " ('슈퍼리그', 1.6895519677147233),\n",
       " ('클로즈', 1.6880632934864688),\n",
       " ('김정현', 1.2730761500460281),\n",
       " ('비제', 1.1448339147424684),\n",
       " ('만우절', 1.1299672608995588),\n",
       " ('벼락치기', 0.8972771472427674),\n",
       " ('권혁', 0.4997246313270325),\n",
       " ('파상', 0.4670631125631868),\n",
       " ('분포', 0.4465461535817043),\n",
       " ('너비', 0.43658398039753943)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('참가자', 2.0620549547283336),\n",
       " ('퍼즐', 2.061422982385385),\n",
       " ('공혁준', 2.0193505845033326),\n",
       " ('이루리', 1.7752761958177912),\n",
       " ('정민', 1.758700161419743),\n",
       " ('퇴소', 1.7352013308542047),\n",
       " ('또즐', 1.7010357834601493),\n",
       " ('니갸르', 1.5548242004092578),\n",
       " ('파이', 1.5152887325168194),\n",
       " ('자진', 1.5046535945302328),\n",
       " ('사물함', 1.4891681972729147),\n",
       " ('학생회', 1.4786129546458162),\n",
       " ('전기', 1.2066400820413237),\n",
       " ('범인', 1.0835541224993812),\n",
       " ('코난', 1.0285868555594113),\n",
       " ('성당', 0.9012279189844271),\n",
       " ('에어컨', 0.8047932944798283),\n",
       " ('어린이', 0.7861394025069605),\n",
       " ('실종', 0.7526812093728193),\n",
       " ('캣맘', 0.7436837301002479),\n",
       " ('무죄', 0.6489785383501229),\n",
       " ('어버이날', 0.6076281219154295),\n",
       " ('약육강식', 0.5902651138496333),\n",
       " ('호날두', 0.574112523473142),\n",
       " ('퇴', 0.5604843885505018),\n",
       " ('육지', 0.5199889921983183),\n",
       " ('어린이날', 0.4606035918840763),\n",
       " ('최면', 0.4170355382815962)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('텀페', 1.606603203188053),\n",
       " ('관회', 1.3746085911616708),\n",
       " ('광학', 1.2967518608025441),\n",
       " ('독일', 1.242447823527372),\n",
       " ('팬덤', 1.201700999169101),\n",
       " ('소희', 1.1362068081919847),\n",
       " ('부정행위', 1.094260938677591),\n",
       " ('유로', 0.9619952825122491),\n",
       " ('메리트', 0.9043947269187297),\n",
       " ('중회', 0.6250872479194971),\n",
       " ('경통', 0.60320749747943),\n",
       " ('국무', 0.566041043992044),\n",
       " ('사프컴', 0.5319942501084838),\n",
       " ('현주', 0.5215723113458508),\n",
       " ('에고', 0.49777081290346725),\n",
       " ('잉글랜드', 0.49256289396082537),\n",
       " ('할미', 0.47724325105923293),\n",
       " ('반타작', 0.45792501046152534),\n",
       " ('쁘걸', 0.4462492446186387),\n",
       " ('떡밥', 0.4452337671503154),\n",
       " ('미분', 0.4445983569019486),\n",
       " ('곡선', 0.44408952348419106),\n",
       " ('리믹스', 0.4418088480118401),\n",
       " ('펩시', 0.4320645626434206),\n",
       " ('미적분', 0.4170023692209237),\n",
       " ('프제', 0.41329545502830006),\n",
       " ('열역학', 0.4113587420406447)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "month = 1\n",
    "\n",
    "for month in range(1,7):\n",
    "    display([(idx_extended_key[arg],Points[month,arg]) for arg in np.flip(np.argsort(Points[month])) if Points[month,arg]>0.4])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70458b01",
   "metadata": {},
   "source": [
    "### 단어별 검토"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "aa185949",
   "metadata": {},
   "outputs": [],
   "source": [
    "_word = '피셋'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da83b0",
   "metadata": {},
   "source": [
    "- 월별 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "91f94e74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -1.21918944, -1.37305272,  1.70328498, -1.34172567,\n",
       "       -1.42083641, -1.34372986])"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Points[:,idx_extended[_word]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b0f937",
   "metadata": {},
   "source": [
    "- 전체 등장 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "b0b3e63e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_extended[idx_extended[_word]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242fb0f7",
   "metadata": {},
   "source": [
    "- 월별 등장 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "449e3c49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 79.,  50.,  36., 489.,  45.,  11.,  36.])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BoW_mat[:,idx_extended[_word]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07663378",
   "metadata": {},
   "source": [
    "- 월별 게시글 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "88180caa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11., 14.,  8., 51., 10.,  4.,  8.])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_extended[:,idx_extended[_word]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56549b42",
   "metadata": {},
   "source": [
    "- 지수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "b417c453",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상승률지수 : 1.463536799078829\n",
      "언급지수   : 0.04921103108035467\n",
      "게시글상승 : 0.0565289497131827\n",
      "게시글수   : -0.251312339887548\n",
      "패널티     : -0.021212579182274108\n",
      "최종값     : 1.2967518608025441\n"
     ]
    }
   ],
   "source": [
    "end = 6\n",
    "pp3(BoW_mat[end-1,idx_extended[_word]],BoW_mat[end,idx_extended[_word]],\n",
    "    posts_extended[end-1,idx_extended[_word]], posts_extended[end,idx_extended[_word]],\n",
    "    idx_extended[_word])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60f265",
   "metadata": {},
   "source": [
    "- 내용 검색 툴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "02db56f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_cd(word, x):\n",
    "    try:\n",
    "        return True if word in [y[0] for y in x] else False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def s_search(word, month, show_urls=True):\n",
    "    df_month = df2[df2.upload_date.apply(lambda x: True if x.month==month else False)]\n",
    "    title_cd = df2.title_tokenized.apply(lambda x: search_cd(word,x))\n",
    "    text_cd = df2.text_tokenized.apply(lambda x: search_cd(word,x))\n",
    "    comments_cd = df2.comments_tokenized.apply(lambda x: search_cd(word,x))\n",
    "    comments_writer_cd = df2.comments_writer_tokenized.apply(lambda x: search_cd(word,x))\n",
    "    df = df_month[title_cd | text_cd | comments_cd | comments_writer_cd]\n",
    "    if show_urls==True:\n",
    "        [print('http://www.ssodam.com/content/'+str(number)) for number in df.num]\n",
    "    return df\n",
    "\n",
    "def numofposts(word, month):\n",
    "    df = s_search(word,month,show_urls=False)\n",
    "    return len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8fa2b978",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24316/573384908.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'모닝콜'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24316/1827098987.py\u001b[0m in \u001b[0;36ms_search\u001b[1;34m(word, month, show_urls)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0ms_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_urls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdf_month\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload_date\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mmonth\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtitle_cd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle_tokenized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msearch_cd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtext_cd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_tokenized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msearch_cd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "s_search('모닝콜',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d140f0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "aa68aefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>board</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>writer</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>view</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_writer</th>\n",
       "      <th>comments_cnt</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>comments_writer_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1082901</td>\n",
       "      <td>익게2</td>\n",
       "      <td>해피뉴이어</td>\n",
       "      <td>2021년은 모두 행복한 한해가 되길</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>앗, 성지다, 첫글 ㅊㅊ, 추천 준다, 내 24살은 인생에서 가장 빛나는 날로 만들...</td>\n",
       "      <td></td>\n",
       "      <td>20.0</td>\n",
       "      <td>[(2021년, Number), (은, Foreign), (모두, Noun), (행...</td>\n",
       "      <td>[(해피뉴이어, Noun)]</td>\n",
       "      <td>[(앗, Noun), (,, Punctuation), (성지, Noun), (다, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1082902</td>\n",
       "      <td>익게2</td>\n",
       "      <td>2021년 새해복 많이받으세요</td>\n",
       "      <td>모든 일이 잘 되기를 12시 땡</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>107.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>늦었네</td>\n",
       "      <td>2빠다 ㅎㅎ, 내년에 도전한다</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(모든, Noun), (일이, Modifier), (잘, Verb), (되, Ve...</td>\n",
       "      <td>[(2021년, Number), (새해, Noun), (복, Noun), (많이, ...</td>\n",
       "      <td>[(늦었네, Verb)]</td>\n",
       "      <td>[(2, Number), (빠다, Noun), (ㅎㅎ, KoreanParticle)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082903</td>\n",
       "      <td>익게2</td>\n",
       "      <td>첫글은 내꼬</td>\n",
       "      <td>예비회계사 나다미</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ㄹㅇ 1등이네 ㅋㅋ, 실패</td>\n",
       "      <td>ㅜㅜ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(예비, Noun), (회계사, Noun), (나, Noun), (다미, Noun)]</td>\n",
       "      <td>[(첫, Modifier), (글, Noun), (은, Josa), (내꼬, Noun)]</td>\n",
       "      <td>[(ㄹㅇ, KoreanParticle), (1등, Number), (이네, Fore...</td>\n",
       "      <td>[(ㅜㅜ, KoreanParticle)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082905</td>\n",
       "      <td>익게2</td>\n",
       "      <td>땡ㅎㅎㅎㅎㅎㅎㅎ</td>\n",
       "      <td>1등</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(1등, Number)]</td>\n",
       "      <td>[(땡, Noun), (ㅎㅎㅎㅎㅎㅎㅎ, KoreanParticle)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1082906</td>\n",
       "      <td>익게2</td>\n",
       "      <td>어디 카운트 다운 하는 곳 없냐</td>\n",
       "      <td>언제바껴</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232번 불교방송</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(언, Modifier), (제바, Noun), (껴, Verb)]</td>\n",
       "      <td>[(어디, Noun), (카운트, Noun), (다운, Noun), (하는, Ver...</td>\n",
       "      <td>[(232, Number), (번, Noun), (불교, Noun), (방송, No...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77975</th>\n",
       "      <td>1200285</td>\n",
       "      <td>익게2</td>\n",
       "      <td>아버지께서 칼럼 쓰셨는데 댓글 한 번씩만 달아줄 수 있을까</td>\n",
       "      <td>2222408544049우리 아버지께서 이번에 짧은 칼럼처럼 블로그에 쓰시는 거 맡...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>23:43</td>\n",
       "      <td>5802.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>비댓으로 달래 너무 귀엽다, 이 글 조회수 늘리려면 제목 바꾸는거 추천 광고글인줄 ...</td>\n",
       "      <td>헉 피드백 반영했어 너무 고마워, 엇 아마 확인은 못하실 텐데 비댓이든 공개댓이든 ...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>[(2222408544049, Number), (우리, Noun), (아버지, No...</td>\n",
       "      <td>[(아버지, Noun), (께서, Josa), (칼럼, Noun), (쓰셨는데, V...</td>\n",
       "      <td>[(비댓, Noun), (으로, Josa), (달래, Noun), (너무, Adve...</td>\n",
       "      <td>[(헉, Adverb), (피드백, Noun), (반영, Noun), (했어, Ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77976</th>\n",
       "      <td>1200287</td>\n",
       "      <td>익게2</td>\n",
       "      <td>프로포폴 하면 기분이 좋음</td>\n",
       "      <td>하는거 신기하네하면 힙해보여서 하는건가</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>23:47</td>\n",
       "      <td>373.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>썰로 들은 거라 정확하지는 않는데 지방흡입할 때 고통 줄이려고 프로포폴 투약하다가 ...</td>\n",
       "      <td></td>\n",
       "      <td>5.0</td>\n",
       "      <td>[(하는거, Verb), (신기하네하면, Adjective), (힙, Noun), ...</td>\n",
       "      <td>[(프로포폴, Noun), (하면, Verb), (기분, Noun), (이, Jos...</td>\n",
       "      <td>[(썰로, Verb), (들은, Verb), (거, Noun), (라, Josa),...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77977</th>\n",
       "      <td>1200288</td>\n",
       "      <td>익게2</td>\n",
       "      <td>취업 후기 쓰려는데 안올라간다ㅠ</td>\n",
       "      <td>손다쳐서 폰으로 열심히 적었는데나한테왜 이래ㅠ혹시 뭔가 지켜야 하는 양식이 있나요ㅠ...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>23:49</td>\n",
       "      <td>387.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>중간에 임티 넣었었어, 임티, 1 이모티콘 빼기2 사진 많으면 업로드 될 동안 조금...</td>\n",
       "      <td>이건 되네</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[(손, Noun), (다쳐서, Verb), (폰, Noun), (으로, Josa)...</td>\n",
       "      <td>[(취업, Noun), (후기, Noun), (쓰려는데, Verb), (안, Ver...</td>\n",
       "      <td>[(중간, Noun), (에, Josa), (임티, Noun), (넣었었어, Ver...</td>\n",
       "      <td>[(이건, Noun), (되네, Verb)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77978</th>\n",
       "      <td>1200291</td>\n",
       "      <td>익게2</td>\n",
       "      <td>간떨어지는동거 보는 사람</td>\n",
       "      <td>아 이번주 기대했는데                                예고편...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>23:55</td>\n",
       "      <td>138.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>너무 오글거리는데 장기용때매 봄 ㅎㅎ, 난 계선우땜에 봐ㅠㅠ, 나도 계선우 때문에 ...</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(아, Exclamation), (이번, Noun), (주, Noun), (기대했...</td>\n",
       "      <td>[(간, Noun), (떨어지는, Verb), (동거, Noun), (보는, Ver...</td>\n",
       "      <td>[(너무, Adverb), (오글거리는데, Verb), (장기, Noun), (용때...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77979</th>\n",
       "      <td>1200293</td>\n",
       "      <td>익게2</td>\n",
       "      <td>오타루 오마카세 후기</td>\n",
       "      <td>전에 어떤 다미가 추천한거 보고 오늘 가봤어ㅎㅎ디너 오마카세 가격은 55,000원이...</td>\n",
       "      <td>익명</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>23:59</td>\n",
       "      <td>869.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>맛있겠다, 김을 안 주는게 아쉽다, 너무 괜찮은데 와 나도 가보고싶다지방다미, 와 ...</td>\n",
       "      <td>존맛 꼭가봐ㅎㅎ, 아무래도 가격이 가격인지라 전반적으로 딱 기본에 충실한 느낌이긴 ...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[(전, Noun), (에, Josa), (어떤, Adjective), (다미, N...</td>\n",
       "      <td>[(오타루, Noun), (오, Modifier), (마카, Noun), (세, N...</td>\n",
       "      <td>[(맛있겠다, Adjective), (,, Punctuation), (김, Noun...</td>\n",
       "      <td>[(존맛, Noun), (꼭, Noun), (가봐, Verb), (ㅎㅎ, Korea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77980 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           num board                             title  \\\n",
       "0      1082901   익게2                             해피뉴이어   \n",
       "1      1082902   익게2                  2021년 새해복 많이받으세요   \n",
       "2      1082903   익게2                            첫글은 내꼬   \n",
       "3      1082905   익게2                          땡ㅎㅎㅎㅎㅎㅎㅎ   \n",
       "4      1082906   익게2                 어디 카운트 다운 하는 곳 없냐   \n",
       "...        ...   ...                               ...   \n",
       "77975  1200285   익게2  아버지께서 칼럼 쓰셨는데 댓글 한 번씩만 달아줄 수 있을까   \n",
       "77976  1200287   익게2                    프로포폴 하면 기분이 좋음   \n",
       "77977  1200288   익게2                 취업 후기 쓰려는데 안올라간다ㅠ   \n",
       "77978  1200291   익게2                     간떨어지는동거 보는 사람   \n",
       "77979  1200293   익게2                       오타루 오마카세 후기   \n",
       "\n",
       "                                                    text writer upload_date  \\\n",
       "0                                   2021년은 모두 행복한 한해가 되길     익명  2021-01-01   \n",
       "1                                      모든 일이 잘 되기를 12시 땡     익명  2021-01-01   \n",
       "2                                              예비회계사 나다미     익명  2021-01-01   \n",
       "3                                                     1등     익명  2021-01-01   \n",
       "4                                                   언제바껴     익명  2021-01-01   \n",
       "...                                                  ...    ...         ...   \n",
       "77975  2222408544049우리 아버지께서 이번에 짧은 칼럼처럼 블로그에 쓰시는 거 맡...     익명  2021-06-30   \n",
       "77976                              하는거 신기하네하면 힙해보여서 하는건가     익명  2021-06-30   \n",
       "77977  손다쳐서 폰으로 열심히 적었는데나한테왜 이래ㅠ혹시 뭔가 지켜야 하는 양식이 있나요ㅠ...     익명  2021-06-30   \n",
       "77978  아 이번주 기대했는데                                예고편...     익명  2021-06-30   \n",
       "77979  전에 어떤 다미가 추천한거 보고 오늘 가봤어ㅎㅎ디너 오마카세 가격은 55,000원이...     익명  2021-06-30   \n",
       "\n",
       "      upload_time    view  likes  dislikes  \\\n",
       "0           00:00  1343.0  195.0       0.0   \n",
       "1           00:00   107.0    3.0       0.0   \n",
       "2           00:00   139.0    1.0       0.0   \n",
       "3           00:00    39.0    0.0       0.0   \n",
       "4           00:00    84.0    0.0       0.0   \n",
       "...           ...     ...    ...       ...   \n",
       "77975       23:43  5802.0  374.0      11.0   \n",
       "77976       23:47   373.0    1.0       1.0   \n",
       "77977       23:49   387.0    3.0       0.0   \n",
       "77978       23:55   138.0    6.0       0.0   \n",
       "77979       23:59   869.0   24.0       0.0   \n",
       "\n",
       "                                                comments  \\\n",
       "0      앗, 성지다, 첫글 ㅊㅊ, 추천 준다, 내 24살은 인생에서 가장 빛나는 날로 만들...   \n",
       "1                                                    늦었네   \n",
       "2                                         ㄹㅇ 1등이네 ㅋㅋ, 실패   \n",
       "3                                                          \n",
       "4                                              232번 불교방송   \n",
       "...                                                  ...   \n",
       "77975  비댓으로 달래 너무 귀엽다, 이 글 조회수 늘리려면 제목 바꾸는거 추천 광고글인줄 ...   \n",
       "77976  썰로 들은 거라 정확하지는 않는데 지방흡입할 때 고통 줄이려고 프로포폴 투약하다가 ...   \n",
       "77977  중간에 임티 넣었었어, 임티, 1 이모티콘 빼기2 사진 많으면 업로드 될 동안 조금...   \n",
       "77978  너무 오글거리는데 장기용때매 봄 ㅎㅎ, 난 계선우땜에 봐ㅠㅠ, 나도 계선우 때문에 ...   \n",
       "77979  맛있겠다, 김을 안 주는게 아쉽다, 너무 괜찮은데 와 나도 가보고싶다지방다미, 와 ...   \n",
       "\n",
       "                                         comments_writer  comments_cnt  \\\n",
       "0                                                                 20.0   \n",
       "1                                       2빠다 ㅎㅎ, 내년에 도전한다           3.0   \n",
       "2                                                     ㅜㅜ           3.0   \n",
       "3                                                                  0.0   \n",
       "4                                                                  1.0   \n",
       "...                                                  ...           ...   \n",
       "77975  헉 피드백 반영했어 너무 고마워, 엇 아마 확인은 못하실 텐데 비댓이든 공개댓이든 ...          75.0   \n",
       "77976                                                              5.0   \n",
       "77977                                              이건 되네           7.0   \n",
       "77978                                                              3.0   \n",
       "77979  존맛 꼭가봐ㅎㅎ, 아무래도 가격이 가격인지라 전반적으로 딱 기본에 충실한 느낌이긴 ...          16.0   \n",
       "\n",
       "                                          text_tokenized  \\\n",
       "0      [(2021년, Number), (은, Foreign), (모두, Noun), (행...   \n",
       "1      [(모든, Noun), (일이, Modifier), (잘, Verb), (되, Ve...   \n",
       "2       [(예비, Noun), (회계사, Noun), (나, Noun), (다미, Noun)]   \n",
       "3                                         [(1등, Number)]   \n",
       "4                 [(언, Modifier), (제바, Noun), (껴, Verb)]   \n",
       "...                                                  ...   \n",
       "77975  [(2222408544049, Number), (우리, Noun), (아버지, No...   \n",
       "77976  [(하는거, Verb), (신기하네하면, Adjective), (힙, Noun), ...   \n",
       "77977  [(손, Noun), (다쳐서, Verb), (폰, Noun), (으로, Josa)...   \n",
       "77978  [(아, Exclamation), (이번, Noun), (주, Noun), (기대했...   \n",
       "77979  [(전, Noun), (에, Josa), (어떤, Adjective), (다미, N...   \n",
       "\n",
       "                                         title_tokenized  \\\n",
       "0                                        [(해피뉴이어, Noun)]   \n",
       "1      [(2021년, Number), (새해, Noun), (복, Noun), (많이, ...   \n",
       "2      [(첫, Modifier), (글, Noun), (은, Josa), (내꼬, Noun)]   \n",
       "3                 [(땡, Noun), (ㅎㅎㅎㅎㅎㅎㅎ, KoreanParticle)]   \n",
       "4      [(어디, Noun), (카운트, Noun), (다운, Noun), (하는, Ver...   \n",
       "...                                                  ...   \n",
       "77975  [(아버지, Noun), (께서, Josa), (칼럼, Noun), (쓰셨는데, V...   \n",
       "77976  [(프로포폴, Noun), (하면, Verb), (기분, Noun), (이, Jos...   \n",
       "77977  [(취업, Noun), (후기, Noun), (쓰려는데, Verb), (안, Ver...   \n",
       "77978  [(간, Noun), (떨어지는, Verb), (동거, Noun), (보는, Ver...   \n",
       "77979  [(오타루, Noun), (오, Modifier), (마카, Noun), (세, N...   \n",
       "\n",
       "                                      comments_tokenized  \\\n",
       "0      [(앗, Noun), (,, Punctuation), (성지, Noun), (다, ...   \n",
       "1                                          [(늦었네, Verb)]   \n",
       "2      [(ㄹㅇ, KoreanParticle), (1등, Number), (이네, Fore...   \n",
       "3                                                     []   \n",
       "4      [(232, Number), (번, Noun), (불교, Noun), (방송, No...   \n",
       "...                                                  ...   \n",
       "77975  [(비댓, Noun), (으로, Josa), (달래, Noun), (너무, Adve...   \n",
       "77976  [(썰로, Verb), (들은, Verb), (거, Noun), (라, Josa),...   \n",
       "77977  [(중간, Noun), (에, Josa), (임티, Noun), (넣었었어, Ver...   \n",
       "77978  [(너무, Adverb), (오글거리는데, Verb), (장기, Noun), (용때...   \n",
       "77979  [(맛있겠다, Adjective), (,, Punctuation), (김, Noun...   \n",
       "\n",
       "                               comments_writer_tokenized  \n",
       "0                                                     []  \n",
       "1      [(2, Number), (빠다, Noun), (ㅎㅎ, KoreanParticle)...  \n",
       "2                                 [(ㅜㅜ, KoreanParticle)]  \n",
       "3                                                     []  \n",
       "4                                                     []  \n",
       "...                                                  ...  \n",
       "77975  [(헉, Adverb), (피드백, Noun), (반영, Noun), (했어, Ve...  \n",
       "77976                                                 []  \n",
       "77977                           [(이건, Noun), (되네, Verb)]  \n",
       "77978                                                 []  \n",
       "77979  [(존맛, Noun), (꼭, Noun), (가봐, Verb), (ㅎㅎ, Korea...  \n",
       "\n",
       "[77980 rows x 17 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "502eb0cd",
   "metadata": {},
   "source": [
    "## ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "id": "e87b2de4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "4\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15264/2476273054.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mPosts_mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumofposts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15264/1827098987.py\u001b[0m in \u001b[0;36mnumofposts\u001b[1;34m(word, month)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnumofposts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_urls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15264/1827098987.py\u001b[0m in \u001b[0;36ms_search\u001b[1;34m(word, month, show_urls)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0ms_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_urls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdf_month\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload_date\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mmonth\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtitle_cd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle_tokenized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msearch_cd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtext_cd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_tokenized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msearch_cd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4135\u001b[0m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4137\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4138\u001b[0m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5875\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5876\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5877\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5878\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m     ) -> \"BlockManager\":\n\u001b[1;32m--> 631\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     def convert(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   2280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2281\u001b[0m         \u001b[1;31m# delegate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2282\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2284\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_can_hold_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m             \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mget_values\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2173\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m             \u001b[1;31m# DTA/TDA constructor and astype can handle 2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2175\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_holder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2176\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_period_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_period\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdtl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatetimeLikeArrayMixin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[1;31m# -----------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masi8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_string_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py\u001b[0m in \u001b[0;36m_box_values\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mapply\u001b[0m \u001b[0mbox\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0mto\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36m_box_func\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[1;31m# Descriptive Properties\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m_box_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNaTType\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Posts_mat = np.zeros((7,len(idx_extended)))\n",
    "for i, key in enumerate(idx_extended):\n",
    "    print(i)\n",
    "    for j in range(1,7):\n",
    "        print(j)\n",
    "        Posts_mat[j,i] = numofposts(key,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bafde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('posts_mat.pkl','wb') as f:\n",
    "    pickle.dump(Posts_mat,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
